{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 163,
   "id": "5c795334-a58e-49c4-a93d-b94f64db216d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.distributions.normal import Normal\n",
    "import matplotlib.pyplot as plt\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "id": "e3d1e1a3-f0af-4cc8-bc25-a65eee974631",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "def simulate_paths_multi(S0_vec, r, q_vec, sigma_vec, rho,\n",
    "                         T, num_steps, N, seed=None):\n",
    "    \"\"\"Simulate N correlated GBM paths.  Return (N, num_steps+1, d).\"\"\"\n",
    "    if seed is not None:\n",
    "        np.random.seed(seed)\n",
    "\n",
    "    d   = len(S0_vec)\n",
    "    dt  = T / num_steps\n",
    "\n",
    "    corr = rho * np.ones((d, d), dtype=np.float32)\n",
    "    np.fill_diagonal(corr, 1.0)\n",
    "    L = np.linalg.cholesky(corr)                       # (d,d) Cholesky\n",
    "\n",
    "    S = np.zeros((N, num_steps + 1, d), dtype=np.float32)\n",
    "    S[:, 0, :] = S0_vec\n",
    "\n",
    "    drift  = (r - q_vec - 0.5 * sigma_vec**2) * dt\n",
    "    vol_dt = sigma_vec * np.sqrt(dt)\n",
    "\n",
    "    for t in range(num_steps):\n",
    "        z_corr = np.random.randn(N, d).astype(np.float32) @ L.T\n",
    "        S[:, t + 1, :] = S[:, t, :] * np.exp(drift + vol_dt * z_corr)\n",
    "\n",
    "    return S\n",
    "\n",
    "\n",
    "class ContinuationValueNet(nn.Module):\n",
    "    \"\"\"\n",
    "    Neural network u^theta for continuation value\n",
    "    \"\"\"\n",
    "    def __init__(self, d: int, width: int = None, depth: int = None,\n",
    "                 negative_slope: float = 0.01, dropout: float = 0.1):\n",
    "        super().__init__()\n",
    "        self.d = d\n",
    "        \n",
    "        # Normalisation\n",
    "        self.register_buffer('input_mean', torch.zeros(d + 1))\n",
    "        self.register_buffer('input_std', torch.ones(d + 1))\n",
    "        \n",
    "        # Network\n",
    "        layers = [nn.Linear(d + 1, width), nn.LeakyReLU(negative_slope)]\n",
    "        \n",
    "        for _ in range(depth - 2):\n",
    "            layers.extend([\n",
    "                nn.Linear(width, width),\n",
    "                nn.LeakyReLU(negative_slope)\n",
    "            ])\n",
    "        \n",
    "        layers.append(nn.Linear(width, 1))\n",
    "        self.net = nn.Sequential(*layers)\n",
    "        \n",
    "        # Init weights\n",
    "        self.apply(self._init_weights)\n",
    "    \n",
    "    def _init_weights(self, m):\n",
    "        if isinstance(m, nn.Linear):\n",
    "            nn.init.xavier_uniform_(m.weight)\n",
    "            if m.bias is not None:\n",
    "                nn.init.constant_(m.bias, 0)\n",
    "    \n",
    "    def set_normalization(self, mean, std):\n",
    "        self.input_mean.copy_(mean)\n",
    "        self.input_std.copy_(std)\n",
    "    \n",
    "    def forward(self, t_norm: torch.Tensor, logS: torch.Tensor) -> torch.Tensor:\n",
    "        x = torch.cat([t_norm.unsqueeze(-1), logS], dim=-1)\n",
    "        x = (x - self.input_mean) / (self.input_std + 1e-8)\n",
    "        return self.net(x).squeeze(-1)\n",
    "\n",
    "\n",
    "@torch.no_grad()\n",
    "def evaluate_policy(net, soft_sigma=0.2, N_eval=20_000):\n",
    "    paths = simulate_paths_multi(S0_vec, r, q_vec, sigma_vec, rho,\n",
    "                                 T, num_steps, N_eval)\n",
    "    paths = torch.from_numpy(paths).to(device)\n",
    "    B     = paths.size(0)\n",
    "\n",
    "    normal  = Normal(0., 1.)\n",
    "    survival      = torch.ones(B, device=device)\n",
    "    total_payoffs = torch.zeros(B, device=device)\n",
    "    disc_vec      = torch.exp(-r * dt * torch.arange(num_steps, device=device))\n",
    "\n",
    "    for t in range(num_steps):\n",
    "        t_norm   = t / num_steps\n",
    "        S_t      = paths[:, t, :]\n",
    "        payoff   = torch.clamp(S_t.max(dim=-1).values - K, min=0.)\n",
    "        payoff_d = payoff * disc_vec[t]\n",
    "\n",
    "        cont = net(torch.full((B,), t_norm, device=device),\n",
    "                   torch.log(S_t + 1e-12))\n",
    "        x    = (payoff_d - cont) / soft_sigma\n",
    "        p_t  = normal.cdf(x)\n",
    "\n",
    "        total_payoffs += survival * p_t * payoff_d\n",
    "        survival       = survival * (1 - p_t)\n",
    "\n",
    "    S_T     = paths[:, -1, :]\n",
    "    payoffT = torch.clamp(S_T.max(dim=-1).values - K, min=0.)\n",
    "    total_payoffs += survival * payoffT * np.exp(-r * T)\n",
    "\n",
    "    mean = total_payoffs.mean().item()\n",
    "    se   = total_payoffs.std(unbiased=True).item() / math.sqrt(N_eval)\n",
    "    return mean, se\n",
    "\n",
    "\n",
    "@torch.no_grad()\n",
    "def evaluate_sharp_policy(net, N_eval=20_000, seed_eval=9999):\n",
    "    net.eval()\n",
    "\n",
    "    paths = simulate_paths_multi(S0_vec, r, q_vec, sigma_vec, rho,\n",
    "                                 T, num_steps, N_eval, seed=seed_eval)\n",
    "    paths = torch.from_numpy(paths).to(device)\n",
    "    B     = paths.size(0)\n",
    "\n",
    "    survival      = torch.ones(B, device=device)\n",
    "    total_payoffs = torch.zeros(B, device=device)\n",
    "    disc_vec      = torch.exp(-r * dt * torch.arange(num_steps, device=device))\n",
    "\n",
    "    for t in range(num_steps):\n",
    "        t_norm   = t / num_steps\n",
    "        S_t      = paths[:, t, :]\n",
    "        payoff   = torch.clamp(S_t.max(dim=-1).values - K, min=0.)\n",
    "        payoff_d = payoff * disc_vec[t]\n",
    "\n",
    "        cont = net(torch.full((B,), t_norm, device=device),\n",
    "                   torch.log(S_t + 1e-12))\n",
    "\n",
    "        exercise = (payoff_d > cont)\n",
    "        total_payoffs += survival * exercise.float() * payoff_d\n",
    "        survival       = survival * (~exercise).float()\n",
    "\n",
    "    S_T     = paths[:, -1, :]\n",
    "    payoffT = torch.clamp(S_T.max(dim=-1).values - K, min=0.)\n",
    "    total_payoffs += survival * payoffT * np.exp(-r * T)\n",
    "\n",
    "    mean = total_payoffs.mean().item()\n",
    "    se   = total_payoffs.std(unbiased=True).item() / math.sqrt(N_eval)\n",
    "    return mean, se\n",
    "\n",
    "\n",
    "class EarlyStopping:\n",
    "    \"\"\"\n",
    "    Early stopping to stop training when improvement small\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, patience=20, min_delta=1e-4, relative_threshold=1e-3, \n",
    "                 min_epochs=50, max_epochs=2000):\n",
    "        self.patience = patience\n",
    "        self.min_delta = min_delta\n",
    "        self.relative_threshold = relative_threshold\n",
    "        self.min_epochs = min_epochs\n",
    "        self.max_epochs = max_epochs\n",
    "        \n",
    "        self.best_score = -np.inf\n",
    "        self.epochs_without_improvement = 0\n",
    "        self.history = []\n",
    "        self.start_time = None\n",
    "        \n",
    "    def start_training(self):\n",
    "        self.start_time = time.time()\n",
    "    \n",
    "    def get_elapsed_time(self):\n",
    "        if self.start_time is None:\n",
    "            return 0\n",
    "        return time.time() - self.start_time\n",
    "    \n",
    "    def format_time(self, seconds):\n",
    "        hours = int(seconds // 3600)\n",
    "        minutes = int((seconds % 3600) // 60)\n",
    "        seconds = int(seconds % 60)\n",
    "        \n",
    "        if hours > 0:\n",
    "            return f\"{hours}h {minutes}m {seconds}s\"\n",
    "        elif minutes > 0:\n",
    "            return f\"{minutes}m {seconds}s\"\n",
    "        else:\n",
    "            return f\"{seconds}s\"\n",
    "            \n",
    "    def should_stop(self, current_score, epoch):\n",
    "        self.history.append(current_score)\n",
    "        \n",
    "        if epoch < self.min_epochs:\n",
    "            if current_score > self.best_score:\n",
    "                self.best_score = current_score\n",
    "                self.epochs_without_improvement = 0\n",
    "            else:\n",
    "                self.epochs_without_improvement += 1\n",
    "            return False\n",
    "        \n",
    "        if epoch >= self.max_epochs:\n",
    "            elapsed_time = self.get_elapsed_time()\n",
    "            print(f\"Maximum epochs ({self.max_epochs}) reached after {self.format_time(elapsed_time)}. Stopping training.\")\n",
    "            return True\n",
    "        \n",
    "        absolute_improvement = current_score - self.best_score\n",
    "        relative_improvement = absolute_improvement / abs(self.best_score) if self.best_score != 0 else 0\n",
    "        \n",
    "        is_improvement = (absolute_improvement > self.min_delta and \n",
    "                         relative_improvement > self.relative_threshold)\n",
    "        \n",
    "        if is_improvement:\n",
    "            self.best_score = current_score\n",
    "            self.epochs_without_improvement = 0\n",
    "            return False\n",
    "        else:\n",
    "            self.epochs_without_improvement += 1\n",
    "            \n",
    "            if self.epochs_without_improvement >= self.patience:\n",
    "                elapsed_time = self.get_elapsed_time()\n",
    "                print(f\"Early stopping triggered after {epoch + 1} epochs ({self.format_time(elapsed_time)})\")\n",
    "                print(f\"Best score: {self.best_score:.6f}\")\n",
    "                print(f\"No improvement for {self.patience} epochs\")\n",
    "                return True\n",
    "        \n",
    "        return False\n",
    "    \n",
    "    def get_best_score(self):\n",
    "        return self.best_score\n",
    "    \n",
    "    def get_convergence_info(self):\n",
    "        \"\"\"\n",
    "        Return information about the convergence process\n",
    "        \"\"\"\n",
    "        return {\n",
    "            'best_score': self.best_score,\n",
    "            'epochs_without_improvement': self.epochs_without_improvement,\n",
    "            'total_epochs': len(self.history),\n",
    "            'final_score': self.history[-1] if self.history else None,\n",
    "            'training_time': self.get_elapsed_time(),\n",
    "            'training_time_formatted': self.format_time(self.get_elapsed_time())\n",
    "        }\n",
    "\n",
    "\n",
    "def train_net(soft_sigma,\n",
    "              N_train=10_000,\n",
    "              batch=500,\n",
    "              lr=0.003,\n",
    "              seed=None,\n",
    "              eval_every=10,\n",
    "              width=None,\n",
    "              depth=None,\n",
    "              dropout=0.1,\n",
    "              curriculum=True,\n",
    "              # Early stopping parameters\n",
    "              patience=25,\n",
    "              min_delta=1e-4,\n",
    "              relative_threshold=1e-3,\n",
    "              min_epochs=50,\n",
    "              max_epochs=2000):\n",
    "    \"\"\"\n",
    "    Train continuation‑value network\n",
    "    \"\"\"\n",
    "    if seed is not None:\n",
    "        np.random.seed(seed)\n",
    "        torch.manual_seed(seed)\n",
    "\n",
    "    net = ContinuationValueNet(d, width=width, depth=depth, dropout=dropout).to(device)\n",
    "    optimiser = optim.Adam(net.parameters(), lr=lr, weight_decay=1e-4)\n",
    "    scheduler = optim.lr_scheduler.ReduceLROnPlateau(\n",
    "        optimiser, mode='max', patience=15, factor=0.5, verbose=True, min_lr=1e-6\n",
    "    )\n",
    "    \n",
    "    # Init early stopping\n",
    "    early_stopping = EarlyStopping(\n",
    "        patience=patience,\n",
    "        min_delta=min_delta,\n",
    "        relative_threshold=relative_threshold,\n",
    "        min_epochs=min_epochs,\n",
    "        max_epochs=max_epochs\n",
    "    )\n",
    "    \n",
    "    normal = Normal(0., 1.)\n",
    "    disc_vec = torch.exp(-r * dt * torch.arange(num_steps, device=device))\n",
    "\n",
    "    steps_per_epoch = N_train // batch\n",
    "    train_hist, eval_hist = [], []\n",
    "    \n",
    "    # Input normalization\n",
    "    print(\"Setting up input normalization...\")\n",
    "    log_S0 = np.log(S0_vec[0])\n",
    "    input_mean = torch.tensor([0.5] + [log_S0] * d, device=device)\n",
    "    input_std = torch.tensor([0.3] + [0.3] * d, device=device)\n",
    "    net.set_normalization(input_mean, input_std)\n",
    "    \n",
    "    if curriculum:\n",
    "        def get_soft_sigma(ep):\n",
    "            # Gradually decrease from 2*soft_sigma to soft_sigma over first 200 epochs\n",
    "            if ep < 200:\n",
    "                return soft_sigma * (2 - ep / 200)\n",
    "            return soft_sigma\n",
    "    else:\n",
    "        get_soft_sigma = lambda ep: soft_sigma\n",
    "\n",
    "    print(f\"Starting training with early stopping (patience={patience}, min_epochs={min_epochs})\")\n",
    "    print(f\"Will stop when improvement < {min_delta:.2e} absolute or < {relative_threshold:.2e} relative\")\n",
    "    \n",
    "    early_stopping.start_training()\n",
    "    \n",
    "    ep = 0\n",
    "    while True:\n",
    "        current_soft_sigma = get_soft_sigma(ep)\n",
    "        epoch_reward_sum = 0.0\n",
    "        net.train()\n",
    "\n",
    "        for _ in range(steps_per_epoch):\n",
    "            S_b = torch.from_numpy(\n",
    "                simulate_paths_multi(S0_vec, r, q_vec, sigma_vec, rho,\n",
    "                                     T, num_steps, batch)\n",
    "            ).to(device)\n",
    "            B = S_b.size(0)\n",
    "\n",
    "            logS = torch.log(S_b[:, :num_steps, :] + 1e-12)\n",
    "            logS_f = logS.reshape(-1, d)\n",
    "            t_norm = torch.arange(num_steps, device=device).repeat(B) / num_steps\n",
    "            cont = net(t_norm, logS_f).view(B, num_steps)\n",
    "\n",
    "            payoff_now = torch.clamp(S_b[:, :num_steps, :].max(dim=-1).values - K, 0.)\n",
    "            payoff_disc = payoff_now * disc_vec.unsqueeze(0)\n",
    "\n",
    "            survival = torch.ones(B, device=device)\n",
    "            total_payoffs = torch.zeros(B, device=device)\n",
    "\n",
    "            for t in range(num_steps):\n",
    "                x_t = (payoff_disc[:, t] - cont[:, t]) / current_soft_sigma\n",
    "                p_t = normal.cdf(x_t)\n",
    "\n",
    "                total_payoffs += survival * p_t * payoff_disc[:, t]\n",
    "                survival = survival * (1 - p_t)\n",
    "\n",
    "            payoff_T = torch.clamp(S_b[:, -1, :].max(dim=-1).values - K, 0.)\n",
    "            total_payoffs += survival * payoff_T * np.exp(-r * T)\n",
    "\n",
    "            optimiser.zero_grad()\n",
    "            loss = -total_payoffs.mean()\n",
    "            loss.backward()\n",
    "            \n",
    "            torch.nn.utils.clip_grad_norm_(net.parameters(), max_norm=1.0)\n",
    "            optimiser.step()\n",
    "            epoch_reward_sum += total_payoffs.mean().item()\n",
    "\n",
    "        avg_reward = epoch_reward_sum / steps_per_epoch\n",
    "        train_hist.append(avg_reward)\n",
    "        \n",
    "        # Evaluation and early stopping check\n",
    "        if (ep + 1) % eval_every == 0:\n",
    "            net.eval()\n",
    "            eval_mean, _ = evaluate_policy(net, current_soft_sigma, N_eval=10_000)\n",
    "            eval_hist.append((ep + 1, eval_mean))\n",
    "            \n",
    "            # Update learning rate scheduler\n",
    "            scheduler.step(eval_mean)\n",
    "            \n",
    "            # Calculate elapsed time\n",
    "            elapsed_time = early_stopping.get_elapsed_time()\n",
    "            time_per_epoch = elapsed_time / (ep + 1)\n",
    "            \n",
    "            # print(f\"Epoch {ep + 1:4d} | \"\n",
    "            #       f\"train‑avg = {avg_reward:8.4f} | \"\n",
    "            #       f\"soft‑eval = {eval_mean:8.4f} | \"\n",
    "            #       f\"best = {early_stopping.get_best_score():8.4f} | \"\n",
    "            #       f\"no_improve = {early_stopping.epochs_without_improvement:2d} | \"\n",
    "            #       f\"time = {early_stopping.format_time(elapsed_time)} | \"\n",
    "            #       f\"epoch_time = {time_per_epoch:.1f}s | \"\n",
    "            #       f\"soft_sigma = {current_soft_sigma:.3f} | \"\n",
    "            #       f\"lr = {optimiser.param_groups[0]['lr']:.2e}\")\n",
    "            \n",
    "            # Check for early stopping\n",
    "            if early_stopping.should_stop(eval_mean, ep + 1):\n",
    "                break\n",
    "        else:\n",
    "            if early_stopping.should_stop(avg_reward, ep + 1):\n",
    "                break\n",
    "        \n",
    "        ep += 1\n",
    "    \n",
    "    convergence_info = early_stopping.get_convergence_info()\n",
    "    print(f\"\\nTraining completed after {ep + 1} epochs\")\n",
    "    print(f\"Total training time: {convergence_info['training_time_formatted']}\")\n",
    "    print(f\"Average time per epoch: {convergence_info['training_time'] / (ep + 1):.1f}s\")\n",
    "    print(f\"Best evaluation score: {convergence_info['best_score']:.6f}\")\n",
    "    print(f\"Final score: {convergence_info['final_score']:.6f}\")\n",
    "    \n",
    "    return net, train_hist, eval_hist, convergence_info['training_time_formatted']\n",
    "\n",
    "def average_time_in_seconds(times):\n",
    "    \"\"\"\n",
    "    Helper function for checking training time\n",
    "    \"\"\"\n",
    "    seconds = [float(t.strip('s')) for t in times]   \n",
    "    avg = sum(seconds) / len(seconds)  \n",
    "    return round(avg, 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85237880-35b7-442c-8751-e68acfc15c36",
   "metadata": {},
   "source": [
    "# Option Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1c090b85-3491-4260-a454-e47379c107e2",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'd' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[5]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m S0_vec       = np.full(\u001b[43md\u001b[49m, \u001b[32m100.0\u001b[39m, dtype=np.float32)\n\u001b[32m      2\u001b[39m sigma_vec    = np.full(d, \u001b[32m0.2\u001b[39m, dtype=np.float32)\n\u001b[32m      3\u001b[39m q_vec        = np.full(d, \u001b[32m0.1\u001b[39m, dtype=np.float32)\n",
      "\u001b[31mNameError\u001b[39m: name 'd' is not defined"
     ]
    }
   ],
   "source": [
    "# S0_vec       = np.full(d, 100.0, dtype=np.float32)\n",
    "# sigma_vec    = np.full(d, 0.2, dtype=np.float32)\n",
    "# q_vec        = np.full(d, 0.1, dtype=np.float32)\n",
    "# rho          = 0.0\n",
    "# r            = 0.05\n",
    "# K            = 100.0\n",
    "# T            = 3.0\n",
    "# num_steps    = 9\n",
    "# dt           = T / num_steps"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b69e8d60-b1cc-4a52-83f8-94830ec4c5f2",
   "metadata": {},
   "source": [
    "# d = 2 (Asymm. Div)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "25bf888a-50e5-4eba-a1ec-d409b50e96c0",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Setting up input normalization...\n",
      "Starting training with early stopping (patience=200, min_epochs=50)\n",
      "Will stop when improvement < 1.00e-02 absolute or < 1.00e-03 relative\n",
      "Epoch   10 | train‑avg =  15.3463 | soft‑eval =  15.4480 | best =  15.3306 | no_improve =  0 | time = 0s | epoch_time = 0.1s | soft_sigma = 2.000 | lr = 7.00e-03\n",
      "Epoch   20 | train‑avg =  15.4741 | soft‑eval =  15.4910 | best =  15.5884 | no_improve =  5 | time = 0s | epoch_time = 0.0s | soft_sigma = 2.000 | lr = 7.00e-03\n",
      "Epoch   30 | train‑avg =  15.5026 | soft‑eval =  15.3555 | best =  15.8268 | no_improve =  6 | time = 1s | epoch_time = 0.0s | soft_sigma = 2.000 | lr = 7.00e-03\n",
      "Epoch   40 | train‑avg =  15.4192 | soft‑eval =  15.9871 | best =  15.8268 | no_improve = 16 | time = 1s | epoch_time = 0.0s | soft_sigma = 2.000 | lr = 7.00e-03\n",
      "Epoch   50 | train‑avg =  15.3353 | soft‑eval =  15.4575 | best =  15.9871 | no_improve =  9 | time = 2s | epoch_time = 0.0s | soft_sigma = 2.000 | lr = 7.00e-03\n",
      "Epoch   60 | train‑avg =  15.7024 | soft‑eval =  15.4162 | best =  15.9871 | no_improve = 19 | time = 2s | epoch_time = 0.0s | soft_sigma = 2.000 | lr = 7.00e-03\n",
      "Epoch   70 | train‑avg =  15.3998 | soft‑eval =  15.5170 | best =  15.9871 | no_improve = 29 | time = 2s | epoch_time = 0.0s | soft_sigma = 2.000 | lr = 7.00e-03\n",
      "Epoch   80 | train‑avg =  15.8775 | soft‑eval =  15.5501 | best =  15.9871 | no_improve = 39 | time = 3s | epoch_time = 0.0s | soft_sigma = 2.000 | lr = 7.00e-03\n",
      "Epoch   90 | train‑avg =  15.3430 | soft‑eval =  15.2633 | best =  15.9871 | no_improve = 49 | time = 3s | epoch_time = 0.0s | soft_sigma = 2.000 | lr = 7.00e-03\n",
      "Epoch  100 | train‑avg =  15.6558 | soft‑eval =  15.4982 | best =  15.9871 | no_improve = 59 | time = 4s | epoch_time = 0.0s | soft_sigma = 2.000 | lr = 7.00e-03\n",
      "Epoch  110 | train‑avg =  15.2571 | soft‑eval =  15.8264 | best =  15.9871 | no_improve = 69 | time = 4s | epoch_time = 0.0s | soft_sigma = 2.000 | lr = 7.00e-03\n",
      "Epoch  120 | train‑avg =  15.3421 | soft‑eval =  15.7176 | best =  15.9871 | no_improve = 79 | time = 4s | epoch_time = 0.0s | soft_sigma = 2.000 | lr = 7.00e-03\n",
      "Epoch  130 | train‑avg =  15.4806 | soft‑eval =  15.5278 | best =  15.9871 | no_improve = 89 | time = 5s | epoch_time = 0.0s | soft_sigma = 2.000 | lr = 7.00e-03\n",
      "Epoch  140 | train‑avg =  15.3241 | soft‑eval =  15.4133 | best =  15.9871 | no_improve = 99 | time = 5s | epoch_time = 0.0s | soft_sigma = 2.000 | lr = 7.00e-03\n",
      "Epoch  150 | train‑avg =  15.6668 | soft‑eval =  15.6752 | best =  15.9871 | no_improve = 109 | time = 6s | epoch_time = 0.0s | soft_sigma = 2.000 | lr = 7.00e-03\n",
      "Epoch  160 | train‑avg =  15.2318 | soft‑eval =  15.2713 | best =  15.9871 | no_improve = 119 | time = 6s | epoch_time = 0.0s | soft_sigma = 2.000 | lr = 7.00e-03\n",
      "Epoch  170 | train‑avg =  15.2317 | soft‑eval =  15.6032 | best =  15.9871 | no_improve = 129 | time = 6s | epoch_time = 0.0s | soft_sigma = 2.000 | lr = 7.00e-03\n",
      "Epoch  180 | train‑avg =  15.7021 | soft‑eval =  15.9085 | best =  15.9871 | no_improve = 139 | time = 7s | epoch_time = 0.0s | soft_sigma = 2.000 | lr = 7.00e-03\n",
      "Epoch  190 | train‑avg =  15.7547 | soft‑eval =  15.2493 | best =  15.9871 | no_improve = 149 | time = 7s | epoch_time = 0.0s | soft_sigma = 2.000 | lr = 7.00e-03\n",
      "Epoch  200 | train‑avg =  15.4787 | soft‑eval =  15.4019 | best =  15.9871 | no_improve = 159 | time = 8s | epoch_time = 0.0s | soft_sigma = 2.000 | lr = 3.50e-03\n",
      "Epoch  210 | train‑avg =  15.7817 | soft‑eval =  15.5523 | best =  15.9871 | no_improve = 169 | time = 9s | epoch_time = 0.0s | soft_sigma = 2.000 | lr = 3.50e-03\n",
      "Epoch  220 | train‑avg =  15.4621 | soft‑eval =  15.8041 | best =  15.9871 | no_improve = 179 | time = 9s | epoch_time = 0.0s | soft_sigma = 2.000 | lr = 3.50e-03\n",
      "Epoch  230 | train‑avg =  15.4275 | soft‑eval =  15.7114 | best =  15.9871 | no_improve = 189 | time = 10s | epoch_time = 0.0s | soft_sigma = 2.000 | lr = 3.50e-03\n",
      "Epoch  240 | train‑avg =  15.6234 | soft‑eval =  15.6227 | best =  15.9871 | no_improve = 199 | time = 10s | epoch_time = 0.0s | soft_sigma = 2.000 | lr = 3.50e-03\n",
      "Early stopping triggered after 241 epochs (10s)\n",
      "Best score: 15.987082\n",
      "No improvement for 200 epochs\n",
      "\n",
      "Training completed after 240 epochs\n",
      "Total training time: 10s\n",
      "Average time per epoch: 0.0s\n",
      "Best evaluation score: 15.987082\n",
      "Final score: 15.622731\n",
      "\n",
      "Evaluating final policy...\n",
      "Sharp policy price ≈ 15.5452  CI: [15.5292,15.5613] (95% CI)\n",
      "Setting up input normalization...\n",
      "Starting training with early stopping (patience=200, min_epochs=50)\n",
      "Will stop when improvement < 1.00e-02 absolute or < 1.00e-03 relative\n",
      "Epoch   10 | train‑avg =  15.2552 | soft‑eval =  15.5142 | best =  15.2890 | no_improve =  0 | time = 0s | epoch_time = 0.0s | soft_sigma = 2.000 | lr = 7.00e-03\n",
      "Epoch   20 | train‑avg =  15.1910 | soft‑eval =  15.6228 | best =  15.5283 | no_improve =  3 | time = 0s | epoch_time = 0.0s | soft_sigma = 2.000 | lr = 7.00e-03\n",
      "Epoch   30 | train‑avg =  15.2599 | soft‑eval =  15.3256 | best =  15.7838 | no_improve =  5 | time = 1s | epoch_time = 0.0s | soft_sigma = 2.000 | lr = 7.00e-03\n",
      "Epoch   40 | train‑avg =  15.5797 | soft‑eval =  15.6373 | best =  15.7838 | no_improve = 15 | time = 1s | epoch_time = 0.0s | soft_sigma = 2.000 | lr = 7.00e-03\n",
      "Epoch   50 | train‑avg =  15.3837 | soft‑eval =  15.4740 | best =  15.7838 | no_improve = 25 | time = 1s | epoch_time = 0.0s | soft_sigma = 2.000 | lr = 7.00e-03\n",
      "Epoch   60 | train‑avg =  15.7727 | soft‑eval =  15.9280 | best =  15.7838 | no_improve = 35 | time = 2s | epoch_time = 0.0s | soft_sigma = 2.000 | lr = 7.00e-03\n",
      "Epoch   70 | train‑avg =  15.1130 | soft‑eval =  15.6860 | best =  15.9280 | no_improve =  9 | time = 2s | epoch_time = 0.0s | soft_sigma = 2.000 | lr = 7.00e-03\n",
      "Epoch   80 | train‑avg =  15.7358 | soft‑eval =  15.5817 | best =  15.9280 | no_improve = 19 | time = 3s | epoch_time = 0.0s | soft_sigma = 2.000 | lr = 7.00e-03\n",
      "Epoch   90 | train‑avg =  15.5528 | soft‑eval =  15.6197 | best =  15.9280 | no_improve = 29 | time = 3s | epoch_time = 0.0s | soft_sigma = 2.000 | lr = 7.00e-03\n",
      "Epoch  100 | train‑avg =  15.4404 | soft‑eval =  15.4801 | best =  15.9280 | no_improve = 39 | time = 3s | epoch_time = 0.0s | soft_sigma = 2.000 | lr = 7.00e-03\n",
      "Epoch  110 | train‑avg =  15.4832 | soft‑eval =  15.2646 | best =  15.9280 | no_improve = 49 | time = 4s | epoch_time = 0.0s | soft_sigma = 2.000 | lr = 7.00e-03\n",
      "Epoch  120 | train‑avg =  15.5558 | soft‑eval =  15.6312 | best =  15.9280 | no_improve = 59 | time = 4s | epoch_time = 0.0s | soft_sigma = 2.000 | lr = 7.00e-03\n",
      "Epoch  130 | train‑avg =  15.5119 | soft‑eval =  15.5263 | best =  15.9280 | no_improve = 69 | time = 5s | epoch_time = 0.0s | soft_sigma = 2.000 | lr = 7.00e-03\n",
      "Epoch  140 | train‑avg =  15.3086 | soft‑eval =  15.8345 | best =  15.9280 | no_improve = 79 | time = 5s | epoch_time = 0.0s | soft_sigma = 2.000 | lr = 7.00e-03\n",
      "Epoch  150 | train‑avg =  15.5405 | soft‑eval =  15.5079 | best =  15.9280 | no_improve = 89 | time = 5s | epoch_time = 0.0s | soft_sigma = 2.000 | lr = 7.00e-03\n",
      "Epoch  160 | train‑avg =  15.2962 | soft‑eval =  14.9848 | best =  15.9280 | no_improve = 99 | time = 6s | epoch_time = 0.0s | soft_sigma = 2.000 | lr = 7.00e-03\n",
      "Epoch  170 | train‑avg =  15.7231 | soft‑eval =  15.6662 | best =  15.9280 | no_improve = 109 | time = 6s | epoch_time = 0.0s | soft_sigma = 2.000 | lr = 7.00e-03\n",
      "Epoch  180 | train‑avg =  15.5525 | soft‑eval =  15.2637 | best =  15.9280 | no_improve = 119 | time = 7s | epoch_time = 0.0s | soft_sigma = 2.000 | lr = 7.00e-03\n",
      "Epoch  190 | train‑avg =  15.6755 | soft‑eval =  15.9112 | best =  15.9280 | no_improve = 129 | time = 7s | epoch_time = 0.0s | soft_sigma = 2.000 | lr = 7.00e-03\n",
      "Epoch  200 | train‑avg =  15.2918 | soft‑eval =  15.6132 | best =  15.9280 | no_improve = 139 | time = 7s | epoch_time = 0.0s | soft_sigma = 2.000 | lr = 7.00e-03\n",
      "Epoch  210 | train‑avg =  15.5020 | soft‑eval =  15.3904 | best =  15.9280 | no_improve = 149 | time = 8s | epoch_time = 0.0s | soft_sigma = 2.000 | lr = 7.00e-03\n",
      "Epoch  220 | train‑avg =  15.5444 | soft‑eval =  15.5321 | best =  15.9280 | no_improve = 159 | time = 8s | epoch_time = 0.0s | soft_sigma = 2.000 | lr = 3.50e-03\n",
      "Epoch  230 | train‑avg =  15.6793 | soft‑eval =  15.7935 | best =  15.9280 | no_improve = 169 | time = 9s | epoch_time = 0.0s | soft_sigma = 2.000 | lr = 3.50e-03\n",
      "Epoch  240 | train‑avg =  15.5361 | soft‑eval =  15.1299 | best =  15.9280 | no_improve = 179 | time = 9s | epoch_time = 0.0s | soft_sigma = 2.000 | lr = 3.50e-03\n",
      "Epoch  250 | train‑avg =  15.6058 | soft‑eval =  15.4488 | best =  15.9280 | no_improve = 189 | time = 9s | epoch_time = 0.0s | soft_sigma = 2.000 | lr = 3.50e-03\n",
      "Epoch  260 | train‑avg =  15.5009 | soft‑eval =  15.5333 | best =  16.0065 | no_improve =  2 | time = 10s | epoch_time = 0.0s | soft_sigma = 2.000 | lr = 3.50e-03\n",
      "Epoch  270 | train‑avg =  15.7270 | soft‑eval =  15.7555 | best =  16.0065 | no_improve = 12 | time = 10s | epoch_time = 0.0s | soft_sigma = 2.000 | lr = 3.50e-03\n",
      "Epoch  280 | train‑avg =  15.6274 | soft‑eval =  15.5367 | best =  16.0065 | no_improve = 22 | time = 11s | epoch_time = 0.0s | soft_sigma = 2.000 | lr = 3.50e-03\n",
      "Epoch  290 | train‑avg =  15.7528 | soft‑eval =  15.4996 | best =  16.0065 | no_improve = 32 | time = 11s | epoch_time = 0.0s | soft_sigma = 2.000 | lr = 3.50e-03\n",
      "Epoch  300 | train‑avg =  15.7284 | soft‑eval =  15.6904 | best =  16.0065 | no_improve = 42 | time = 11s | epoch_time = 0.0s | soft_sigma = 2.000 | lr = 3.50e-03\n",
      "Epoch  310 | train‑avg =  15.5251 | soft‑eval =  15.5019 | best =  16.0065 | no_improve = 52 | time = 12s | epoch_time = 0.0s | soft_sigma = 2.000 | lr = 3.50e-03\n",
      "Epoch  320 | train‑avg =  15.5797 | soft‑eval =  15.3826 | best =  16.0065 | no_improve = 62 | time = 12s | epoch_time = 0.0s | soft_sigma = 2.000 | lr = 3.50e-03\n",
      "Epoch  330 | train‑avg =  15.4132 | soft‑eval =  15.5896 | best =  16.0065 | no_improve = 72 | time = 13s | epoch_time = 0.0s | soft_sigma = 2.000 | lr = 3.50e-03\n",
      "Epoch  340 | train‑avg =  15.8991 | soft‑eval =  15.9385 | best =  16.0065 | no_improve = 82 | time = 13s | epoch_time = 0.0s | soft_sigma = 2.000 | lr = 3.50e-03\n",
      "Epoch  350 | train‑avg =  15.5207 | soft‑eval =  15.6223 | best =  16.0065 | no_improve = 92 | time = 13s | epoch_time = 0.0s | soft_sigma = 2.000 | lr = 3.50e-03\n",
      "Epoch  360 | train‑avg =  15.3689 | soft‑eval =  15.5278 | best =  16.0065 | no_improve = 102 | time = 14s | epoch_time = 0.0s | soft_sigma = 2.000 | lr = 3.50e-03\n",
      "Epoch  370 | train‑avg =  15.1503 | soft‑eval =  15.7958 | best =  16.0065 | no_improve = 112 | time = 14s | epoch_time = 0.0s | soft_sigma = 2.000 | lr = 3.50e-03\n",
      "Epoch  380 | train‑avg =  15.5164 | soft‑eval =  15.5012 | best =  16.0065 | no_improve = 122 | time = 15s | epoch_time = 0.0s | soft_sigma = 2.000 | lr = 3.50e-03\n",
      "Epoch  390 | train‑avg =  15.2425 | soft‑eval =  15.3356 | best =  16.2172 | no_improve =  1 | time = 15s | epoch_time = 0.0s | soft_sigma = 2.000 | lr = 3.50e-03\n",
      "Epoch  400 | train‑avg =  15.3259 | soft‑eval =  15.5956 | best =  16.2172 | no_improve = 11 | time = 15s | epoch_time = 0.0s | soft_sigma = 2.000 | lr = 3.50e-03\n",
      "Epoch  410 | train‑avg =  15.4173 | soft‑eval =  15.6042 | best =  16.2172 | no_improve = 21 | time = 16s | epoch_time = 0.0s | soft_sigma = 2.000 | lr = 3.50e-03\n",
      "Epoch  420 | train‑avg =  15.6230 | soft‑eval =  15.5093 | best =  16.2172 | no_improve = 31 | time = 16s | epoch_time = 0.0s | soft_sigma = 2.000 | lr = 3.50e-03\n",
      "Epoch  430 | train‑avg =  15.5097 | soft‑eval =  15.3090 | best =  16.2172 | no_improve = 41 | time = 17s | epoch_time = 0.0s | soft_sigma = 2.000 | lr = 3.50e-03\n",
      "Epoch  440 | train‑avg =  15.5344 | soft‑eval =  15.6600 | best =  16.2172 | no_improve = 51 | time = 17s | epoch_time = 0.0s | soft_sigma = 2.000 | lr = 3.50e-03\n",
      "Epoch  450 | train‑avg =  15.4125 | soft‑eval =  15.4799 | best =  16.2172 | no_improve = 61 | time = 17s | epoch_time = 0.0s | soft_sigma = 2.000 | lr = 3.50e-03\n",
      "Epoch  460 | train‑avg =  15.4769 | soft‑eval =  15.4353 | best =  16.2172 | no_improve = 71 | time = 18s | epoch_time = 0.0s | soft_sigma = 2.000 | lr = 3.50e-03\n",
      "Epoch  470 | train‑avg =  15.2724 | soft‑eval =  15.7526 | best =  16.2172 | no_improve = 81 | time = 18s | epoch_time = 0.0s | soft_sigma = 2.000 | lr = 3.50e-03\n",
      "Epoch  480 | train‑avg =  15.5560 | soft‑eval =  15.5932 | best =  16.2172 | no_improve = 91 | time = 18s | epoch_time = 0.0s | soft_sigma = 2.000 | lr = 3.50e-03\n",
      "Epoch  490 | train‑avg =  15.4730 | soft‑eval =  15.4411 | best =  16.2172 | no_improve = 101 | time = 19s | epoch_time = 0.0s | soft_sigma = 2.000 | lr = 3.50e-03\n",
      "Epoch  500 | train‑avg =  15.6888 | soft‑eval =  16.1212 | best =  16.2172 | no_improve = 111 | time = 19s | epoch_time = 0.0s | soft_sigma = 2.000 | lr = 3.50e-03\n",
      "Epoch  510 | train‑avg =  15.4216 | soft‑eval =  15.7054 | best =  16.2172 | no_improve = 121 | time = 20s | epoch_time = 0.0s | soft_sigma = 2.000 | lr = 3.50e-03\n",
      "Epoch  520 | train‑avg =  15.9176 | soft‑eval =  15.5843 | best =  16.2172 | no_improve = 131 | time = 20s | epoch_time = 0.0s | soft_sigma = 2.000 | lr = 3.50e-03\n",
      "Epoch  530 | train‑avg =  15.2136 | soft‑eval =  15.5657 | best =  16.2172 | no_improve = 141 | time = 20s | epoch_time = 0.0s | soft_sigma = 2.000 | lr = 3.50e-03\n",
      "Epoch  540 | train‑avg =  15.6274 | soft‑eval =  15.3591 | best =  16.2172 | no_improve = 151 | time = 21s | epoch_time = 0.0s | soft_sigma = 2.000 | lr = 3.50e-03\n",
      "Epoch  550 | train‑avg =  15.5869 | soft‑eval =  15.6538 | best =  16.2172 | no_improve = 161 | time = 21s | epoch_time = 0.0s | soft_sigma = 2.000 | lr = 3.50e-03\n",
      "Epoch  560 | train‑avg =  15.8828 | soft‑eval =  15.3274 | best =  16.2172 | no_improve = 171 | time = 21s | epoch_time = 0.0s | soft_sigma = 2.000 | lr = 3.50e-03\n",
      "Epoch  570 | train‑avg =  15.5563 | soft‑eval =  15.3999 | best =  16.2172 | no_improve = 181 | time = 22s | epoch_time = 0.0s | soft_sigma = 2.000 | lr = 3.50e-03\n",
      "Epoch  580 | train‑avg =  15.3194 | soft‑eval =  15.7435 | best =  16.2172 | no_improve = 191 | time = 22s | epoch_time = 0.0s | soft_sigma = 2.000 | lr = 3.50e-03\n",
      "Early stopping triggered after 589 epochs (23s)\n",
      "Best score: 16.217174\n",
      "No improvement for 200 epochs\n",
      "\n",
      "Training completed after 588 epochs\n",
      "Total training time: 23s\n",
      "Average time per epoch: 0.0s\n",
      "Best evaluation score: 16.217174\n",
      "Final score: 15.971078\n",
      "\n",
      "Evaluating final policy...\n",
      "Sharp policy price ≈ 15.5427  CI: [15.5272,15.5582] (95% CI)\n",
      "Setting up input normalization...\n",
      "Starting training with early stopping (patience=200, min_epochs=50)\n",
      "Will stop when improvement < 1.00e-02 absolute or < 1.00e-03 relative\n",
      "Epoch   10 | train‑avg =  15.4210 | soft‑eval =  15.2151 | best =  15.3133 | no_improve =  2 | time = 0s | epoch_time = 0.1s | soft_sigma = 2.000 | lr = 7.00e-03\n",
      "Epoch   20 | train‑avg =  15.4759 | soft‑eval =  15.6432 | best =  15.6727 | no_improve =  0 | time = 0s | epoch_time = 0.0s | soft_sigma = 2.000 | lr = 7.00e-03\n",
      "Epoch   30 | train‑avg =  15.6483 | soft‑eval =  15.3928 | best =  15.7121 | no_improve =  7 | time = 1s | epoch_time = 0.0s | soft_sigma = 2.000 | lr = 7.00e-03\n",
      "Epoch   40 | train‑avg =  15.2813 | soft‑eval =  15.6709 | best =  15.9870 | no_improve =  2 | time = 1s | epoch_time = 0.0s | soft_sigma = 2.000 | lr = 7.00e-03\n",
      "Epoch   50 | train‑avg =  15.3373 | soft‑eval =  15.7587 | best =  15.9870 | no_improve = 12 | time = 2s | epoch_time = 0.0s | soft_sigma = 2.000 | lr = 7.00e-03\n",
      "Epoch   60 | train‑avg =  15.4070 | soft‑eval =  15.6099 | best =  15.9870 | no_improve = 22 | time = 2s | epoch_time = 0.0s | soft_sigma = 2.000 | lr = 7.00e-03\n",
      "Epoch   70 | train‑avg =  15.7306 | soft‑eval =  15.4801 | best =  15.9870 | no_improve = 32 | time = 2s | epoch_time = 0.0s | soft_sigma = 2.000 | lr = 7.00e-03\n",
      "Epoch   80 | train‑avg =  15.6783 | soft‑eval =  15.7124 | best =  16.0612 | no_improve =  4 | time = 3s | epoch_time = 0.0s | soft_sigma = 2.000 | lr = 7.00e-03\n",
      "Epoch   90 | train‑avg =  15.7147 | soft‑eval =  15.4450 | best =  16.0612 | no_improve = 14 | time = 3s | epoch_time = 0.0s | soft_sigma = 2.000 | lr = 7.00e-03\n",
      "Epoch  100 | train‑avg =  15.5149 | soft‑eval =  15.7152 | best =  16.0612 | no_improve = 24 | time = 4s | epoch_time = 0.0s | soft_sigma = 2.000 | lr = 7.00e-03\n",
      "Epoch  110 | train‑avg =  15.3669 | soft‑eval =  15.6882 | best =  16.0612 | no_improve = 34 | time = 4s | epoch_time = 0.0s | soft_sigma = 2.000 | lr = 7.00e-03\n",
      "Epoch  120 | train‑avg =  15.1312 | soft‑eval =  15.2998 | best =  16.0612 | no_improve = 44 | time = 4s | epoch_time = 0.0s | soft_sigma = 2.000 | lr = 7.00e-03\n",
      "Epoch  130 | train‑avg =  15.5332 | soft‑eval =  15.9088 | best =  16.0612 | no_improve = 54 | time = 5s | epoch_time = 0.0s | soft_sigma = 2.000 | lr = 7.00e-03\n",
      "Epoch  140 | train‑avg =  15.7178 | soft‑eval =  15.5268 | best =  16.0612 | no_improve = 64 | time = 5s | epoch_time = 0.0s | soft_sigma = 2.000 | lr = 7.00e-03\n",
      "Epoch  150 | train‑avg =  15.1887 | soft‑eval =  15.5446 | best =  16.0612 | no_improve = 74 | time = 6s | epoch_time = 0.0s | soft_sigma = 2.000 | lr = 7.00e-03\n",
      "Epoch  160 | train‑avg =  15.1692 | soft‑eval =  15.5487 | best =  16.0612 | no_improve = 84 | time = 6s | epoch_time = 0.0s | soft_sigma = 2.000 | lr = 7.00e-03\n",
      "Epoch  170 | train‑avg =  15.5329 | soft‑eval =  15.4546 | best =  16.0612 | no_improve = 94 | time = 7s | epoch_time = 0.0s | soft_sigma = 2.000 | lr = 7.00e-03\n",
      "Epoch  180 | train‑avg =  15.2734 | soft‑eval =  15.4597 | best =  16.0612 | no_improve = 104 | time = 7s | epoch_time = 0.0s | soft_sigma = 2.000 | lr = 7.00e-03\n",
      "Epoch  190 | train‑avg =  15.4047 | soft‑eval =  15.6513 | best =  16.0612 | no_improve = 114 | time = 7s | epoch_time = 0.0s | soft_sigma = 2.000 | lr = 7.00e-03\n",
      "Epoch  200 | train‑avg =  15.3995 | soft‑eval =  15.4922 | best =  16.0612 | no_improve = 124 | time = 8s | epoch_time = 0.0s | soft_sigma = 2.000 | lr = 7.00e-03\n",
      "Epoch  210 | train‑avg =  15.3962 | soft‑eval =  15.5948 | best =  16.0612 | no_improve = 134 | time = 8s | epoch_time = 0.0s | soft_sigma = 2.000 | lr = 7.00e-03\n",
      "Epoch  220 | train‑avg =  15.5572 | soft‑eval =  15.4905 | best =  16.0612 | no_improve = 144 | time = 9s | epoch_time = 0.0s | soft_sigma = 2.000 | lr = 7.00e-03\n",
      "Epoch  230 | train‑avg =  15.4373 | soft‑eval =  15.6019 | best =  16.0612 | no_improve = 154 | time = 9s | epoch_time = 0.0s | soft_sigma = 2.000 | lr = 7.00e-03\n",
      "Epoch  240 | train‑avg =  15.2955 | soft‑eval =  15.6770 | best =  16.0612 | no_improve = 164 | time = 9s | epoch_time = 0.0s | soft_sigma = 2.000 | lr = 7.00e-03\n",
      "Epoch  250 | train‑avg =  15.7557 | soft‑eval =  15.3814 | best =  16.0612 | no_improve = 174 | time = 10s | epoch_time = 0.0s | soft_sigma = 2.000 | lr = 7.00e-03\n",
      "Epoch  260 | train‑avg =  15.6232 | soft‑eval =  15.4624 | best =  16.0612 | no_improve = 184 | time = 10s | epoch_time = 0.0s | soft_sigma = 2.000 | lr = 7.00e-03\n",
      "Epoch  270 | train‑avg =  15.4833 | soft‑eval =  15.8310 | best =  16.0612 | no_improve = 194 | time = 11s | epoch_time = 0.0s | soft_sigma = 2.000 | lr = 7.00e-03\n",
      "Early stopping triggered after 276 epochs (11s)\n",
      "Best score: 16.061205\n",
      "No improvement for 200 epochs\n",
      "\n",
      "Training completed after 275 epochs\n",
      "Total training time: 11s\n",
      "Average time per epoch: 0.0s\n",
      "Best evaluation score: 16.061205\n",
      "Final score: 15.473031\n",
      "\n",
      "Evaluating final policy...\n",
      "Sharp policy price ≈ 15.5410  CI: [15.5247,15.5572] (95% CI)\n",
      "Setting up input normalization...\n",
      "Starting training with early stopping (patience=200, min_epochs=50)\n",
      "Will stop when improvement < 1.00e-02 absolute or < 1.00e-03 relative\n",
      "Epoch   10 | train‑avg =  15.4550 | soft‑eval =  15.4907 | best =  15.6962 | no_improve =  0 | time = 0s | epoch_time = 0.0s | soft_sigma = 2.000 | lr = 7.00e-03\n",
      "Epoch   20 | train‑avg =  15.4148 | soft‑eval =  15.4857 | best =  15.6962 | no_improve = 10 | time = 0s | epoch_time = 0.0s | soft_sigma = 2.000 | lr = 7.00e-03\n",
      "Epoch   30 | train‑avg =  15.4885 | soft‑eval =  15.4966 | best =  15.6962 | no_improve = 20 | time = 1s | epoch_time = 0.0s | soft_sigma = 2.000 | lr = 7.00e-03\n",
      "Epoch   40 | train‑avg =  15.3362 | soft‑eval =  15.7043 | best =  15.9740 | no_improve =  0 | time = 1s | epoch_time = 0.0s | soft_sigma = 2.000 | lr = 7.00e-03\n",
      "Epoch   50 | train‑avg =  15.5523 | soft‑eval =  15.6147 | best =  15.9740 | no_improve = 10 | time = 2s | epoch_time = 0.0s | soft_sigma = 2.000 | lr = 7.00e-03\n",
      "Epoch   60 | train‑avg =  15.3531 | soft‑eval =  15.4039 | best =  15.9740 | no_improve = 20 | time = 2s | epoch_time = 0.0s | soft_sigma = 2.000 | lr = 7.00e-03\n",
      "Epoch   70 | train‑avg =  15.1430 | soft‑eval =  15.3838 | best =  15.9740 | no_improve = 30 | time = 3s | epoch_time = 0.0s | soft_sigma = 2.000 | lr = 7.00e-03\n",
      "Epoch   80 | train‑avg =  15.3936 | soft‑eval =  15.7778 | best =  15.9740 | no_improve = 40 | time = 3s | epoch_time = 0.0s | soft_sigma = 2.000 | lr = 7.00e-03\n",
      "Epoch   90 | train‑avg =  15.3771 | soft‑eval =  15.5804 | best =  15.9740 | no_improve = 50 | time = 3s | epoch_time = 0.0s | soft_sigma = 2.000 | lr = 7.00e-03\n",
      "Epoch  100 | train‑avg =  15.5532 | soft‑eval =  15.3559 | best =  15.9740 | no_improve = 60 | time = 4s | epoch_time = 0.0s | soft_sigma = 2.000 | lr = 7.00e-03\n",
      "Epoch  110 | train‑avg =  15.5731 | soft‑eval =  15.5527 | best =  16.0480 | no_improve =  2 | time = 4s | epoch_time = 0.0s | soft_sigma = 2.000 | lr = 7.00e-03\n",
      "Epoch  120 | train‑avg =  15.2054 | soft‑eval =  15.5584 | best =  16.0480 | no_improve = 12 | time = 5s | epoch_time = 0.0s | soft_sigma = 2.000 | lr = 7.00e-03\n",
      "Epoch  130 | train‑avg =  15.4443 | soft‑eval =  15.4337 | best =  16.0480 | no_improve = 22 | time = 5s | epoch_time = 0.0s | soft_sigma = 2.000 | lr = 7.00e-03\n",
      "Epoch  140 | train‑avg =  15.1708 | soft‑eval =  15.3181 | best =  16.0480 | no_improve = 32 | time = 5s | epoch_time = 0.0s | soft_sigma = 2.000 | lr = 7.00e-03\n",
      "Epoch  150 | train‑avg =  15.5117 | soft‑eval =  15.4375 | best =  16.0480 | no_improve = 42 | time = 6s | epoch_time = 0.0s | soft_sigma = 2.000 | lr = 7.00e-03\n",
      "Epoch  160 | train‑avg =  15.5896 | soft‑eval =  15.3907 | best =  16.0480 | no_improve = 52 | time = 6s | epoch_time = 0.0s | soft_sigma = 2.000 | lr = 7.00e-03\n",
      "Epoch  170 | train‑avg =  15.4218 | soft‑eval =  15.6914 | best =  16.0480 | no_improve = 62 | time = 7s | epoch_time = 0.0s | soft_sigma = 2.000 | lr = 7.00e-03\n",
      "Epoch  180 | train‑avg =  15.3984 | soft‑eval =  15.5443 | best =  16.0480 | no_improve = 72 | time = 7s | epoch_time = 0.0s | soft_sigma = 2.000 | lr = 7.00e-03\n",
      "Epoch  190 | train‑avg =  15.7441 | soft‑eval =  15.3647 | best =  16.0480 | no_improve = 82 | time = 7s | epoch_time = 0.0s | soft_sigma = 2.000 | lr = 7.00e-03\n",
      "Epoch  200 | train‑avg =  15.5571 | soft‑eval =  15.6376 | best =  16.0480 | no_improve = 92 | time = 8s | epoch_time = 0.0s | soft_sigma = 2.000 | lr = 7.00e-03\n",
      "Epoch  210 | train‑avg =  15.4176 | soft‑eval =  15.6229 | best =  16.0480 | no_improve = 102 | time = 8s | epoch_time = 0.0s | soft_sigma = 2.000 | lr = 7.00e-03\n",
      "Epoch  220 | train‑avg =  15.8455 | soft‑eval =  15.2123 | best =  16.0480 | no_improve = 112 | time = 9s | epoch_time = 0.0s | soft_sigma = 2.000 | lr = 7.00e-03\n",
      "Epoch  230 | train‑avg =  15.5464 | soft‑eval =  15.6573 | best =  16.0480 | no_improve = 122 | time = 9s | epoch_time = 0.0s | soft_sigma = 2.000 | lr = 7.00e-03\n",
      "Epoch  240 | train‑avg =  15.6252 | soft‑eval =  15.8700 | best =  16.0480 | no_improve = 132 | time = 9s | epoch_time = 0.0s | soft_sigma = 2.000 | lr = 7.00e-03\n",
      "Epoch  250 | train‑avg =  15.6605 | soft‑eval =  15.6040 | best =  16.0480 | no_improve = 142 | time = 10s | epoch_time = 0.0s | soft_sigma = 2.000 | lr = 7.00e-03\n",
      "Epoch  260 | train‑avg =  15.4869 | soft‑eval =  15.2473 | best =  16.0480 | no_improve = 152 | time = 10s | epoch_time = 0.0s | soft_sigma = 2.000 | lr = 7.00e-03\n",
      "Epoch  270 | train‑avg =  15.7793 | soft‑eval =  15.5858 | best =  16.0480 | no_improve = 162 | time = 11s | epoch_time = 0.0s | soft_sigma = 2.000 | lr = 7.00e-03\n",
      "Epoch  280 | train‑avg =  15.1942 | soft‑eval =  15.2062 | best =  16.0480 | no_improve = 172 | time = 11s | epoch_time = 0.0s | soft_sigma = 2.000 | lr = 7.00e-03\n",
      "Epoch  290 | train‑avg =  15.3358 | soft‑eval =  15.2230 | best =  16.0480 | no_improve = 182 | time = 11s | epoch_time = 0.0s | soft_sigma = 2.000 | lr = 7.00e-03\n",
      "Epoch  300 | train‑avg =  15.6359 | soft‑eval =  15.3068 | best =  16.0480 | no_improve = 192 | time = 12s | epoch_time = 0.0s | soft_sigma = 2.000 | lr = 7.00e-03\n",
      "Early stopping triggered after 308 epochs (12s)\n",
      "Best score: 16.048025\n",
      "No improvement for 200 epochs\n",
      "\n",
      "Training completed after 307 epochs\n",
      "Total training time: 12s\n",
      "Average time per epoch: 0.0s\n",
      "Best evaluation score: 16.048025\n",
      "Final score: 15.431336\n",
      "\n",
      "Evaluating final policy...\n",
      "Sharp policy price ≈ 15.5480  CI: [15.5320,15.5640] (95% CI)\n",
      "Setting up input normalization...\n",
      "Starting training with early stopping (patience=200, min_epochs=50)\n",
      "Will stop when improvement < 1.00e-02 absolute or < 1.00e-03 relative\n",
      "Epoch   10 | train‑avg =  15.3322 | soft‑eval =  15.6026 | best =  15.3232 | no_improve =  3 | time = 0s | epoch_time = 0.0s | soft_sigma = 2.000 | lr = 7.00e-03\n",
      "Epoch   20 | train‑avg =  15.4716 | soft‑eval =  15.5844 | best =  15.6936 | no_improve =  1 | time = 0s | epoch_time = 0.0s | soft_sigma = 2.000 | lr = 7.00e-03\n",
      "Epoch   30 | train‑avg =  15.5771 | soft‑eval =  15.4338 | best =  15.7535 | no_improve =  2 | time = 1s | epoch_time = 0.0s | soft_sigma = 2.000 | lr = 7.00e-03\n",
      "Epoch   40 | train‑avg =  15.2269 | soft‑eval =  15.5716 | best =  15.7535 | no_improve = 12 | time = 1s | epoch_time = 0.0s | soft_sigma = 2.000 | lr = 7.00e-03\n",
      "Epoch   50 | train‑avg =  15.7442 | soft‑eval =  15.3308 | best =  15.8945 | no_improve =  7 | time = 1s | epoch_time = 0.0s | soft_sigma = 2.000 | lr = 7.00e-03\n",
      "Epoch   60 | train‑avg =  15.6738 | soft‑eval =  15.5937 | best =  15.8945 | no_improve = 17 | time = 2s | epoch_time = 0.0s | soft_sigma = 2.000 | lr = 7.00e-03\n",
      "Epoch   70 | train‑avg =  15.5945 | soft‑eval =  15.7066 | best =  15.8945 | no_improve = 27 | time = 2s | epoch_time = 0.0s | soft_sigma = 2.000 | lr = 7.00e-03\n",
      "Epoch   80 | train‑avg =  15.4264 | soft‑eval =  15.4673 | best =  15.8945 | no_improve = 37 | time = 3s | epoch_time = 0.0s | soft_sigma = 2.000 | lr = 7.00e-03\n",
      "Epoch   90 | train‑avg =  15.3676 | soft‑eval =  15.9645 | best =  15.8945 | no_improve = 47 | time = 3s | epoch_time = 0.0s | soft_sigma = 2.000 | lr = 7.00e-03\n",
      "Epoch  100 | train‑avg =  15.7452 | soft‑eval =  15.7094 | best =  15.9645 | no_improve =  9 | time = 3s | epoch_time = 0.0s | soft_sigma = 2.000 | lr = 7.00e-03\n",
      "Epoch  110 | train‑avg =  15.4743 | soft‑eval =  15.4176 | best =  15.9645 | no_improve = 19 | time = 4s | epoch_time = 0.0s | soft_sigma = 2.000 | lr = 7.00e-03\n",
      "Epoch  120 | train‑avg =  15.7484 | soft‑eval =  15.4268 | best =  15.9645 | no_improve = 29 | time = 4s | epoch_time = 0.0s | soft_sigma = 2.000 | lr = 7.00e-03\n",
      "Epoch  130 | train‑avg =  15.3848 | soft‑eval =  15.4642 | best =  15.9645 | no_improve = 39 | time = 4s | epoch_time = 0.0s | soft_sigma = 2.000 | lr = 7.00e-03\n",
      "Epoch  140 | train‑avg =  15.5389 | soft‑eval =  15.4515 | best =  15.9645 | no_improve = 49 | time = 5s | epoch_time = 0.0s | soft_sigma = 2.000 | lr = 7.00e-03\n",
      "Epoch  150 | train‑avg =  15.6685 | soft‑eval =  15.5214 | best =  15.9645 | no_improve = 59 | time = 5s | epoch_time = 0.0s | soft_sigma = 2.000 | lr = 7.00e-03\n",
      "Epoch  160 | train‑avg =  15.8291 | soft‑eval =  15.3035 | best =  15.9645 | no_improve = 69 | time = 6s | epoch_time = 0.0s | soft_sigma = 2.000 | lr = 7.00e-03\n",
      "Epoch  170 | train‑avg =  15.4654 | soft‑eval =  15.2492 | best =  15.9645 | no_improve = 79 | time = 6s | epoch_time = 0.0s | soft_sigma = 2.000 | lr = 7.00e-03\n",
      "Epoch  180 | train‑avg =  15.6611 | soft‑eval =  15.5874 | best =  15.9645 | no_improve = 89 | time = 6s | epoch_time = 0.0s | soft_sigma = 2.000 | lr = 7.00e-03\n",
      "Epoch  190 | train‑avg =  15.5732 | soft‑eval =  15.0887 | best =  15.9645 | no_improve = 99 | time = 7s | epoch_time = 0.0s | soft_sigma = 2.000 | lr = 7.00e-03\n",
      "Epoch  200 | train‑avg =  15.6252 | soft‑eval =  15.3167 | best =  15.9645 | no_improve = 109 | time = 7s | epoch_time = 0.0s | soft_sigma = 2.000 | lr = 7.00e-03\n",
      "Epoch  210 | train‑avg =  15.5791 | soft‑eval =  15.4700 | best =  15.9645 | no_improve = 119 | time = 8s | epoch_time = 0.0s | soft_sigma = 2.000 | lr = 7.00e-03\n",
      "Epoch  220 | train‑avg =  15.6130 | soft‑eval =  15.5187 | best =  15.9645 | no_improve = 129 | time = 8s | epoch_time = 0.0s | soft_sigma = 2.000 | lr = 7.00e-03\n",
      "Epoch  230 | train‑avg =  15.5196 | soft‑eval =  15.7901 | best =  15.9645 | no_improve = 139 | time = 8s | epoch_time = 0.0s | soft_sigma = 2.000 | lr = 7.00e-03\n",
      "Epoch  240 | train‑avg =  15.2472 | soft‑eval =  15.4479 | best =  15.9645 | no_improve = 149 | time = 9s | epoch_time = 0.0s | soft_sigma = 2.000 | lr = 7.00e-03\n",
      "Epoch  250 | train‑avg =  15.1809 | soft‑eval =  15.3234 | best =  15.9645 | no_improve = 159 | time = 9s | epoch_time = 0.0s | soft_sigma = 2.000 | lr = 3.50e-03\n",
      "Epoch  260 | train‑avg =  15.4785 | soft‑eval =  15.3296 | best =  15.9645 | no_improve = 169 | time = 10s | epoch_time = 0.0s | soft_sigma = 2.000 | lr = 3.50e-03\n",
      "Epoch  270 | train‑avg =  15.2512 | soft‑eval =  15.7740 | best =  15.9645 | no_improve = 179 | time = 10s | epoch_time = 0.0s | soft_sigma = 2.000 | lr = 3.50e-03\n",
      "Epoch  280 | train‑avg =  15.6670 | soft‑eval =  15.3830 | best =  15.9645 | no_improve = 189 | time = 10s | epoch_time = 0.0s | soft_sigma = 2.000 | lr = 3.50e-03\n",
      "Epoch  290 | train‑avg =  15.3575 | soft‑eval =  15.4680 | best =  15.9645 | no_improve = 199 | time = 11s | epoch_time = 0.0s | soft_sigma = 2.000 | lr = 3.50e-03\n",
      "Early stopping triggered after 291 epochs (11s)\n",
      "Best score: 15.964540\n",
      "No improvement for 200 epochs\n",
      "\n",
      "Training completed after 290 epochs\n",
      "Total training time: 11s\n",
      "Average time per epoch: 0.0s\n",
      "Best evaluation score: 15.964540\n",
      "Final score: 15.467983\n",
      "\n",
      "Evaluating final policy...\n",
      "Sharp policy price ≈ 15.5449  CI: [15.5289,15.5609] (95% CI)\n",
      "Setting up input normalization...\n",
      "Starting training with early stopping (patience=200, min_epochs=50)\n",
      "Will stop when improvement < 1.00e-02 absolute or < 1.00e-03 relative\n",
      "Epoch   10 | train‑avg =  15.4680 | soft‑eval =  15.4093 | best =  15.5242 | no_improve =  0 | time = 0s | epoch_time = 0.1s | soft_sigma = 2.000 | lr = 7.00e-03\n",
      "Epoch   20 | train‑avg =  15.3455 | soft‑eval =  15.7610 | best =  15.5549 | no_improve =  0 | time = 0s | epoch_time = 0.0s | soft_sigma = 2.000 | lr = 7.00e-03\n",
      "Epoch   30 | train‑avg =  15.4503 | soft‑eval =  15.4074 | best =  15.7610 | no_improve =  9 | time = 1s | epoch_time = 0.0s | soft_sigma = 2.000 | lr = 7.00e-03\n",
      "Epoch   40 | train‑avg =  15.4553 | soft‑eval =  15.6072 | best =  15.8084 | no_improve =  8 | time = 1s | epoch_time = 0.0s | soft_sigma = 2.000 | lr = 7.00e-03\n",
      "Epoch   50 | train‑avg =  15.3244 | soft‑eval =  15.5695 | best =  15.8084 | no_improve = 18 | time = 2s | epoch_time = 0.0s | soft_sigma = 2.000 | lr = 7.00e-03\n",
      "Epoch   60 | train‑avg =  15.4456 | soft‑eval =  15.6801 | best =  15.8084 | no_improve = 28 | time = 2s | epoch_time = 0.0s | soft_sigma = 2.000 | lr = 7.00e-03\n",
      "Epoch   70 | train‑avg =  15.8650 | soft‑eval =  15.3844 | best =  15.8084 | no_improve = 38 | time = 2s | epoch_time = 0.0s | soft_sigma = 2.000 | lr = 7.00e-03\n",
      "Epoch   80 | train‑avg =  15.4678 | soft‑eval =  15.7317 | best =  15.8248 | no_improve =  6 | time = 3s | epoch_time = 0.0s | soft_sigma = 2.000 | lr = 7.00e-03\n",
      "Epoch   90 | train‑avg =  15.3377 | soft‑eval =  15.5378 | best =  15.8248 | no_improve = 16 | time = 3s | epoch_time = 0.0s | soft_sigma = 2.000 | lr = 7.00e-03\n",
      "Epoch  100 | train‑avg =  15.7613 | soft‑eval =  15.3529 | best =  15.8248 | no_improve = 26 | time = 4s | epoch_time = 0.0s | soft_sigma = 2.000 | lr = 7.00e-03\n",
      "Epoch  110 | train‑avg =  15.3092 | soft‑eval =  15.6165 | best =  15.8248 | no_improve = 36 | time = 4s | epoch_time = 0.0s | soft_sigma = 2.000 | lr = 7.00e-03\n",
      "Epoch  120 | train‑avg =  15.5157 | soft‑eval =  15.5079 | best =  15.8248 | no_improve = 46 | time = 4s | epoch_time = 0.0s | soft_sigma = 2.000 | lr = 7.00e-03\n",
      "Epoch  130 | train‑avg =  15.5573 | soft‑eval =  15.2816 | best =  15.8248 | no_improve = 56 | time = 5s | epoch_time = 0.0s | soft_sigma = 2.000 | lr = 7.00e-03\n",
      "Epoch  140 | train‑avg =  15.7019 | soft‑eval =  15.5945 | best =  15.8248 | no_improve = 66 | time = 5s | epoch_time = 0.0s | soft_sigma = 2.000 | lr = 7.00e-03\n",
      "Epoch  150 | train‑avg =  15.4707 | soft‑eval =  15.6604 | best =  15.8248 | no_improve = 76 | time = 6s | epoch_time = 0.0s | soft_sigma = 2.000 | lr = 7.00e-03\n",
      "Epoch  160 | train‑avg =  15.6658 | soft‑eval =  15.3533 | best =  15.8719 | no_improve =  4 | time = 6s | epoch_time = 0.0s | soft_sigma = 2.000 | lr = 7.00e-03\n",
      "Epoch  170 | train‑avg =  15.7307 | soft‑eval =  15.3009 | best =  15.8719 | no_improve = 14 | time = 6s | epoch_time = 0.0s | soft_sigma = 2.000 | lr = 7.00e-03\n",
      "Epoch  180 | train‑avg =  15.4226 | soft‑eval =  15.6029 | best =  15.8719 | no_improve = 24 | time = 7s | epoch_time = 0.0s | soft_sigma = 2.000 | lr = 3.50e-03\n",
      "Epoch  190 | train‑avg =  15.4880 | soft‑eval =  15.5886 | best =  15.8719 | no_improve = 34 | time = 7s | epoch_time = 0.0s | soft_sigma = 2.000 | lr = 3.50e-03\n",
      "Epoch  200 | train‑avg =  15.6146 | soft‑eval =  15.5549 | best =  15.9014 | no_improve =  2 | time = 7s | epoch_time = 0.0s | soft_sigma = 2.000 | lr = 3.50e-03\n",
      "Epoch  210 | train‑avg =  15.4656 | soft‑eval =  15.5698 | best =  15.9014 | no_improve = 12 | time = 8s | epoch_time = 0.0s | soft_sigma = 2.000 | lr = 3.50e-03\n",
      "Epoch  220 | train‑avg =  15.6781 | soft‑eval =  15.3856 | best =  15.9014 | no_improve = 22 | time = 8s | epoch_time = 0.0s | soft_sigma = 2.000 | lr = 3.50e-03\n",
      "Epoch  230 | train‑avg =  15.5990 | soft‑eval =  15.5180 | best =  15.9014 | no_improve = 32 | time = 9s | epoch_time = 0.0s | soft_sigma = 2.000 | lr = 3.50e-03\n",
      "Epoch  240 | train‑avg =  15.3935 | soft‑eval =  15.5673 | best =  15.9014 | no_improve = 42 | time = 9s | epoch_time = 0.0s | soft_sigma = 2.000 | lr = 3.50e-03\n",
      "Epoch  250 | train‑avg =  15.3370 | soft‑eval =  15.3570 | best =  15.9966 | no_improve =  6 | time = 10s | epoch_time = 0.0s | soft_sigma = 2.000 | lr = 3.50e-03\n",
      "Epoch  260 | train‑avg =  15.1788 | soft‑eval =  15.5551 | best =  15.9966 | no_improve = 16 | time = 10s | epoch_time = 0.0s | soft_sigma = 2.000 | lr = 3.50e-03\n",
      "Epoch  270 | train‑avg =  15.5319 | soft‑eval =  15.2609 | best =  15.9966 | no_improve = 26 | time = 10s | epoch_time = 0.0s | soft_sigma = 2.000 | lr = 3.50e-03\n",
      "Epoch  280 | train‑avg =  15.4926 | soft‑eval =  15.4177 | best =  15.9966 | no_improve = 36 | time = 11s | epoch_time = 0.0s | soft_sigma = 2.000 | lr = 3.50e-03\n",
      "Epoch  290 | train‑avg =  15.7035 | soft‑eval =  15.7018 | best =  15.9966 | no_improve = 46 | time = 11s | epoch_time = 0.0s | soft_sigma = 2.000 | lr = 3.50e-03\n",
      "Epoch  300 | train‑avg =  15.6678 | soft‑eval =  15.5057 | best =  15.9966 | no_improve = 56 | time = 12s | epoch_time = 0.0s | soft_sigma = 2.000 | lr = 3.50e-03\n",
      "Epoch  310 | train‑avg =  15.3331 | soft‑eval =  15.6741 | best =  15.9966 | no_improve = 66 | time = 12s | epoch_time = 0.0s | soft_sigma = 2.000 | lr = 3.50e-03\n",
      "Epoch  320 | train‑avg =  15.2867 | soft‑eval =  15.1605 | best =  15.9966 | no_improve = 76 | time = 12s | epoch_time = 0.0s | soft_sigma = 2.000 | lr = 3.50e-03\n",
      "Epoch  330 | train‑avg =  15.4329 | soft‑eval =  15.5140 | best =  15.9966 | no_improve = 86 | time = 13s | epoch_time = 0.0s | soft_sigma = 2.000 | lr = 3.50e-03\n",
      "Epoch  340 | train‑avg =  15.3294 | soft‑eval =  15.5452 | best =  16.0202 | no_improve =  5 | time = 13s | epoch_time = 0.0s | soft_sigma = 2.000 | lr = 1.75e-03\n",
      "Epoch  350 | train‑avg =  15.4869 | soft‑eval =  15.5293 | best =  16.0202 | no_improve = 15 | time = 14s | epoch_time = 0.0s | soft_sigma = 2.000 | lr = 1.75e-03\n",
      "Epoch  360 | train‑avg =  15.6620 | soft‑eval =  15.2970 | best =  16.0202 | no_improve = 25 | time = 14s | epoch_time = 0.0s | soft_sigma = 2.000 | lr = 1.75e-03\n",
      "Epoch  370 | train‑avg =  15.6194 | soft‑eval =  15.6064 | best =  16.0202 | no_improve = 35 | time = 14s | epoch_time = 0.0s | soft_sigma = 2.000 | lr = 1.75e-03\n",
      "Epoch  380 | train‑avg =  15.5894 | soft‑eval =  15.4586 | best =  16.0202 | no_improve = 45 | time = 15s | epoch_time = 0.0s | soft_sigma = 2.000 | lr = 1.75e-03\n",
      "Epoch  390 | train‑avg =  15.6151 | soft‑eval =  15.4006 | best =  16.0202 | no_improve = 55 | time = 15s | epoch_time = 0.0s | soft_sigma = 2.000 | lr = 1.75e-03\n",
      "Epoch  400 | train‑avg =  15.4810 | soft‑eval =  15.6900 | best =  16.0202 | no_improve = 65 | time = 16s | epoch_time = 0.0s | soft_sigma = 2.000 | lr = 1.75e-03\n",
      "Epoch  410 | train‑avg =  15.7537 | soft‑eval =  15.3995 | best =  16.0202 | no_improve = 75 | time = 16s | epoch_time = 0.0s | soft_sigma = 2.000 | lr = 1.75e-03\n",
      "Epoch  420 | train‑avg =  15.5182 | soft‑eval =  15.4999 | best =  16.0202 | no_improve = 85 | time = 16s | epoch_time = 0.0s | soft_sigma = 2.000 | lr = 1.75e-03\n",
      "Epoch  430 | train‑avg =  15.7396 | soft‑eval =  15.7562 | best =  16.0202 | no_improve = 95 | time = 17s | epoch_time = 0.0s | soft_sigma = 2.000 | lr = 1.75e-03\n",
      "Epoch  440 | train‑avg =  15.4720 | soft‑eval =  15.6753 | best =  16.0202 | no_improve = 105 | time = 17s | epoch_time = 0.0s | soft_sigma = 2.000 | lr = 1.75e-03\n",
      "Epoch  450 | train‑avg =  15.6909 | soft‑eval =  15.6287 | best =  16.0202 | no_improve = 115 | time = 18s | epoch_time = 0.0s | soft_sigma = 2.000 | lr = 1.75e-03\n",
      "Epoch  460 | train‑avg =  15.2786 | soft‑eval =  15.2741 | best =  16.0202 | no_improve = 125 | time = 18s | epoch_time = 0.0s | soft_sigma = 2.000 | lr = 1.75e-03\n",
      "Epoch  470 | train‑avg =  15.6043 | soft‑eval =  15.3172 | best =  16.0202 | no_improve = 135 | time = 18s | epoch_time = 0.0s | soft_sigma = 2.000 | lr = 1.75e-03\n",
      "Epoch  480 | train‑avg =  15.2984 | soft‑eval =  15.3822 | best =  16.0202 | no_improve = 145 | time = 19s | epoch_time = 0.0s | soft_sigma = 2.000 | lr = 1.75e-03\n",
      "Epoch  490 | train‑avg =  15.4658 | soft‑eval =  15.2375 | best =  16.0202 | no_improve = 155 | time = 19s | epoch_time = 0.0s | soft_sigma = 2.000 | lr = 1.75e-03\n",
      "Epoch  500 | train‑avg =  15.6745 | soft‑eval =  15.6480 | best =  16.0202 | no_improve = 165 | time = 20s | epoch_time = 0.0s | soft_sigma = 2.000 | lr = 8.75e-04\n",
      "Epoch  510 | train‑avg =  15.7671 | soft‑eval =  15.5591 | best =  16.0202 | no_improve = 175 | time = 20s | epoch_time = 0.0s | soft_sigma = 2.000 | lr = 8.75e-04\n",
      "Epoch  520 | train‑avg =  15.5781 | soft‑eval =  15.2814 | best =  16.0202 | no_improve = 185 | time = 21s | epoch_time = 0.0s | soft_sigma = 2.000 | lr = 8.75e-04\n",
      "Epoch  530 | train‑avg =  15.8017 | soft‑eval =  15.7310 | best =  16.0202 | no_improve = 195 | time = 21s | epoch_time = 0.0s | soft_sigma = 2.000 | lr = 8.75e-04\n",
      "Early stopping triggered after 535 epochs (21s)\n",
      "Best score: 16.020222\n",
      "No improvement for 200 epochs\n",
      "\n",
      "Training completed after 534 epochs\n",
      "Total training time: 21s\n",
      "Average time per epoch: 0.0s\n",
      "Best evaluation score: 16.020222\n",
      "Final score: 15.625773\n",
      "\n",
      "Evaluating final policy...\n",
      "Sharp policy price ≈ 15.5420  CI: [15.5257,15.5582] (95% CI)\n",
      "Setting up input normalization...\n",
      "Starting training with early stopping (patience=200, min_epochs=50)\n",
      "Will stop when improvement < 1.00e-02 absolute or < 1.00e-03 relative\n",
      "Epoch   10 | train‑avg =  15.6158 | soft‑eval =  15.2129 | best =  15.5807 | no_improve =  0 | time = 0s | epoch_time = 0.0s | soft_sigma = 2.000 | lr = 7.00e-03\n",
      "Epoch   20 | train‑avg =  15.3455 | soft‑eval =  15.3834 | best =  15.5807 | no_improve = 10 | time = 0s | epoch_time = 0.0s | soft_sigma = 2.000 | lr = 7.00e-03\n",
      "Epoch   30 | train‑avg =  15.6007 | soft‑eval =  15.5442 | best =  15.7404 | no_improve =  0 | time = 1s | epoch_time = 0.0s | soft_sigma = 2.000 | lr = 7.00e-03\n",
      "Epoch   40 | train‑avg =  15.2822 | soft‑eval =  15.8498 | best =  15.7404 | no_improve = 10 | time = 1s | epoch_time = 0.0s | soft_sigma = 2.000 | lr = 7.00e-03\n",
      "Epoch   50 | train‑avg =  15.5096 | soft‑eval =  15.7809 | best =  15.8498 | no_improve =  9 | time = 1s | epoch_time = 0.0s | soft_sigma = 2.000 | lr = 7.00e-03\n",
      "Epoch   60 | train‑avg =  15.8281 | soft‑eval =  15.4098 | best =  15.9910 | no_improve =  5 | time = 2s | epoch_time = 0.0s | soft_sigma = 2.000 | lr = 7.00e-03\n",
      "Epoch   70 | train‑avg =  15.6030 | soft‑eval =  15.3268 | best =  15.9910 | no_improve = 15 | time = 2s | epoch_time = 0.0s | soft_sigma = 2.000 | lr = 7.00e-03\n",
      "Epoch   80 | train‑avg =  15.2801 | soft‑eval =  15.6401 | best =  15.9910 | no_improve = 25 | time = 3s | epoch_time = 0.0s | soft_sigma = 2.000 | lr = 7.00e-03\n",
      "Epoch   90 | train‑avg =  15.6438 | soft‑eval =  15.7191 | best =  15.9910 | no_improve = 35 | time = 3s | epoch_time = 0.0s | soft_sigma = 2.000 | lr = 7.00e-03\n",
      "Epoch  100 | train‑avg =  15.3184 | soft‑eval =  15.6949 | best =  15.9910 | no_improve = 45 | time = 3s | epoch_time = 0.0s | soft_sigma = 2.000 | lr = 7.00e-03\n",
      "Epoch  110 | train‑avg =  15.7446 | soft‑eval =  15.5167 | best =  15.9910 | no_improve = 55 | time = 4s | epoch_time = 0.0s | soft_sigma = 2.000 | lr = 7.00e-03\n",
      "Epoch  120 | train‑avg =  15.2044 | soft‑eval =  15.7136 | best =  15.9910 | no_improve = 65 | time = 4s | epoch_time = 0.0s | soft_sigma = 2.000 | lr = 7.00e-03\n",
      "Epoch  130 | train‑avg =  15.7988 | soft‑eval =  15.2812 | best =  15.9910 | no_improve = 75 | time = 5s | epoch_time = 0.0s | soft_sigma = 2.000 | lr = 7.00e-03\n",
      "Epoch  140 | train‑avg =  15.6636 | soft‑eval =  15.7903 | best =  15.9910 | no_improve = 85 | time = 5s | epoch_time = 0.0s | soft_sigma = 2.000 | lr = 7.00e-03\n",
      "Epoch  150 | train‑avg =  15.4526 | soft‑eval =  15.3323 | best =  15.9910 | no_improve = 95 | time = 5s | epoch_time = 0.0s | soft_sigma = 2.000 | lr = 7.00e-03\n",
      "Epoch  160 | train‑avg =  15.2909 | soft‑eval =  15.1142 | best =  15.9910 | no_improve = 105 | time = 6s | epoch_time = 0.0s | soft_sigma = 2.000 | lr = 7.00e-03\n",
      "Epoch  170 | train‑avg =  15.4716 | soft‑eval =  15.6872 | best =  15.9910 | no_improve = 115 | time = 6s | epoch_time = 0.0s | soft_sigma = 2.000 | lr = 7.00e-03\n",
      "Epoch  180 | train‑avg =  15.7552 | soft‑eval =  15.6042 | best =  15.9910 | no_improve = 125 | time = 7s | epoch_time = 0.0s | soft_sigma = 2.000 | lr = 7.00e-03\n",
      "Epoch  190 | train‑avg =  15.4886 | soft‑eval =  15.4025 | best =  15.9910 | no_improve = 135 | time = 7s | epoch_time = 0.0s | soft_sigma = 2.000 | lr = 7.00e-03\n",
      "Epoch  200 | train‑avg =  15.3118 | soft‑eval =  15.5304 | best =  15.9910 | no_improve = 145 | time = 7s | epoch_time = 0.0s | soft_sigma = 2.000 | lr = 3.50e-03\n",
      "Epoch  210 | train‑avg =  15.5062 | soft‑eval =  15.6786 | best =  15.9910 | no_improve = 155 | time = 8s | epoch_time = 0.0s | soft_sigma = 2.000 | lr = 3.50e-03\n",
      "Epoch  220 | train‑avg =  15.7122 | soft‑eval =  15.5208 | best =  15.9910 | no_improve = 165 | time = 8s | epoch_time = 0.0s | soft_sigma = 2.000 | lr = 3.50e-03\n",
      "Epoch  230 | train‑avg =  15.4892 | soft‑eval =  15.5074 | best =  15.9910 | no_improve = 175 | time = 8s | epoch_time = 0.0s | soft_sigma = 2.000 | lr = 3.50e-03\n",
      "Epoch  240 | train‑avg =  15.5782 | soft‑eval =  15.9136 | best =  15.9910 | no_improve = 185 | time = 9s | epoch_time = 0.0s | soft_sigma = 2.000 | lr = 3.50e-03\n",
      "Epoch  250 | train‑avg =  15.3509 | soft‑eval =  15.9300 | best =  15.9910 | no_improve = 195 | time = 9s | epoch_time = 0.0s | soft_sigma = 2.000 | lr = 3.50e-03\n",
      "Early stopping triggered after 255 epochs (9s)\n",
      "Best score: 15.991022\n",
      "No improvement for 200 epochs\n",
      "\n",
      "Training completed after 254 epochs\n",
      "Total training time: 9s\n",
      "Average time per epoch: 0.0s\n",
      "Best evaluation score: 15.991022\n",
      "Final score: 15.630591\n",
      "\n",
      "Evaluating final policy...\n",
      "Sharp policy price ≈ 15.5318  CI: [15.5155,15.5481] (95% CI)\n",
      "Setting up input normalization...\n",
      "Starting training with early stopping (patience=200, min_epochs=50)\n",
      "Will stop when improvement < 1.00e-02 absolute or < 1.00e-03 relative\n",
      "Epoch   10 | train‑avg =  15.4854 | soft‑eval =  15.3049 | best =  15.3656 | no_improve =  1 | time = 0s | epoch_time = 0.0s | soft_sigma = 2.000 | lr = 7.00e-03\n",
      "Epoch   20 | train‑avg =  15.7679 | soft‑eval =  15.4610 | best =  15.8884 | no_improve =  3 | time = 0s | epoch_time = 0.0s | soft_sigma = 2.000 | lr = 7.00e-03\n",
      "Epoch   30 | train‑avg =  15.5138 | soft‑eval =  15.3035 | best =  15.8884 | no_improve = 13 | time = 1s | epoch_time = 0.0s | soft_sigma = 2.000 | lr = 7.00e-03\n",
      "Epoch   40 | train‑avg =  15.3635 | soft‑eval =  15.4278 | best =  15.8884 | no_improve = 23 | time = 1s | epoch_time = 0.0s | soft_sigma = 2.000 | lr = 7.00e-03\n",
      "Epoch   50 | train‑avg =  15.3668 | soft‑eval =  15.4653 | best =  15.8884 | no_improve = 33 | time = 1s | epoch_time = 0.0s | soft_sigma = 2.000 | lr = 7.00e-03\n",
      "Epoch   60 | train‑avg =  15.4592 | soft‑eval =  15.4459 | best =  15.8884 | no_improve = 43 | time = 2s | epoch_time = 0.0s | soft_sigma = 2.000 | lr = 7.00e-03\n",
      "Epoch   70 | train‑avg =  15.3102 | soft‑eval =  15.5275 | best =  15.8884 | no_improve = 53 | time = 2s | epoch_time = 0.0s | soft_sigma = 2.000 | lr = 7.00e-03\n",
      "Epoch   80 | train‑avg =  15.2996 | soft‑eval =  15.5627 | best =  15.8884 | no_improve = 63 | time = 3s | epoch_time = 0.0s | soft_sigma = 2.000 | lr = 7.00e-03\n",
      "Epoch   90 | train‑avg =  15.7015 | soft‑eval =  15.2083 | best =  15.8884 | no_improve = 73 | time = 3s | epoch_time = 0.0s | soft_sigma = 2.000 | lr = 7.00e-03\n",
      "Epoch  100 | train‑avg =  15.5236 | soft‑eval =  15.3931 | best =  15.8884 | no_improve = 83 | time = 4s | epoch_time = 0.0s | soft_sigma = 2.000 | lr = 7.00e-03\n",
      "Epoch  110 | train‑avg =  15.6320 | soft‑eval =  15.5249 | best =  15.8884 | no_improve = 93 | time = 4s | epoch_time = 0.0s | soft_sigma = 2.000 | lr = 7.00e-03\n",
      "Epoch  120 | train‑avg =  15.8120 | soft‑eval =  15.7809 | best =  15.8884 | no_improve = 103 | time = 4s | epoch_time = 0.0s | soft_sigma = 2.000 | lr = 7.00e-03\n",
      "Epoch  130 | train‑avg =  15.5586 | soft‑eval =  15.1300 | best =  15.8884 | no_improve = 113 | time = 5s | epoch_time = 0.0s | soft_sigma = 2.000 | lr = 7.00e-03\n",
      "Epoch  140 | train‑avg =  15.7350 | soft‑eval =  15.4697 | best =  15.8884 | no_improve = 123 | time = 5s | epoch_time = 0.0s | soft_sigma = 2.000 | lr = 7.00e-03\n",
      "Epoch  150 | train‑avg =  15.3835 | soft‑eval =  15.4920 | best =  15.8884 | no_improve = 133 | time = 6s | epoch_time = 0.0s | soft_sigma = 2.000 | lr = 7.00e-03\n",
      "Epoch  160 | train‑avg =  15.5667 | soft‑eval =  15.4184 | best =  15.8884 | no_improve = 143 | time = 6s | epoch_time = 0.0s | soft_sigma = 2.000 | lr = 7.00e-03\n",
      "Epoch  170 | train‑avg =  15.2617 | soft‑eval =  15.6776 | best =  15.8884 | no_improve = 153 | time = 6s | epoch_time = 0.0s | soft_sigma = 2.000 | lr = 7.00e-03\n",
      "Epoch  180 | train‑avg =  15.4894 | soft‑eval =  15.5110 | best =  15.8884 | no_improve = 163 | time = 7s | epoch_time = 0.0s | soft_sigma = 2.000 | lr = 7.00e-03\n",
      "Epoch  190 | train‑avg =  15.7190 | soft‑eval =  15.6647 | best =  16.0072 | no_improve =  3 | time = 7s | epoch_time = 0.0s | soft_sigma = 2.000 | lr = 7.00e-03\n",
      "Epoch  200 | train‑avg =  15.7949 | soft‑eval =  15.2651 | best =  16.0072 | no_improve = 13 | time = 8s | epoch_time = 0.0s | soft_sigma = 2.000 | lr = 7.00e-03\n",
      "Epoch  210 | train‑avg =  15.5989 | soft‑eval =  15.4315 | best =  16.0072 | no_improve = 23 | time = 8s | epoch_time = 0.0s | soft_sigma = 2.000 | lr = 7.00e-03\n",
      "Epoch  220 | train‑avg =  15.3519 | soft‑eval =  15.6213 | best =  16.0072 | no_improve = 33 | time = 8s | epoch_time = 0.0s | soft_sigma = 2.000 | lr = 7.00e-03\n",
      "Epoch  230 | train‑avg =  15.5494 | soft‑eval =  15.3297 | best =  16.0623 | no_improve =  4 | time = 9s | epoch_time = 0.0s | soft_sigma = 2.000 | lr = 7.00e-03\n",
      "Epoch  240 | train‑avg =  15.6668 | soft‑eval =  15.3302 | best =  16.0623 | no_improve = 14 | time = 9s | epoch_time = 0.0s | soft_sigma = 2.000 | lr = 7.00e-03\n",
      "Epoch  250 | train‑avg =  15.5279 | soft‑eval =  15.4221 | best =  16.0623 | no_improve = 24 | time = 9s | epoch_time = 0.0s | soft_sigma = 2.000 | lr = 7.00e-03\n",
      "Epoch  260 | train‑avg =  15.6113 | soft‑eval =  15.5632 | best =  16.0623 | no_improve = 34 | time = 10s | epoch_time = 0.0s | soft_sigma = 2.000 | lr = 7.00e-03\n",
      "Epoch  270 | train‑avg =  15.4947 | soft‑eval =  15.1722 | best =  16.0623 | no_improve = 44 | time = 10s | epoch_time = 0.0s | soft_sigma = 2.000 | lr = 7.00e-03\n",
      "Epoch  280 | train‑avg =  15.7399 | soft‑eval =  15.5111 | best =  16.0623 | no_improve = 54 | time = 11s | epoch_time = 0.0s | soft_sigma = 2.000 | lr = 3.50e-03\n",
      "Epoch  290 | train‑avg =  15.3834 | soft‑eval =  15.4881 | best =  16.0623 | no_improve = 64 | time = 11s | epoch_time = 0.0s | soft_sigma = 2.000 | lr = 3.50e-03\n",
      "Epoch  300 | train‑avg =  15.2063 | soft‑eval =  15.3687 | best =  16.0623 | no_improve = 74 | time = 11s | epoch_time = 0.0s | soft_sigma = 2.000 | lr = 3.50e-03\n",
      "Epoch  310 | train‑avg =  15.2453 | soft‑eval =  15.6506 | best =  16.0623 | no_improve = 84 | time = 12s | epoch_time = 0.0s | soft_sigma = 2.000 | lr = 3.50e-03\n",
      "Epoch  320 | train‑avg =  15.4560 | soft‑eval =  15.5786 | best =  16.0623 | no_improve = 94 | time = 12s | epoch_time = 0.0s | soft_sigma = 2.000 | lr = 3.50e-03\n",
      "Epoch  330 | train‑avg =  15.6926 | soft‑eval =  15.3029 | best =  16.0623 | no_improve = 104 | time = 13s | epoch_time = 0.0s | soft_sigma = 2.000 | lr = 3.50e-03\n",
      "Epoch  340 | train‑avg =  15.2950 | soft‑eval =  15.3493 | best =  16.0623 | no_improve = 114 | time = 13s | epoch_time = 0.0s | soft_sigma = 2.000 | lr = 3.50e-03\n",
      "Epoch  350 | train‑avg =  15.4429 | soft‑eval =  15.8317 | best =  16.0623 | no_improve = 124 | time = 13s | epoch_time = 0.0s | soft_sigma = 2.000 | lr = 3.50e-03\n",
      "Epoch  360 | train‑avg =  15.4754 | soft‑eval =  15.2298 | best =  16.0623 | no_improve = 134 | time = 14s | epoch_time = 0.0s | soft_sigma = 2.000 | lr = 3.50e-03\n",
      "Epoch  370 | train‑avg =  15.6272 | soft‑eval =  15.6546 | best =  16.0623 | no_improve = 144 | time = 14s | epoch_time = 0.0s | soft_sigma = 2.000 | lr = 3.50e-03\n",
      "Epoch  380 | train‑avg =  15.6044 | soft‑eval =  15.3395 | best =  16.0623 | no_improve = 154 | time = 15s | epoch_time = 0.0s | soft_sigma = 2.000 | lr = 3.50e-03\n",
      "Epoch  390 | train‑avg =  15.4305 | soft‑eval =  15.5235 | best =  16.0623 | no_improve = 164 | time = 15s | epoch_time = 0.0s | soft_sigma = 2.000 | lr = 3.50e-03\n",
      "Epoch  400 | train‑avg =  15.4644 | soft‑eval =  15.6351 | best =  16.0623 | no_improve = 174 | time = 16s | epoch_time = 0.0s | soft_sigma = 2.000 | lr = 3.50e-03\n",
      "Epoch  410 | train‑avg =  15.6783 | soft‑eval =  15.3907 | best =  16.0623 | no_improve = 184 | time = 16s | epoch_time = 0.0s | soft_sigma = 2.000 | lr = 3.50e-03\n",
      "Epoch  420 | train‑avg =  15.5437 | soft‑eval =  15.7127 | best =  16.0623 | no_improve = 194 | time = 16s | epoch_time = 0.0s | soft_sigma = 2.000 | lr = 3.50e-03\n",
      "Early stopping triggered after 426 epochs (16s)\n",
      "Best score: 16.062283\n",
      "No improvement for 200 epochs\n",
      "\n",
      "Training completed after 425 epochs\n",
      "Total training time: 16s\n",
      "Average time per epoch: 0.0s\n",
      "Best evaluation score: 16.062283\n",
      "Final score: 15.823097\n",
      "\n",
      "Evaluating final policy...\n",
      "Sharp policy price ≈ 15.5421  CI: [15.5258,15.5583] (95% CI)\n"
     ]
    }
   ],
   "source": [
    "d = 2\n",
    "seed = 42\n",
    "\n",
    "prices = []\n",
    "times = []\n",
    "n_trials = 8\n",
    "\n",
    "S0_vec       = np.full(d, 100.0, dtype=np.float32)\n",
    "sigma_vec    = np.full(d, 0.2, dtype=np.float32)\n",
    "q_vec        = np.array([0.05, 0.15], dtype=np.float32)\n",
    "rho          = 0.0\n",
    "r            = 0.05\n",
    "K            = 100.0\n",
    "T            = 3.0\n",
    "num_steps    = 9\n",
    "dt           = T / num_steps\n",
    "\n",
    "for trial in range(n_trials):\n",
    "    net, train_hist, eval_hist, training_time = train_net(\n",
    "    soft_sigma=2.0,\n",
    "    N_train=10_000,\n",
    "    batch=500,\n",
    "    lr=0.007,\n",
    "    seed=seed + trial,\n",
    "    eval_every=10,\n",
    "    width=64,\n",
    "    depth=2,\n",
    "    dropout=0.1,\n",
    "    curriculum=False,\n",
    "    patience=200,            \n",
    "    min_delta=1e-2,      \n",
    "    relative_threshold=1e-3,\n",
    "    min_epochs=50,         \n",
    "    max_epochs=2000     \n",
    "    )\n",
    "    times.append(training_time)\n",
    "\n",
    "    print(\"\\nEvaluating final policy...\")\n",
    "    sharp_mean, sharp_se = evaluate_sharp_policy(net, N_eval=5_000_000)\n",
    "    prices.append(sharp_mean)\n",
    "    print(f\"Sharp policy price ≈ {sharp_mean:.4f}  CI: [{sharp_mean - 1.96*sharp_se:.4f},{sharp_mean + 1.96*sharp_se:.4f}] (95% CI)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "0ef306c3-ea56-4805-a7f4-b305c459efda",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Price = 15.542 (0.004)\n",
      "Max Price = 15.548\n",
      "Times = ['10s', '23s', '11s', '12s', '11s', '21s', '9s', '16s']\n"
     ]
    }
   ],
   "source": [
    "print(f\"Price = {np.mean(prices):.3f} ({np.std(prices):.3f})\")\n",
    "print(f\"Max Price = {np.max(prices):.3f}\")\n",
    "print(f\"Times = {times}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "5ce799b4-3554-4672-b880-82f602d449bf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average training time = 14.1\n"
     ]
    }
   ],
   "source": [
    "times = ['10s', '23s', '11s', '12s', '11s', '21s', '9s', '16s']\n",
    "print(f\"Average training time = {average_time_in_seconds(times)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7be9649-3ddb-4685-ab3c-b9d553e20de0",
   "metadata": {},
   "source": [
    "# d = 2 (Asymm. Div) Sigma Soft Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "id": "ed3312a6-2b92-4c57-af99-f8b052600798",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Setting up input normalization...\n",
      "Starting training with early stopping (patience=200, min_epochs=50)\n",
      "Will stop when improvement < 1.00e-02 absolute or < 1.00e-03 relative\n",
      "Early stopping triggered after 285 epochs (10s)\n",
      "Best score: 15.919025\n",
      "No improvement for 200 epochs\n",
      "\n",
      "Training completed after 284 epochs\n",
      "Total training time: 10s\n",
      "Average time per epoch: 0.0s\n",
      "Best evaluation score: 15.919025\n",
      "Final score: 15.197704\n",
      "\n",
      "Evaluating final policy...\n",
      "Sharp policy price ≈ 15.4429  CI: [15.4255,15.4602] (95% CI)\n",
      "Setting up input normalization...\n",
      "Starting training with early stopping (patience=200, min_epochs=50)\n",
      "Will stop when improvement < 1.00e-02 absolute or < 1.00e-03 relative\n",
      "Early stopping triggered after 589 epochs (23s)\n",
      "Best score: 16.305494\n",
      "No improvement for 200 epochs\n",
      "\n",
      "Training completed after 588 epochs\n",
      "Total training time: 23s\n",
      "Average time per epoch: 0.0s\n",
      "Best evaluation score: 16.305494\n",
      "Final score: 15.969384\n",
      "\n",
      "Evaluating final policy...\n",
      "Sharp policy price ≈ 15.5009  CI: [15.4841,15.5176] (95% CI)\n",
      "Setting up input normalization...\n",
      "Starting training with early stopping (patience=200, min_epochs=50)\n",
      "Will stop when improvement < 1.00e-02 absolute or < 1.00e-03 relative\n",
      "Early stopping triggered after 276 epochs (10s)\n",
      "Best score: 15.849556\n",
      "No improvement for 200 epochs\n",
      "\n",
      "Training completed after 275 epochs\n",
      "Total training time: 10s\n",
      "Average time per epoch: 0.0s\n",
      "Best evaluation score: 15.849556\n",
      "Final score: 15.195542\n",
      "\n",
      "Evaluating final policy...\n",
      "Sharp policy price ≈ 15.0957  CI: [15.0768,15.1145] (95% CI)\n",
      "Setting up input normalization...\n",
      "Starting training with early stopping (patience=200, min_epochs=50)\n",
      "Will stop when improvement < 1.00e-02 absolute or < 1.00e-03 relative\n",
      "Early stopping triggered after 468 epochs (18s)\n",
      "Best score: 16.026447\n",
      "No improvement for 200 epochs\n",
      "\n",
      "Training completed after 467 epochs\n",
      "Total training time: 18s\n",
      "Average time per epoch: 0.0s\n",
      "Best evaluation score: 16.026447\n",
      "Final score: 15.413872\n",
      "\n",
      "Evaluating final policy...\n",
      "Sharp policy price ≈ 15.4564  CI: [15.4392,15.4735] (95% CI)\n",
      "=======================================\n",
      "Sigma Soft = 0.100\n",
      "Price = 15.374 (0.162)\n",
      "Max Price = 15.501\n",
      "=======================================\n",
      "Setting up input normalization...\n",
      "Starting training with early stopping (patience=200, min_epochs=50)\n",
      "Will stop when improvement < 1.00e-02 absolute or < 1.00e-03 relative\n",
      "Early stopping triggered after 241 epochs (9s)\n",
      "Best score: 15.959750\n",
      "No improvement for 200 epochs\n",
      "\n",
      "Training completed after 240 epochs\n",
      "Total training time: 9s\n",
      "Average time per epoch: 0.0s\n",
      "Best evaluation score: 15.959750\n",
      "Final score: 15.598011\n",
      "\n",
      "Evaluating final policy...\n",
      "Sharp policy price ≈ 15.5036  CI: [15.4881,15.5191] (95% CI)\n",
      "Setting up input normalization...\n",
      "Starting training with early stopping (patience=200, min_epochs=50)\n",
      "Will stop when improvement < 1.00e-02 absolute or < 1.00e-03 relative\n",
      "Early stopping triggered after 225 epochs (9s)\n",
      "Best score: 15.800885\n",
      "No improvement for 200 epochs\n",
      "\n",
      "Training completed after 224 epochs\n",
      "Total training time: 9s\n",
      "Average time per epoch: 0.0s\n",
      "Best evaluation score: 15.800885\n",
      "Final score: 15.160345\n",
      "\n",
      "Evaluating final policy...\n",
      "Sharp policy price ≈ 15.1613  CI: [15.1427,15.1799] (95% CI)\n",
      "Setting up input normalization...\n",
      "Starting training with early stopping (patience=200, min_epochs=50)\n",
      "Will stop when improvement < 1.00e-02 absolute or < 1.00e-03 relative\n",
      "Early stopping triggered after 276 epochs (11s)\n",
      "Best score: 15.966555\n",
      "No improvement for 200 epochs\n",
      "\n",
      "Training completed after 275 epochs\n",
      "Total training time: 11s\n",
      "Average time per epoch: 0.0s\n",
      "Best evaluation score: 15.966555\n",
      "Final score: 15.450254\n",
      "\n",
      "Evaluating final policy...\n",
      "Sharp policy price ≈ 15.5097  CI: [15.4943,15.5252] (95% CI)\n",
      "Setting up input normalization...\n",
      "Starting training with early stopping (patience=200, min_epochs=50)\n",
      "Will stop when improvement < 1.00e-02 absolute or < 1.00e-03 relative\n",
      "Early stopping triggered after 308 epochs (12s)\n",
      "Best score: 16.094923\n",
      "No improvement for 200 epochs\n",
      "\n",
      "Training completed after 307 epochs\n",
      "Total training time: 12s\n",
      "Average time per epoch: 0.0s\n",
      "Best evaluation score: 16.094923\n",
      "Final score: 15.438841\n",
      "\n",
      "Evaluating final policy...\n",
      "Sharp policy price ≈ 15.5097  CI: [15.4934,15.5260] (95% CI)\n",
      "=======================================\n",
      "Sigma Soft = 0.176\n",
      "Price = 15.421 (0.150)\n",
      "Max Price = 15.510\n",
      "=======================================\n",
      "Setting up input normalization...\n",
      "Starting training with early stopping (patience=200, min_epochs=50)\n",
      "Will stop when improvement < 1.00e-02 absolute or < 1.00e-03 relative\n",
      "Early stopping triggered after 241 epochs (9s)\n",
      "Best score: 15.997056\n",
      "No improvement for 200 epochs\n",
      "\n",
      "Training completed after 240 epochs\n",
      "Total training time: 9s\n",
      "Average time per epoch: 0.0s\n",
      "Best evaluation score: 15.997056\n",
      "Final score: 15.707470\n",
      "\n",
      "Evaluating final policy...\n",
      "Sharp policy price ≈ 15.5302  CI: [15.5147,15.5457] (95% CI)\n",
      "Setting up input normalization...\n",
      "Starting training with early stopping (patience=200, min_epochs=50)\n",
      "Will stop when improvement < 1.00e-02 absolute or < 1.00e-03 relative\n",
      "Early stopping triggered after 261 epochs (10s)\n",
      "Best score: 15.983518\n",
      "No improvement for 200 epochs\n",
      "\n",
      "Training completed after 260 epochs\n",
      "Total training time: 10s\n",
      "Average time per epoch: 0.0s\n",
      "Best evaluation score: 15.983518\n",
      "Final score: 15.657535\n",
      "\n",
      "Evaluating final policy...\n",
      "Sharp policy price ≈ 15.5081  CI: [15.4927,15.5235] (95% CI)\n",
      "Setting up input normalization...\n",
      "Starting training with early stopping (patience=200, min_epochs=50)\n",
      "Will stop when improvement < 1.00e-02 absolute or < 1.00e-03 relative\n",
      "Early stopping triggered after 276 epochs (11s)\n",
      "Best score: 15.988850\n",
      "No improvement for 200 epochs\n",
      "\n",
      "Training completed after 275 epochs\n",
      "Total training time: 11s\n",
      "Average time per epoch: 0.0s\n",
      "Best evaluation score: 15.988850\n",
      "Final score: 15.471578\n",
      "\n",
      "Evaluating final policy...\n",
      "Sharp policy price ≈ 15.5333  CI: [15.5177,15.5488] (95% CI)\n",
      "Setting up input normalization...\n",
      "Starting training with early stopping (patience=200, min_epochs=50)\n",
      "Will stop when improvement < 1.00e-02 absolute or < 1.00e-03 relative\n",
      "Early stopping triggered after 308 epochs (12s)\n",
      "Best score: 16.010258\n",
      "No improvement for 200 epochs\n",
      "\n",
      "Training completed after 307 epochs\n",
      "Total training time: 12s\n",
      "Average time per epoch: 0.0s\n",
      "Best evaluation score: 16.010258\n",
      "Final score: 15.388210\n",
      "\n",
      "Evaluating final policy...\n",
      "Sharp policy price ≈ 15.5162  CI: [15.4997,15.5327] (95% CI)\n",
      "=======================================\n",
      "Sigma Soft = 0.310\n",
      "Price = 15.522 (0.010)\n",
      "Max Price = 15.533\n",
      "=======================================\n",
      "Setting up input normalization...\n",
      "Starting training with early stopping (patience=200, min_epochs=50)\n",
      "Will stop when improvement < 1.00e-02 absolute or < 1.00e-03 relative\n",
      "Early stopping triggered after 285 epochs (11s)\n",
      "Best score: 16.018290\n",
      "No improvement for 200 epochs\n",
      "\n",
      "Training completed after 284 epochs\n",
      "Total training time: 11s\n",
      "Average time per epoch: 0.0s\n",
      "Best evaluation score: 16.018290\n",
      "Final score: 15.310454\n",
      "\n",
      "Evaluating final policy...\n",
      "Sharp policy price ≈ 15.5371  CI: [15.5216,15.5525] (95% CI)\n",
      "Setting up input normalization...\n",
      "Starting training with early stopping (patience=200, min_epochs=50)\n",
      "Will stop when improvement < 1.00e-02 absolute or < 1.00e-03 relative\n",
      "Early stopping triggered after 589 epochs (24s)\n",
      "Best score: 16.218575\n",
      "No improvement for 200 epochs\n",
      "\n",
      "Training completed after 588 epochs\n",
      "Total training time: 24s\n",
      "Average time per epoch: 0.0s\n",
      "Best evaluation score: 16.218575\n",
      "Final score: 15.974785\n",
      "\n",
      "Evaluating final policy...\n",
      "Sharp policy price ≈ 15.5133  CI: [15.4982,15.5283] (95% CI)\n",
      "Setting up input normalization...\n",
      "Starting training with early stopping (patience=200, min_epochs=50)\n",
      "Will stop when improvement < 1.00e-02 absolute or < 1.00e-03 relative\n",
      "Early stopping triggered after 276 epochs (12s)\n",
      "Best score: 16.091987\n",
      "No improvement for 200 epochs\n",
      "\n",
      "Training completed after 275 epochs\n",
      "Total training time: 12s\n",
      "Average time per epoch: 0.0s\n",
      "Best evaluation score: 16.091987\n",
      "Final score: 15.431936\n",
      "\n",
      "Evaluating final policy...\n",
      "Sharp policy price ≈ 15.5251  CI: [15.5086,15.5416] (95% CI)\n",
      "Setting up input normalization...\n",
      "Starting training with early stopping (patience=200, min_epochs=50)\n",
      "Will stop when improvement < 1.00e-02 absolute or < 1.00e-03 relative\n",
      "Early stopping triggered after 308 epochs (16s)\n",
      "Best score: 16.015459\n",
      "No improvement for 200 epochs\n",
      "\n",
      "Training completed after 307 epochs\n",
      "Total training time: 16s\n",
      "Average time per epoch: 0.1s\n",
      "Best evaluation score: 16.015459\n",
      "Final score: 15.398545\n",
      "\n",
      "Evaluating final policy...\n",
      "Sharp policy price ≈ 15.5451  CI: [15.5292,15.5609] (95% CI)\n",
      "=======================================\n",
      "Sigma Soft = 0.545\n",
      "Price = 15.530 (0.012)\n",
      "Max Price = 15.545\n",
      "=======================================\n",
      "Setting up input normalization...\n",
      "Starting training with early stopping (patience=200, min_epochs=50)\n",
      "Will stop when improvement < 1.00e-02 absolute or < 1.00e-03 relative\n",
      "Early stopping triggered after 285 epochs (13s)\n",
      "Best score: 16.048219\n",
      "No improvement for 200 epochs\n",
      "\n",
      "Training completed after 284 epochs\n",
      "Total training time: 13s\n",
      "Average time per epoch: 0.0s\n",
      "Best evaluation score: 16.048219\n",
      "Final score: 15.308096\n",
      "\n",
      "Evaluating final policy...\n",
      "Sharp policy price ≈ 15.5463  CI: [15.5304,15.5623] (95% CI)\n",
      "Setting up input normalization...\n",
      "Starting training with early stopping (patience=200, min_epochs=50)\n",
      "Will stop when improvement < 1.00e-02 absolute or < 1.00e-03 relative\n",
      "Early stopping triggered after 589 epochs (27s)\n",
      "Best score: 16.150051\n",
      "No improvement for 200 epochs\n",
      "\n",
      "Training completed after 588 epochs\n",
      "Total training time: 27s\n",
      "Average time per epoch: 0.0s\n",
      "Best evaluation score: 16.150051\n",
      "Final score: 15.969974\n",
      "\n",
      "Evaluating final policy...\n",
      "Sharp policy price ≈ 15.5317  CI: [15.5164,15.5470] (95% CI)\n",
      "Setting up input normalization...\n",
      "Starting training with early stopping (patience=200, min_epochs=50)\n",
      "Will stop when improvement < 1.00e-02 absolute or < 1.00e-03 relative\n",
      "Early stopping triggered after 238 epochs (10s)\n",
      "Best score: 16.018127\n",
      "No improvement for 200 epochs\n",
      "\n",
      "Training completed after 237 epochs\n",
      "Total training time: 10s\n",
      "Average time per epoch: 0.0s\n",
      "Best evaluation score: 16.018127\n",
      "Final score: 15.398149\n",
      "\n",
      "Evaluating final policy...\n",
      "Sharp policy price ≈ 15.5190  CI: [15.5037,15.5343] (95% CI)\n",
      "Setting up input normalization...\n",
      "Starting training with early stopping (patience=200, min_epochs=50)\n",
      "Will stop when improvement < 1.00e-02 absolute or < 1.00e-03 relative\n",
      "Early stopping triggered after 308 epochs (14s)\n",
      "Best score: 16.094027\n",
      "No improvement for 200 epochs\n",
      "\n",
      "Training completed after 307 epochs\n",
      "Total training time: 14s\n",
      "Average time per epoch: 0.0s\n",
      "Best evaluation score: 16.094027\n",
      "Final score: 15.382221\n",
      "\n",
      "Evaluating final policy...\n",
      "Sharp policy price ≈ 15.5457  CI: [15.5299,15.5614] (95% CI)\n",
      "=======================================\n",
      "Sigma Soft = 0.959\n",
      "Price = 15.536 (0.011)\n",
      "Max Price = 15.546\n",
      "=======================================\n",
      "Setting up input normalization...\n",
      "Starting training with early stopping (patience=200, min_epochs=50)\n",
      "Will stop when improvement < 1.00e-02 absolute or < 1.00e-03 relative\n",
      "Early stopping triggered after 241 epochs (10s)\n",
      "Best score: 15.984250\n",
      "No improvement for 200 epochs\n",
      "\n",
      "Training completed after 240 epochs\n",
      "Total training time: 10s\n",
      "Average time per epoch: 0.0s\n",
      "Best evaluation score: 15.984250\n",
      "Final score: 15.622973\n",
      "\n",
      "Evaluating final policy...\n",
      "Sharp policy price ≈ 15.5448  CI: [15.5288,15.5609] (95% CI)\n",
      "Setting up input normalization...\n",
      "Starting training with early stopping (patience=200, min_epochs=50)\n",
      "Will stop when improvement < 1.00e-02 absolute or < 1.00e-03 relative\n",
      "Early stopping triggered after 589 epochs (25s)\n",
      "Best score: 16.216749\n",
      "No improvement for 200 epochs\n",
      "\n",
      "Training completed after 588 epochs\n",
      "Total training time: 25s\n",
      "Average time per epoch: 0.0s\n",
      "Best evaluation score: 16.216749\n",
      "Final score: 15.975526\n",
      "\n",
      "Evaluating final policy...\n",
      "Sharp policy price ≈ 15.5371  CI: [15.5218,15.5525] (95% CI)\n",
      "Setting up input normalization...\n",
      "Starting training with early stopping (patience=200, min_epochs=50)\n",
      "Will stop when improvement < 1.00e-02 absolute or < 1.00e-03 relative\n",
      "Early stopping triggered after 276 epochs (11s)\n",
      "Best score: 16.050097\n",
      "No improvement for 200 epochs\n",
      "\n",
      "Training completed after 275 epochs\n",
      "Total training time: 11s\n",
      "Average time per epoch: 0.0s\n",
      "Best evaluation score: 16.050097\n",
      "Final score: 15.473181\n",
      "\n",
      "Evaluating final policy...\n",
      "Sharp policy price ≈ 15.5428  CI: [15.5266,15.5589] (95% CI)\n",
      "Setting up input normalization...\n",
      "Starting training with early stopping (patience=200, min_epochs=50)\n",
      "Will stop when improvement < 1.00e-02 absolute or < 1.00e-03 relative\n",
      "Early stopping triggered after 308 epochs (13s)\n",
      "Best score: 16.055747\n",
      "No improvement for 200 epochs\n",
      "\n",
      "Training completed after 307 epochs\n",
      "Total training time: 13s\n",
      "Average time per epoch: 0.0s\n",
      "Best evaluation score: 16.055747\n",
      "Final score: 15.441571\n",
      "\n",
      "Evaluating final policy...\n",
      "Sharp policy price ≈ 15.5490  CI: [15.5331,15.5650] (95% CI)\n",
      "=======================================\n",
      "Sigma Soft = 1.688\n",
      "Price = 15.543 (0.004)\n",
      "Max Price = 15.549\n",
      "=======================================\n",
      "Setting up input normalization...\n",
      "Starting training with early stopping (patience=200, min_epochs=50)\n",
      "Will stop when improvement < 1.00e-02 absolute or < 1.00e-03 relative\n",
      "Early stopping triggered after 241 epochs (10s)\n",
      "Best score: 15.974162\n",
      "No improvement for 200 epochs\n",
      "\n",
      "Training completed after 240 epochs\n",
      "Total training time: 10s\n",
      "Average time per epoch: 0.0s\n",
      "Best evaluation score: 15.974162\n",
      "Final score: 15.614128\n",
      "\n",
      "Evaluating final policy...\n",
      "Sharp policy price ≈ 15.5431  CI: [15.5271,15.5592] (95% CI)\n",
      "Setting up input normalization...\n",
      "Starting training with early stopping (patience=200, min_epochs=50)\n",
      "Will stop when improvement < 1.00e-02 absolute or < 1.00e-03 relative\n",
      "Early stopping triggered after 589 epochs (25s)\n",
      "Best score: 16.200086\n",
      "No improvement for 200 epochs\n",
      "\n",
      "Training completed after 588 epochs\n",
      "Total training time: 25s\n",
      "Average time per epoch: 0.0s\n",
      "Best evaluation score: 16.200086\n",
      "Final score: 15.970383\n",
      "\n",
      "Evaluating final policy...\n",
      "Sharp policy price ≈ 15.5332  CI: [15.5179,15.5486] (95% CI)\n",
      "Setting up input normalization...\n",
      "Starting training with early stopping (patience=200, min_epochs=50)\n",
      "Will stop when improvement < 1.00e-02 absolute or < 1.00e-03 relative\n",
      "Early stopping triggered after 276 epochs (11s)\n",
      "Best score: 16.042760\n",
      "No improvement for 200 epochs\n",
      "\n",
      "Training completed after 275 epochs\n",
      "Total training time: 11s\n",
      "Average time per epoch: 0.0s\n",
      "Best evaluation score: 16.042760\n",
      "Final score: 15.475235\n",
      "\n",
      "Evaluating final policy...\n",
      "Sharp policy price ≈ 15.5434  CI: [15.5273,15.5596] (95% CI)\n",
      "Setting up input normalization...\n",
      "Starting training with early stopping (patience=200, min_epochs=50)\n",
      "Will stop when improvement < 1.00e-02 absolute or < 1.00e-03 relative\n",
      "Early stopping triggered after 308 epochs (13s)\n",
      "Best score: 16.026788\n",
      "No improvement for 200 epochs\n",
      "\n",
      "Training completed after 307 epochs\n",
      "Total training time: 13s\n",
      "Average time per epoch: 0.0s\n",
      "Best evaluation score: 16.026788\n",
      "Final score: 15.421598\n",
      "\n",
      "Evaluating final policy...\n",
      "Sharp policy price ≈ 15.5464  CI: [15.5304,15.5624] (95% CI)\n",
      "=======================================\n",
      "Sigma Soft = 2.970\n",
      "Price = 15.542 (0.005)\n",
      "Max Price = 15.546\n",
      "=======================================\n",
      "Setting up input normalization...\n",
      "Starting training with early stopping (patience=200, min_epochs=50)\n",
      "Will stop when improvement < 1.00e-02 absolute or < 1.00e-03 relative\n",
      "Early stopping triggered after 241 epochs (9s)\n",
      "Best score: 15.918770\n",
      "No improvement for 200 epochs\n",
      "\n",
      "Training completed after 240 epochs\n",
      "Total training time: 9s\n",
      "Average time per epoch: 0.0s\n",
      "Best evaluation score: 15.918770\n",
      "Final score: 15.602600\n",
      "\n",
      "Evaluating final policy...\n",
      "Sharp policy price ≈ 15.5388  CI: [15.5228,15.5549] (95% CI)\n",
      "Setting up input normalization...\n",
      "Starting training with early stopping (patience=200, min_epochs=50)\n",
      "Will stop when improvement < 1.00e-02 absolute or < 1.00e-03 relative\n",
      "Early stopping triggered after 589 epochs (25s)\n",
      "Best score: 16.197010\n",
      "No improvement for 200 epochs\n",
      "\n",
      "Training completed after 588 epochs\n",
      "Total training time: 25s\n",
      "Average time per epoch: 0.0s\n",
      "Best evaluation score: 16.197010\n",
      "Final score: 15.969863\n",
      "\n",
      "Evaluating final policy...\n",
      "Sharp policy price ≈ 15.5383  CI: [15.5228,15.5538] (95% CI)\n",
      "Setting up input normalization...\n",
      "Starting training with early stopping (patience=200, min_epochs=50)\n",
      "Will stop when improvement < 1.00e-02 absolute or < 1.00e-03 relative\n",
      "Early stopping triggered after 276 epochs (11s)\n",
      "Best score: 16.005230\n",
      "No improvement for 200 epochs\n",
      "\n",
      "Training completed after 275 epochs\n",
      "Total training time: 11s\n",
      "Average time per epoch: 0.0s\n",
      "Best evaluation score: 16.005230\n",
      "Final score: 15.469311\n",
      "\n",
      "Evaluating final policy...\n",
      "Sharp policy price ≈ 15.5410  CI: [15.5249,15.5572] (95% CI)\n",
      "Setting up input normalization...\n",
      "Starting training with early stopping (patience=200, min_epochs=50)\n",
      "Will stop when improvement < 1.00e-02 absolute or < 1.00e-03 relative\n",
      "Early stopping triggered after 308 epochs (13s)\n",
      "Best score: 16.006986\n",
      "No improvement for 200 epochs\n",
      "\n",
      "Training completed after 307 epochs\n",
      "Total training time: 13s\n",
      "Average time per epoch: 0.0s\n",
      "Best evaluation score: 16.006986\n",
      "Final score: 15.425296\n",
      "\n",
      "Evaluating final policy...\n",
      "Sharp policy price ≈ 15.5467  CI: [15.5308,15.5626] (95% CI)\n",
      "=======================================\n",
      "Sigma Soft = 5.226\n",
      "Price = 15.541 (0.003)\n",
      "Max Price = 15.547\n",
      "=======================================\n",
      "Setting up input normalization...\n",
      "Starting training with early stopping (patience=200, min_epochs=50)\n",
      "Will stop when improvement < 1.00e-02 absolute or < 1.00e-03 relative\n",
      "Early stopping triggered after 285 epochs (12s)\n",
      "Best score: 15.905442\n",
      "No improvement for 200 epochs\n",
      "\n",
      "Training completed after 284 epochs\n",
      "Total training time: 12s\n",
      "Average time per epoch: 0.0s\n",
      "Best evaluation score: 15.905442\n",
      "Final score: 15.281766\n",
      "\n",
      "Evaluating final policy...\n",
      "Sharp policy price ≈ 15.5314  CI: [15.5153,15.5476] (95% CI)\n",
      "Setting up input normalization...\n",
      "Starting training with early stopping (patience=200, min_epochs=50)\n",
      "Will stop when improvement < 1.00e-02 absolute or < 1.00e-03 relative\n",
      "Early stopping triggered after 589 epochs (26s)\n",
      "Best score: 16.213740\n",
      "No improvement for 200 epochs\n",
      "\n",
      "Training completed after 588 epochs\n",
      "Total training time: 26s\n",
      "Average time per epoch: 0.0s\n",
      "Best evaluation score: 16.213740\n",
      "Final score: 15.963546\n",
      "\n",
      "Evaluating final policy...\n",
      "Sharp policy price ≈ 15.5420  CI: [15.5263,15.5578] (95% CI)\n",
      "Setting up input normalization...\n",
      "Starting training with early stopping (patience=200, min_epochs=50)\n",
      "Will stop when improvement < 1.00e-02 absolute or < 1.00e-03 relative\n",
      "Early stopping triggered after 276 epochs (12s)\n",
      "Best score: 15.968005\n",
      "No improvement for 200 epochs\n",
      "\n",
      "Training completed after 275 epochs\n",
      "Total training time: 12s\n",
      "Average time per epoch: 0.0s\n",
      "Best evaluation score: 15.968005\n",
      "Final score: 15.462617\n",
      "\n",
      "Evaluating final policy...\n",
      "Sharp policy price ≈ 15.5387  CI: [15.5225,15.5549] (95% CI)\n",
      "Setting up input normalization...\n",
      "Starting training with early stopping (patience=200, min_epochs=50)\n",
      "Will stop when improvement < 1.00e-02 absolute or < 1.00e-03 relative\n",
      "Early stopping triggered after 308 epochs (13s)\n",
      "Best score: 15.986141\n",
      "No improvement for 200 epochs\n",
      "\n",
      "Training completed after 307 epochs\n",
      "Total training time: 13s\n",
      "Average time per epoch: 0.0s\n",
      "Best evaluation score: 15.986141\n",
      "Final score: 15.403143\n",
      "\n",
      "Evaluating final policy...\n",
      "Sharp policy price ≈ 15.5411  CI: [15.5252,15.5571] (95% CI)\n",
      "=======================================\n",
      "Sigma Soft = 9.197\n",
      "Price = 15.538 (0.004)\n",
      "Max Price = 15.542\n",
      "=======================================\n",
      "Setting up input normalization...\n",
      "Starting training with early stopping (patience=200, min_epochs=50)\n",
      "Will stop when improvement < 1.00e-02 absolute or < 1.00e-03 relative\n",
      "Early stopping triggered after 285 epochs (12s)\n",
      "Best score: 15.874340\n",
      "No improvement for 200 epochs\n",
      "\n",
      "Training completed after 284 epochs\n",
      "Total training time: 12s\n",
      "Average time per epoch: 0.0s\n",
      "Best evaluation score: 15.874340\n",
      "Final score: 15.275505\n",
      "\n",
      "Evaluating final policy...\n",
      "Sharp policy price ≈ 15.5247  CI: [15.5085,15.5410] (95% CI)\n",
      "Setting up input normalization...\n",
      "Starting training with early stopping (patience=200, min_epochs=50)\n",
      "Will stop when improvement < 1.00e-02 absolute or < 1.00e-03 relative\n",
      "Early stopping triggered after 589 epochs (25s)\n",
      "Best score: 16.221874\n",
      "No improvement for 200 epochs\n",
      "\n",
      "Training completed after 588 epochs\n",
      "Total training time: 25s\n",
      "Average time per epoch: 0.0s\n",
      "Best evaluation score: 16.221874\n",
      "Final score: 15.962610\n",
      "\n",
      "Evaluating final policy...\n",
      "Sharp policy price ≈ 15.5443  CI: [15.5283,15.5602] (95% CI)\n",
      "Setting up input normalization...\n",
      "Starting training with early stopping (patience=200, min_epochs=50)\n",
      "Will stop when improvement < 1.00e-02 absolute or < 1.00e-03 relative\n",
      "Early stopping triggered after 276 epochs (12s)\n",
      "Best score: 15.937720\n",
      "No improvement for 200 epochs\n",
      "\n",
      "Training completed after 275 epochs\n",
      "Total training time: 12s\n",
      "Average time per epoch: 0.0s\n",
      "Best evaluation score: 15.937720\n",
      "Final score: 15.438897\n",
      "\n",
      "Evaluating final policy...\n",
      "Sharp policy price ≈ 15.5278  CI: [15.5115,15.5442] (95% CI)\n",
      "Setting up input normalization...\n",
      "Starting training with early stopping (patience=200, min_epochs=50)\n",
      "Will stop when improvement < 1.00e-02 absolute or < 1.00e-03 relative\n",
      "Early stopping triggered after 308 epochs (13s)\n",
      "Best score: 15.962453\n",
      "No improvement for 200 epochs\n",
      "\n",
      "Training completed after 307 epochs\n",
      "Total training time: 13s\n",
      "Average time per epoch: 0.0s\n",
      "Best evaluation score: 15.962453\n",
      "Final score: 15.369762\n",
      "\n",
      "Evaluating final policy...\n",
      "Sharp policy price ≈ 15.5310  CI: [15.5150,15.5470] (95% CI)\n",
      "=======================================\n",
      "Sigma Soft = 16.184\n",
      "Price = 15.532 (0.007)\n",
      "Max Price = 15.544\n",
      "=======================================\n",
      "Setting up input normalization...\n",
      "Starting training with early stopping (patience=200, min_epochs=50)\n",
      "Will stop when improvement < 1.00e-02 absolute or < 1.00e-03 relative\n",
      "Early stopping triggered after 285 epochs (12s)\n",
      "Best score: 15.824662\n",
      "No improvement for 200 epochs\n",
      "\n",
      "Training completed after 284 epochs\n",
      "Total training time: 12s\n",
      "Average time per epoch: 0.0s\n",
      "Best evaluation score: 15.824662\n",
      "Final score: 15.232271\n",
      "\n",
      "Evaluating final policy...\n",
      "Sharp policy price ≈ 15.5049  CI: [15.4885,15.5213] (95% CI)\n",
      "Setting up input normalization...\n",
      "Starting training with early stopping (patience=200, min_epochs=50)\n",
      "Will stop when improvement < 1.00e-02 absolute or < 1.00e-03 relative\n",
      "Early stopping triggered after 589 epochs (26s)\n",
      "Best score: 16.199658\n",
      "No improvement for 200 epochs\n",
      "\n",
      "Training completed after 588 epochs\n",
      "Total training time: 26s\n",
      "Average time per epoch: 0.0s\n",
      "Best evaluation score: 16.199658\n",
      "Final score: 15.958273\n",
      "\n",
      "Evaluating final policy...\n",
      "Sharp policy price ≈ 15.5379  CI: [15.5218,15.5541] (95% CI)\n",
      "Setting up input normalization...\n",
      "Starting training with early stopping (patience=200, min_epochs=50)\n",
      "Will stop when improvement < 1.00e-02 absolute or < 1.00e-03 relative\n",
      "Early stopping triggered after 276 epochs (12s)\n",
      "Best score: 15.911902\n",
      "No improvement for 200 epochs\n",
      "\n",
      "Training completed after 275 epochs\n",
      "Total training time: 12s\n",
      "Average time per epoch: 0.0s\n",
      "Best evaluation score: 15.911902\n",
      "Final score: 15.405121\n",
      "\n",
      "Evaluating final policy...\n",
      "Sharp policy price ≈ 15.4966  CI: [15.4802,15.5129] (95% CI)\n",
      "Setting up input normalization...\n",
      "Starting training with early stopping (patience=200, min_epochs=50)\n",
      "Will stop when improvement < 1.00e-02 absolute or < 1.00e-03 relative\n",
      "Early stopping triggered after 308 epochs (13s)\n",
      "Best score: 15.940494\n",
      "No improvement for 200 epochs\n",
      "\n",
      "Training completed after 307 epochs\n",
      "Total training time: 13s\n",
      "Average time per epoch: 0.0s\n",
      "Best evaluation score: 15.940494\n",
      "Final score: 15.352815\n",
      "\n",
      "Evaluating final policy...\n",
      "Sharp policy price ≈ 15.5210  CI: [15.5049,15.5371] (95% CI)\n",
      "=======================================\n",
      "Sigma Soft = 28.480\n",
      "Price = 15.515 (0.016)\n",
      "Max Price = 15.538\n",
      "=======================================\n",
      "Setting up input normalization...\n",
      "Starting training with early stopping (patience=200, min_epochs=50)\n",
      "Will stop when improvement < 1.00e-02 absolute or < 1.00e-03 relative\n",
      "Early stopping triggered after 381 epochs (17s)\n",
      "Best score: 15.803865\n",
      "No improvement for 200 epochs\n",
      "\n",
      "Training completed after 380 epochs\n",
      "Total training time: 17s\n",
      "Average time per epoch: 0.0s\n",
      "Best evaluation score: 15.803865\n",
      "Final score: 15.413201\n",
      "\n",
      "Evaluating final policy...\n",
      "Sharp policy price ≈ 15.4791  CI: [15.4623,15.4959] (95% CI)\n",
      "Setting up input normalization...\n",
      "Starting training with early stopping (patience=200, min_epochs=50)\n",
      "Will stop when improvement < 1.00e-02 absolute or < 1.00e-03 relative\n",
      "Early stopping triggered after 589 epochs (26s)\n",
      "Best score: 16.176302\n",
      "No improvement for 200 epochs\n",
      "\n",
      "Training completed after 588 epochs\n",
      "Total training time: 26s\n",
      "Average time per epoch: 0.0s\n",
      "Best evaluation score: 16.176302\n",
      "Final score: 15.940900\n",
      "\n",
      "Evaluating final policy...\n",
      "Sharp policy price ≈ 15.5244  CI: [15.5080,15.5408] (95% CI)\n",
      "Setting up input normalization...\n",
      "Starting training with early stopping (patience=200, min_epochs=50)\n",
      "Will stop when improvement < 1.00e-02 absolute or < 1.00e-03 relative\n",
      "Early stopping triggered after 276 epochs (16s)\n",
      "Best score: 15.880012\n",
      "No improvement for 200 epochs\n",
      "\n",
      "Training completed after 275 epochs\n",
      "Total training time: 16s\n",
      "Average time per epoch: 0.1s\n",
      "Best evaluation score: 15.880012\n",
      "Final score: 15.380084\n",
      "\n",
      "Evaluating final policy...\n",
      "Sharp policy price ≈ 15.4788  CI: [15.4623,15.4953] (95% CI)\n",
      "Setting up input normalization...\n",
      "Starting training with early stopping (patience=200, min_epochs=50)\n",
      "Will stop when improvement < 1.00e-02 absolute or < 1.00e-03 relative\n",
      "Early stopping triggered after 308 epochs (13s)\n",
      "Best score: 15.913975\n",
      "No improvement for 200 epochs\n",
      "\n",
      "Training completed after 307 epochs\n",
      "Total training time: 13s\n",
      "Average time per epoch: 0.0s\n",
      "Best evaluation score: 15.913975\n",
      "Final score: 15.336333\n",
      "\n",
      "Evaluating final policy...\n",
      "Sharp policy price ≈ 15.5010  CI: [15.4848,15.5173] (95% CI)\n",
      "=======================================\n",
      "Sigma Soft = 50.119\n",
      "Price = 15.496 (0.019)\n",
      "Max Price = 15.524\n",
      "=======================================\n"
     ]
    }
   ],
   "source": [
    "d = 2\n",
    "seed = 42\n",
    "\n",
    "n_trials = 4\n",
    "\n",
    "sigma_soft = np.logspace(-1, 1.7, num=12)\n",
    "acc = []\n",
    "\n",
    "S0_vec       = np.full(d, 100.0, dtype=np.float32)\n",
    "sigma_vec    = np.full(d, 0.2, dtype=np.float32)\n",
    "q_vec        = np.array([0.05, 0.15], dtype=np.float32)\n",
    "rho          = 0.0\n",
    "r            = 0.05\n",
    "K            = 100.0\n",
    "T            = 3.0\n",
    "num_steps    = 9\n",
    "dt           = T / num_steps\n",
    "\n",
    "for s in sigma_soft:\n",
    "    prices = []\n",
    "    times = []\n",
    "\n",
    "    for trial in range(n_trials):\n",
    "        net, train_hist, eval_hist, training_time = train_net(\n",
    "        soft_sigma=s,\n",
    "        N_train=10_000,\n",
    "        batch=500,\n",
    "        lr=0.007,\n",
    "        seed=seed + trial,\n",
    "        eval_every=10,\n",
    "        width=64,\n",
    "        depth=2,\n",
    "        dropout=0.1,\n",
    "        curriculum=False,\n",
    "        patience=200,            \n",
    "        min_delta=1e-2,      \n",
    "        relative_threshold=1e-3,\n",
    "        min_epochs=50,         \n",
    "        max_epochs=2000     \n",
    "        )\n",
    "        times.append(training_time)\n",
    "    \n",
    "        print(\"\\nEvaluating final policy...\")\n",
    "        sharp_mean, sharp_se = evaluate_sharp_policy(net, N_eval=5_000_000)\n",
    "        prices.append(sharp_mean)\n",
    "        print(f\"Sharp policy price ≈ {sharp_mean:.4f}  CI: [{sharp_mean - 1.96*sharp_se:.4f},{sharp_mean + 1.96*sharp_se:.4f}] (95% CI)\")\n",
    "    \n",
    "    print(\"=======================================\")\n",
    "    print(f\"Sigma Soft = {s:.3f}\")\n",
    "    print(f\"Price = {np.mean(prices):.3f} ({np.std(prices):.3f})\")\n",
    "    print(f\"Max Price = {np.max(prices):.3f}\")\n",
    "    print(\"=======================================\")\n",
    "    acc.append((np.mean(prices), np.std(prices), np.max(prices)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "id": "0ef2c99e-e470-4d84-9653-79b9287ccfcf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.1       ,  0.17597645,  0.3096771 ,  0.54495876,  0.95899906,\n",
       "        1.68761248,  2.96980048,  5.22614937,  9.19679199, 16.18418779,\n",
       "       28.48035868, 50.11872336])"
      ]
     },
     "execution_count": 166,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sigma_soft"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "id": "347f0f54-b2ce-441e-8a24-1c492ff3e681",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(15.373937845230103, 0.16209327489193548, 15.500861167907715),\n",
       " (15.421075582504272, 0.15001916236060775, 15.509710311889648),\n",
       " (15.521926403045654, 0.010282273381214216, 15.533257484436035),\n",
       " (15.530131340026855, 0.012052922986671986, 15.545076370239258),\n",
       " (15.535664081573486, 0.0112654046147396, 15.546310424804688),\n",
       " (15.54342794418335, 0.004287714344111217, 15.54901123046875),\n",
       " (15.541552543640137, 0.004972379738340285, 15.546425819396973),\n",
       " (15.541210412979126, 0.0033317588066676136, 15.546699523925781),\n",
       " (15.538328409194946, 0.00415381485654682, 15.542022705078125),\n",
       " (15.53195595741272, 0.007441624862730563, 15.544259071350098),\n",
       " (15.515091180801392, 0.015838079193604544, 15.537912368774414),\n",
       " (15.495837688446045, 0.01879598571318287, 15.524399757385254)]"
      ]
     },
     "execution_count": 167,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "id": "33b95f67-aac8-4df2-8a15-96a914fa0f38",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "id": "16d928ef-0898-41a2-92ee-0d6fc633c0b9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style type=\"text/css\">\n",
       "#T_5aecc th {\n",
       "  text-align: center;\n",
       "}\n",
       "#T_5aecc td {\n",
       "  text-align: center;\n",
       "}\n",
       "</style>\n",
       "<table id=\"T_5aecc\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th id=\"T_5aecc_level0_col0\" class=\"col_heading level0 col0\" >sigma_soft</th>\n",
       "      <th id=\"T_5aecc_level0_col1\" class=\"col_heading level0 col1\" >mean_acc</th>\n",
       "      <th id=\"T_5aecc_level0_col2\" class=\"col_heading level0 col2\" >std_acc</th>\n",
       "      <th id=\"T_5aecc_level0_col3\" class=\"col_heading level0 col3\" >max_acc</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td id=\"T_5aecc_row0_col0\" class=\"data row0 col0\" >0.100</td>\n",
       "      <td id=\"T_5aecc_row0_col1\" class=\"data row0 col1\" >15.374</td>\n",
       "      <td id=\"T_5aecc_row0_col2\" class=\"data row0 col2\" >0.162</td>\n",
       "      <td id=\"T_5aecc_row0_col3\" class=\"data row0 col3\" >15.501</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td id=\"T_5aecc_row1_col0\" class=\"data row1 col0\" >0.176</td>\n",
       "      <td id=\"T_5aecc_row1_col1\" class=\"data row1 col1\" >15.421</td>\n",
       "      <td id=\"T_5aecc_row1_col2\" class=\"data row1 col2\" >0.150</td>\n",
       "      <td id=\"T_5aecc_row1_col3\" class=\"data row1 col3\" >15.510</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td id=\"T_5aecc_row2_col0\" class=\"data row2 col0\" >0.310</td>\n",
       "      <td id=\"T_5aecc_row2_col1\" class=\"data row2 col1\" >15.522</td>\n",
       "      <td id=\"T_5aecc_row2_col2\" class=\"data row2 col2\" >0.010</td>\n",
       "      <td id=\"T_5aecc_row2_col3\" class=\"data row2 col3\" >15.533</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td id=\"T_5aecc_row3_col0\" class=\"data row3 col0\" >0.545</td>\n",
       "      <td id=\"T_5aecc_row3_col1\" class=\"data row3 col1\" >15.530</td>\n",
       "      <td id=\"T_5aecc_row3_col2\" class=\"data row3 col2\" >0.012</td>\n",
       "      <td id=\"T_5aecc_row3_col3\" class=\"data row3 col3\" >15.545</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td id=\"T_5aecc_row4_col0\" class=\"data row4 col0\" >0.959</td>\n",
       "      <td id=\"T_5aecc_row4_col1\" class=\"data row4 col1\" >15.536</td>\n",
       "      <td id=\"T_5aecc_row4_col2\" class=\"data row4 col2\" >0.011</td>\n",
       "      <td id=\"T_5aecc_row4_col3\" class=\"data row4 col3\" >15.546</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td id=\"T_5aecc_row5_col0\" class=\"data row5 col0\" >1.688</td>\n",
       "      <td id=\"T_5aecc_row5_col1\" class=\"data row5 col1\" >15.543</td>\n",
       "      <td id=\"T_5aecc_row5_col2\" class=\"data row5 col2\" >0.004</td>\n",
       "      <td id=\"T_5aecc_row5_col3\" class=\"data row5 col3\" >15.549</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td id=\"T_5aecc_row6_col0\" class=\"data row6 col0\" >2.970</td>\n",
       "      <td id=\"T_5aecc_row6_col1\" class=\"data row6 col1\" >15.542</td>\n",
       "      <td id=\"T_5aecc_row6_col2\" class=\"data row6 col2\" >0.005</td>\n",
       "      <td id=\"T_5aecc_row6_col3\" class=\"data row6 col3\" >15.546</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td id=\"T_5aecc_row7_col0\" class=\"data row7 col0\" >5.226</td>\n",
       "      <td id=\"T_5aecc_row7_col1\" class=\"data row7 col1\" >15.541</td>\n",
       "      <td id=\"T_5aecc_row7_col2\" class=\"data row7 col2\" >0.003</td>\n",
       "      <td id=\"T_5aecc_row7_col3\" class=\"data row7 col3\" >15.547</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td id=\"T_5aecc_row8_col0\" class=\"data row8 col0\" >9.197</td>\n",
       "      <td id=\"T_5aecc_row8_col1\" class=\"data row8 col1\" >15.538</td>\n",
       "      <td id=\"T_5aecc_row8_col2\" class=\"data row8 col2\" >0.004</td>\n",
       "      <td id=\"T_5aecc_row8_col3\" class=\"data row8 col3\" >15.542</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td id=\"T_5aecc_row9_col0\" class=\"data row9 col0\" >16.184</td>\n",
       "      <td id=\"T_5aecc_row9_col1\" class=\"data row9 col1\" >15.532</td>\n",
       "      <td id=\"T_5aecc_row9_col2\" class=\"data row9 col2\" >0.007</td>\n",
       "      <td id=\"T_5aecc_row9_col3\" class=\"data row9 col3\" >15.544</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td id=\"T_5aecc_row10_col0\" class=\"data row10 col0\" >28.480</td>\n",
       "      <td id=\"T_5aecc_row10_col1\" class=\"data row10 col1\" >15.515</td>\n",
       "      <td id=\"T_5aecc_row10_col2\" class=\"data row10 col2\" >0.016</td>\n",
       "      <td id=\"T_5aecc_row10_col3\" class=\"data row10 col3\" >15.538</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td id=\"T_5aecc_row11_col0\" class=\"data row11 col0\" >50.119</td>\n",
       "      <td id=\"T_5aecc_row11_col1\" class=\"data row11 col1\" >15.496</td>\n",
       "      <td id=\"T_5aecc_row11_col2\" class=\"data row11 col2\" >0.019</td>\n",
       "      <td id=\"T_5aecc_row11_col3\" class=\"data row11 col3\" >15.524</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n"
      ],
      "text/plain": [
       "<pandas.io.formats.style.Styler at 0x17caf5730>"
      ]
     },
     "execution_count": 169,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cols = [\"mean_acc\", \"std_acc\", \"max_acc\"]\n",
    "df = pd.DataFrame(acc, columns=cols)\n",
    "df.insert(0, \"sigma_soft\", sigma_soft)  # add the parameter as the first column\n",
    "\n",
    "styled = (\n",
    "    df.style\n",
    "      .format({\"sigma_soft\": \"{:.3f}\",\n",
    "               \"mean_acc\":   \"{:.3f}\",\n",
    "               \"std_acc\":    \"{:.3f}\",\n",
    "               \"max_acc\":    \"{:.3f}\"})\n",
    "      .hide(axis=\"index\")                \n",
    "      .set_table_styles(\n",
    "          [{\"selector\": \"th\",\n",
    "            \"props\": [(\"text-align\", \"center\")]},\n",
    "           {\"selector\": \"td\",\n",
    "            \"props\": [(\"text-align\", \"center\")]}])\n",
    ")\n",
    "styled\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "id": "360ff44c-b48e-47b7-b066-349b62598eab",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<>:16: SyntaxWarning: invalid escape sequence '\\h'\n",
      "<>:16: SyntaxWarning: invalid escape sequence '\\h'\n",
      "/var/folders/zk/dqjkccp920l54p525wpt9gqr0000gn/T/ipykernel_69766/2081451575.py:16: SyntaxWarning: invalid escape sequence '\\h'\n",
      "  plt.ylabel(\"Mean Evaluation Value Function $\\hat{V}_0^{\\\\theta}$\")\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 600x400 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import scienceplots\n",
    "plt.style.context(['science'])\n",
    "plt.figure(figsize=(6, 4))\n",
    "\n",
    "plt.errorbar(\n",
    "    df[\"sigma_soft\"],          # x\n",
    "    df[\"mean_acc\"],            # y\n",
    "    yerr=df[\"std_acc\"],        # ±1 σ\n",
    "    fmt=\"o-\",                  # markers + line\n",
    "    capsize=4\n",
    ")\n",
    "\n",
    "plt.xscale(\"log\")            \n",
    "plt.xlabel(r\"$\\sigma_{\\text{soft}}$\")\n",
    "plt.ylabel(\"Mean Evaluation Value Function $\\hat{V}_0^{\\\\theta}$\")\n",
    "plt.title(r\"Mean Evaluation Value Function vs $\\sigma_{\\text{soft}}$ (log scale)\")\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "id": "47bcf029-5cd7-43a6-ab54-bafb74be861e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Python(80501) MallocStackLogging: can't turn off malloc stack logging because it was not enabled.\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 600x400 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import scienceplots               # pip install scienceplots\n",
    "\n",
    "with plt.style.context(['science', 'grid']):   \n",
    "    fig, ax = plt.subplots(figsize=(6, 4))\n",
    "\n",
    "    ax.errorbar(\n",
    "        df[\"sigma_soft\"],\n",
    "        df[\"mean_acc\"],\n",
    "        yerr=df[\"std_acc\"],\n",
    "        fmt=\".-\",\n",
    "        capsize=4,\n",
    "    )\n",
    "\n",
    "    ax.set_xscale(\"log\")\n",
    "    ax.set_xlabel(r\"$\\sigma_{\\text{soft}}$\")\n",
    "    ax.set_ylabel(r\"Mean Evaluation Value Function $\\hat{V}_0^{\\theta}$\")\n",
    "    ax.set_title(r\"Mean Evaluation Value Function vs $\\sigma_{\\text{soft}}$ (log scale)\")\n",
    "\n",
    "    fig.tight_layout()\n",
    "    plt.savefig('sigma_soft_div_max_call.pdf')\n",
    "\n",
    "    plt.show();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "id": "5c6f7921-df9f-4284-af3d-992ceeae03a4",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/torch/optim/lr_scheduler.py:28: UserWarning: The verbose parameter is deprecated. Please use get_last_lr() to access the learning rate.\n",
      "  warnings.warn(\"The verbose parameter is deprecated. Please use get_last_lr() \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Setting up input normalization...\n",
      "Starting training with early stopping (patience=200, min_epochs=50)\n",
      "Will stop when improvement < 1.00e-02 absolute or < 1.00e-03 relative\n",
      "Early stopping triggered after 285 epochs (11s)\n",
      "Best score: 15.919025\n",
      "No improvement for 200 epochs\n",
      "\n",
      "Training completed after 284 epochs\n",
      "Total training time: 11s\n",
      "Average time per epoch: 0.0s\n",
      "Best evaluation score: 15.919025\n",
      "Final score: 15.197704\n",
      "\n",
      "Evaluating final policy...\n",
      "Sharp policy price ≈ 15.4429  CI: [15.4255,15.4602] (95% CI)\n",
      "=======================================\n",
      "Sigma Soft = 0.100\n",
      "Price = 15.443 (0.000)\n",
      "Max Price = 15.443\n"
     ]
    },
    {
     "ename": "UFuncTypeError",
     "evalue": "ufunc 'add' did not contain a loop with signature matching types (dtype('<U3'), dtype('<U3')) -> None",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mUFuncTypeError\u001b[39m                            Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[150]\u001b[39m\u001b[32m, line 52\u001b[39m\n\u001b[32m     50\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mPrice = \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mnp.mean(prices)\u001b[38;5;132;01m:\u001b[39;00m\u001b[33m.3f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m (\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mnp.std(prices)\u001b[38;5;132;01m:\u001b[39;00m\u001b[33m.3f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m)\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m     51\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mMax Price = \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mnp.max(prices)\u001b[38;5;132;01m:\u001b[39;00m\u001b[33m.3f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m)\n\u001b[32m---> \u001b[39m\u001b[32m52\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mAv. Times = \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[43mnp\u001b[49m\u001b[43m.\u001b[49m\u001b[43mmean\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtimes\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m)\n\u001b[32m     53\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[33m=======================================\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m     54\u001b[39m acc.append((np.mean(prices), np.std(prices), np.max(prices)))\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/numpy/core/fromnumeric.py:3504\u001b[39m, in \u001b[36mmean\u001b[39m\u001b[34m(a, axis, dtype, out, keepdims, where)\u001b[39m\n\u001b[32m   3501\u001b[39m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m   3502\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m mean(axis=axis, dtype=dtype, out=out, **kwargs)\n\u001b[32m-> \u001b[39m\u001b[32m3504\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_methods\u001b[49m\u001b[43m.\u001b[49m\u001b[43m_mean\u001b[49m\u001b[43m(\u001b[49m\u001b[43ma\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis\u001b[49m\u001b[43m=\u001b[49m\u001b[43maxis\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m=\u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   3505\u001b[39m \u001b[43m                      \u001b[49m\u001b[43mout\u001b[49m\u001b[43m=\u001b[49m\u001b[43mout\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/numpy/core/_methods.py:118\u001b[39m, in \u001b[36m_mean\u001b[39m\u001b[34m(a, axis, dtype, out, keepdims, where)\u001b[39m\n\u001b[32m    115\u001b[39m         dtype = mu.dtype(\u001b[33m'\u001b[39m\u001b[33mf4\u001b[39m\u001b[33m'\u001b[39m)\n\u001b[32m    116\u001b[39m         is_float16_result = \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m118\u001b[39m ret = \u001b[43mumr_sum\u001b[49m\u001b[43m(\u001b[49m\u001b[43marr\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mout\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkeepdims\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mwhere\u001b[49m\u001b[43m=\u001b[49m\u001b[43mwhere\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    119\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(ret, mu.ndarray):\n\u001b[32m    120\u001b[39m     \u001b[38;5;28;01mwith\u001b[39;00m _no_nep50_warning():\n",
      "\u001b[31mUFuncTypeError\u001b[39m: ufunc 'add' did not contain a loop with signature matching types (dtype('<U3'), dtype('<U3')) -> None"
     ]
    }
   ],
   "source": [
    "d = 2\n",
    "seed = 42\n",
    "\n",
    "n_trials = 4\n",
    "\n",
    "sigma_soft = np.logspace(-1, 1.5, num=6)\n",
    "acc = []\n",
    "\n",
    "S0_vec       = np.full(d, 100.0, dtype=np.float32)\n",
    "sigma_vec    = np.full(d, 0.2, dtype=np.float32)\n",
    "q_vec        = np.array([0.05, 0.15], dtype=np.float32)\n",
    "rho          = 0.0\n",
    "r            = 0.05\n",
    "K            = 100.0\n",
    "T            = 3.0\n",
    "num_steps    = 9\n",
    "dt           = T / num_steps\n",
    "\n",
    "for s in sigma_soft:\n",
    "    prices = []\n",
    "    times = []\n",
    "\n",
    "    for trial in range(n_trials):\n",
    "        net, train_hist, eval_hist, training_time = train_net(\n",
    "        soft_sigma=s,\n",
    "        N_train=10_000,\n",
    "        batch=500,\n",
    "        lr=0.007,\n",
    "        seed=seed + trial,\n",
    "        eval_every=10,\n",
    "        width=64,\n",
    "        depth=2,\n",
    "        dropout=0.1,\n",
    "        curriculum=False,\n",
    "        patience=200,            \n",
    "        min_delta=1e-2,      \n",
    "        relative_threshold=1e-3,\n",
    "        min_epochs=50,         \n",
    "        max_epochs=2000     \n",
    "        )\n",
    "        times.append(training_time)\n",
    "    \n",
    "        print(\"\\nEvaluating final policy...\")\n",
    "        sharp_mean, sharp_se = evaluate_sharp_policy(net, N_eval=5_000_000)\n",
    "        prices.append(sharp_mean)\n",
    "        print(f\"Sharp policy price ≈ {sharp_mean:.4f}  CI: [{sharp_mean - 1.96*sharp_se:.4f},{sharp_mean + 1.96*sharp_se:.4f}] (95% CI)\")\n",
    "    \n",
    "    print(\"=======================================\")\n",
    "    print(f\"Sigma Soft = {s:.3f}\")\n",
    "    print(f\"Price = {np.mean(prices):.3f} ({np.std(prices):.3f})\")\n",
    "    print(f\"Max Price = {np.max(prices):.3f}\")\n",
    "    print(\"=======================================\")\n",
    "    acc.append((np.mean(prices), np.std(prices), np.max(prices)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "id": "062dd9b1-a9d4-45d8-994f-f0a5d4b6dff1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(15.537816762924194, 0.005199343353425672, 15.54438591003418),\n",
       " (15.537206888198853, 0.005804866266461506, 15.544830322265625),\n",
       " (15.535098632176718, 0.0074669822921103815, 15.544830322265625),\n",
       " (15.531806707382202, 0.011434185640625164, 15.544830322265625),\n",
       " (15.52798376083374, 0.014810440445858775, 15.544830322265625)]"
      ]
     },
     "execution_count": 141,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "id": "0d39afb9-efec-42b7-b3a6-b7f1a98b6a1b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([10.        , 13.33521432, 17.7827941 , 23.71373706, 31.6227766 ])"
      ]
     },
     "execution_count": 142,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sigma_soft"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ddabdf7-1935-4664-a9d6-8009a32e4e93",
   "metadata": {},
   "source": [
    "# d = 2 (Asymm. Vol)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "787589c3-5694-4c26-ad88-665a9337421d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_vol(d):\n",
    "    if d <= 5:\n",
    "        return np.array([0.08 + 0.32 * (i - 1) / (d - 1) for i in range(1,d + 1)], dtype=np.float32)\n",
    "    else:\n",
    "        return np.array([0.1 + i / (2*d) for i in range(1,d + 1)], dtype=np.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "76f4f2d6-c523-4a4a-a5d0-8b2e0ec7b7c6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.08, 0.16, 0.24, 0.32, 0.4 ], dtype=float32)"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_vol(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "3436e947-f71d-4a35-81ff-cba6e316e130",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Setting up input normalization...\n",
      "Starting training with early stopping (patience=200, min_epochs=50)\n",
      "Will stop when improvement < 1.00e-02 absolute or < 1.00e-03 relative\n",
      "Epoch   10 | train‑avg =  19.6807 | soft‑eval =  19.5880 | best =  19.9830 | no_improve =  4 | time = 0s | epoch_time = 0.1s | soft_sigma = 2.000 | lr = 7.00e-03\n",
      "Epoch   20 | train‑avg =  19.6814 | soft‑eval =  19.6968 | best =  20.0247 | no_improve =  7 | time = 0s | epoch_time = 0.0s | soft_sigma = 2.000 | lr = 7.00e-03\n",
      "Epoch   30 | train‑avg =  19.3176 | soft‑eval =  19.7459 | best =  20.3435 | no_improve =  7 | time = 1s | epoch_time = 0.0s | soft_sigma = 2.000 | lr = 7.00e-03\n",
      "Epoch   40 | train‑avg =  19.2728 | soft‑eval =  19.6236 | best =  20.3435 | no_improve = 17 | time = 1s | epoch_time = 0.0s | soft_sigma = 2.000 | lr = 7.00e-03\n",
      "Epoch   50 | train‑avg =  19.3174 | soft‑eval =  19.9785 | best =  20.3435 | no_improve = 27 | time = 2s | epoch_time = 0.0s | soft_sigma = 2.000 | lr = 7.00e-03\n",
      "Epoch   60 | train‑avg =  19.9536 | soft‑eval =  19.9857 | best =  20.3435 | no_improve = 37 | time = 2s | epoch_time = 0.0s | soft_sigma = 2.000 | lr = 7.00e-03\n",
      "Epoch   70 | train‑avg =  19.2022 | soft‑eval =  20.1069 | best =  20.4182 | no_improve =  3 | time = 2s | epoch_time = 0.0s | soft_sigma = 2.000 | lr = 7.00e-03\n",
      "Epoch   80 | train‑avg =  20.5993 | soft‑eval =  19.5058 | best =  20.4182 | no_improve = 13 | time = 3s | epoch_time = 0.0s | soft_sigma = 2.000 | lr = 7.00e-03\n",
      "Epoch   90 | train‑avg =  19.1974 | soft‑eval =  20.0327 | best =  20.4182 | no_improve = 23 | time = 3s | epoch_time = 0.0s | soft_sigma = 2.000 | lr = 7.00e-03\n",
      "Epoch  100 | train‑avg =  20.0176 | soft‑eval =  19.5630 | best =  20.4182 | no_improve = 33 | time = 4s | epoch_time = 0.0s | soft_sigma = 2.000 | lr = 7.00e-03\n",
      "Epoch  110 | train‑avg =  19.5593 | soft‑eval =  20.1765 | best =  20.4182 | no_improve = 43 | time = 4s | epoch_time = 0.0s | soft_sigma = 2.000 | lr = 7.00e-03\n",
      "Epoch  120 | train‑avg =  19.6116 | soft‑eval =  19.8118 | best =  20.4182 | no_improve = 53 | time = 4s | epoch_time = 0.0s | soft_sigma = 2.000 | lr = 7.00e-03\n",
      "Epoch  130 | train‑avg =  19.6614 | soft‑eval =  19.8697 | best =  20.4182 | no_improve = 63 | time = 5s | epoch_time = 0.0s | soft_sigma = 2.000 | lr = 7.00e-03\n",
      "Epoch  140 | train‑avg =  20.3144 | soft‑eval =  19.7386 | best =  20.4691 | no_improve =  7 | time = 5s | epoch_time = 0.0s | soft_sigma = 2.000 | lr = 7.00e-03\n",
      "Epoch  150 | train‑avg =  20.2420 | soft‑eval =  19.6773 | best =  20.4691 | no_improve = 17 | time = 6s | epoch_time = 0.0s | soft_sigma = 2.000 | lr = 7.00e-03\n",
      "Epoch  160 | train‑avg =  19.8163 | soft‑eval =  19.3336 | best =  20.4691 | no_improve = 27 | time = 6s | epoch_time = 0.0s | soft_sigma = 2.000 | lr = 7.00e-03\n",
      "Epoch  170 | train‑avg =  20.0135 | soft‑eval =  19.6978 | best =  20.4691 | no_improve = 37 | time = 6s | epoch_time = 0.0s | soft_sigma = 2.000 | lr = 7.00e-03\n",
      "Epoch  180 | train‑avg =  18.7575 | soft‑eval =  19.8908 | best =  20.4691 | no_improve = 47 | time = 7s | epoch_time = 0.0s | soft_sigma = 2.000 | lr = 7.00e-03\n",
      "Epoch  190 | train‑avg =  19.9327 | soft‑eval =  19.8260 | best =  20.4691 | no_improve = 57 | time = 7s | epoch_time = 0.0s | soft_sigma = 2.000 | lr = 7.00e-03\n",
      "Epoch  200 | train‑avg =  19.8440 | soft‑eval =  19.5202 | best =  20.4691 | no_improve = 67 | time = 7s | epoch_time = 0.0s | soft_sigma = 2.000 | lr = 7.00e-03\n",
      "Epoch  210 | train‑avg =  19.2203 | soft‑eval =  19.1377 | best =  20.4691 | no_improve = 77 | time = 8s | epoch_time = 0.0s | soft_sigma = 2.000 | lr = 7.00e-03\n",
      "Epoch  220 | train‑avg =  19.5296 | soft‑eval =  20.2209 | best =  20.4691 | no_improve = 87 | time = 8s | epoch_time = 0.0s | soft_sigma = 2.000 | lr = 7.00e-03\n",
      "Epoch  230 | train‑avg =  20.0728 | soft‑eval =  19.8732 | best =  20.4691 | no_improve = 97 | time = 9s | epoch_time = 0.0s | soft_sigma = 2.000 | lr = 7.00e-03\n",
      "Epoch  240 | train‑avg =  19.9335 | soft‑eval =  19.8800 | best =  20.4691 | no_improve = 107 | time = 9s | epoch_time = 0.0s | soft_sigma = 2.000 | lr = 7.00e-03\n",
      "Epoch  250 | train‑avg =  19.5621 | soft‑eval =  19.9412 | best =  20.4691 | no_improve = 117 | time = 9s | epoch_time = 0.0s | soft_sigma = 2.000 | lr = 7.00e-03\n",
      "Epoch  260 | train‑avg =  19.7839 | soft‑eval =  19.3958 | best =  20.4691 | no_improve = 127 | time = 10s | epoch_time = 0.0s | soft_sigma = 2.000 | lr = 7.00e-03\n",
      "Epoch  270 | train‑avg =  19.2469 | soft‑eval =  19.7995 | best =  20.4691 | no_improve = 137 | time = 10s | epoch_time = 0.0s | soft_sigma = 2.000 | lr = 7.00e-03\n",
      "Epoch  280 | train‑avg =  19.5497 | soft‑eval =  19.7209 | best =  20.4691 | no_improve = 147 | time = 11s | epoch_time = 0.0s | soft_sigma = 2.000 | lr = 7.00e-03\n",
      "Epoch  290 | train‑avg =  19.5397 | soft‑eval =  19.7094 | best =  20.4691 | no_improve = 157 | time = 11s | epoch_time = 0.0s | soft_sigma = 2.000 | lr = 7.00e-03\n",
      "Epoch  300 | train‑avg =  19.3072 | soft‑eval =  19.7143 | best =  20.4691 | no_improve = 167 | time = 12s | epoch_time = 0.0s | soft_sigma = 2.000 | lr = 7.00e-03\n",
      "Epoch  310 | train‑avg =  19.8494 | soft‑eval =  19.5310 | best =  20.4691 | no_improve = 177 | time = 12s | epoch_time = 0.0s | soft_sigma = 2.000 | lr = 7.00e-03\n",
      "Epoch  320 | train‑avg =  19.7967 | soft‑eval =  19.5783 | best =  20.4691 | no_improve = 187 | time = 12s | epoch_time = 0.0s | soft_sigma = 2.000 | lr = 7.00e-03\n",
      "Epoch  330 | train‑avg =  19.7820 | soft‑eval =  19.4973 | best =  20.4691 | no_improve = 197 | time = 13s | epoch_time = 0.0s | soft_sigma = 2.000 | lr = 7.00e-03\n",
      "Early stopping triggered after 333 epochs (13s)\n",
      "Best score: 20.469063\n",
      "No improvement for 200 epochs\n",
      "\n",
      "Training completed after 332 epochs\n",
      "Total training time: 13s\n",
      "Average time per epoch: 0.0s\n",
      "Best evaluation score: 20.469063\n",
      "Final score: 20.030043\n",
      "\n",
      "Evaluating final policy...\n",
      "Sharp policy price ≈ 19.7982  CI: [19.7717,19.8247] (95% CI)\n",
      "Setting up input normalization...\n",
      "Starting training with early stopping (patience=200, min_epochs=50)\n",
      "Will stop when improvement < 1.00e-02 absolute or < 1.00e-03 relative\n",
      "Epoch   10 | train‑avg =  19.6991 | soft‑eval =  19.7020 | best =  19.8125 | no_improve =  3 | time = 0s | epoch_time = 0.0s | soft_sigma = 2.000 | lr = 7.00e-03\n",
      "Epoch   20 | train‑avg =  19.5767 | soft‑eval =  19.9295 | best =  19.8609 | no_improve =  0 | time = 0s | epoch_time = 0.0s | soft_sigma = 2.000 | lr = 7.00e-03\n",
      "Epoch   30 | train‑avg =  19.2063 | soft‑eval =  19.6998 | best =  20.4068 | no_improve =  3 | time = 1s | epoch_time = 0.0s | soft_sigma = 2.000 | lr = 7.00e-03\n",
      "Epoch   40 | train‑avg =  19.9866 | soft‑eval =  19.4974 | best =  20.4068 | no_improve = 13 | time = 1s | epoch_time = 0.0s | soft_sigma = 2.000 | lr = 7.00e-03\n",
      "Epoch   50 | train‑avg =  19.4758 | soft‑eval =  20.1637 | best =  20.4068 | no_improve = 23 | time = 1s | epoch_time = 0.0s | soft_sigma = 2.000 | lr = 7.00e-03\n",
      "Epoch   60 | train‑avg =  19.2233 | soft‑eval =  19.8974 | best =  20.4068 | no_improve = 33 | time = 2s | epoch_time = 0.0s | soft_sigma = 2.000 | lr = 7.00e-03\n",
      "Epoch   70 | train‑avg =  19.2583 | soft‑eval =  19.8968 | best =  20.4068 | no_improve = 43 | time = 2s | epoch_time = 0.0s | soft_sigma = 2.000 | lr = 7.00e-03\n",
      "Epoch   80 | train‑avg =  19.9454 | soft‑eval =  19.3598 | best =  20.4068 | no_improve = 53 | time = 3s | epoch_time = 0.0s | soft_sigma = 2.000 | lr = 7.00e-03\n",
      "Epoch   90 | train‑avg =  19.5785 | soft‑eval =  19.8243 | best =  20.4068 | no_improve = 63 | time = 3s | epoch_time = 0.0s | soft_sigma = 2.000 | lr = 7.00e-03\n",
      "Epoch  100 | train‑avg =  19.7235 | soft‑eval =  19.7994 | best =  20.4068 | no_improve = 73 | time = 3s | epoch_time = 0.0s | soft_sigma = 2.000 | lr = 7.00e-03\n",
      "Epoch  110 | train‑avg =  19.7669 | soft‑eval =  19.6920 | best =  20.4068 | no_improve = 83 | time = 4s | epoch_time = 0.0s | soft_sigma = 2.000 | lr = 7.00e-03\n",
      "Epoch  120 | train‑avg =  20.1964 | soft‑eval =  20.4512 | best =  20.4068 | no_improve = 93 | time = 4s | epoch_time = 0.0s | soft_sigma = 2.000 | lr = 7.00e-03\n",
      "Epoch  130 | train‑avg =  19.7175 | soft‑eval =  19.6289 | best =  20.4512 | no_improve =  9 | time = 4s | epoch_time = 0.0s | soft_sigma = 2.000 | lr = 7.00e-03\n",
      "Epoch  140 | train‑avg =  20.0584 | soft‑eval =  20.2595 | best =  20.4847 | no_improve =  8 | time = 5s | epoch_time = 0.0s | soft_sigma = 2.000 | lr = 7.00e-03\n",
      "Epoch  150 | train‑avg =  19.5595 | soft‑eval =  19.1963 | best =  20.4847 | no_improve = 18 | time = 5s | epoch_time = 0.0s | soft_sigma = 2.000 | lr = 7.00e-03\n",
      "Epoch  160 | train‑avg =  19.8844 | soft‑eval =  19.4045 | best =  20.4847 | no_improve = 28 | time = 6s | epoch_time = 0.0s | soft_sigma = 2.000 | lr = 7.00e-03\n",
      "Epoch  170 | train‑avg =  19.8313 | soft‑eval =  19.2771 | best =  20.4847 | no_improve = 38 | time = 6s | epoch_time = 0.0s | soft_sigma = 2.000 | lr = 7.00e-03\n",
      "Epoch  180 | train‑avg =  19.6872 | soft‑eval =  19.3900 | best =  20.4847 | no_improve = 48 | time = 6s | epoch_time = 0.0s | soft_sigma = 2.000 | lr = 7.00e-03\n",
      "Epoch  190 | train‑avg =  19.6203 | soft‑eval =  20.3203 | best =  20.4847 | no_improve = 58 | time = 7s | epoch_time = 0.0s | soft_sigma = 2.000 | lr = 7.00e-03\n",
      "Epoch  200 | train‑avg =  19.5084 | soft‑eval =  20.2734 | best =  20.4847 | no_improve = 68 | time = 7s | epoch_time = 0.0s | soft_sigma = 2.000 | lr = 7.00e-03\n",
      "Epoch  210 | train‑avg =  19.6713 | soft‑eval =  19.3631 | best =  20.4847 | no_improve = 78 | time = 7s | epoch_time = 0.0s | soft_sigma = 2.000 | lr = 7.00e-03\n",
      "Epoch  220 | train‑avg =  19.9600 | soft‑eval =  20.2881 | best =  20.4847 | no_improve = 88 | time = 8s | epoch_time = 0.0s | soft_sigma = 2.000 | lr = 7.00e-03\n",
      "Epoch  230 | train‑avg =  19.8487 | soft‑eval =  19.4695 | best =  20.4847 | no_improve = 98 | time = 8s | epoch_time = 0.0s | soft_sigma = 2.000 | lr = 7.00e-03\n",
      "Epoch  240 | train‑avg =  20.1705 | soft‑eval =  19.5344 | best =  20.4847 | no_improve = 108 | time = 9s | epoch_time = 0.0s | soft_sigma = 2.000 | lr = 7.00e-03\n",
      "Epoch  250 | train‑avg =  19.4551 | soft‑eval =  19.6306 | best =  20.4847 | no_improve = 118 | time = 9s | epoch_time = 0.0s | soft_sigma = 2.000 | lr = 7.00e-03\n",
      "Epoch  260 | train‑avg =  20.0102 | soft‑eval =  19.9714 | best =  20.4847 | no_improve = 128 | time = 9s | epoch_time = 0.0s | soft_sigma = 2.000 | lr = 7.00e-03\n",
      "Epoch  270 | train‑avg =  19.9280 | soft‑eval =  20.4993 | best =  20.4847 | no_improve = 138 | time = 10s | epoch_time = 0.0s | soft_sigma = 2.000 | lr = 7.00e-03\n",
      "Epoch  280 | train‑avg =  19.8252 | soft‑eval =  19.9246 | best =  20.4847 | no_improve = 148 | time = 10s | epoch_time = 0.0s | soft_sigma = 2.000 | lr = 7.00e-03\n",
      "Epoch  290 | train‑avg =  20.1285 | soft‑eval =  19.4061 | best =  20.4847 | no_improve = 158 | time = 11s | epoch_time = 0.0s | soft_sigma = 2.000 | lr = 7.00e-03\n",
      "Epoch  300 | train‑avg =  19.5411 | soft‑eval =  20.3511 | best =  20.4847 | no_improve = 168 | time = 11s | epoch_time = 0.0s | soft_sigma = 2.000 | lr = 7.00e-03\n",
      "Epoch  310 | train‑avg =  19.8095 | soft‑eval =  19.6671 | best =  20.4847 | no_improve = 178 | time = 11s | epoch_time = 0.0s | soft_sigma = 2.000 | lr = 7.00e-03\n",
      "Epoch  320 | train‑avg =  20.2290 | soft‑eval =  19.5267 | best =  20.4847 | no_improve = 188 | time = 12s | epoch_time = 0.0s | soft_sigma = 2.000 | lr = 7.00e-03\n",
      "Epoch  330 | train‑avg =  19.7723 | soft‑eval =  19.9940 | best =  20.4847 | no_improve = 198 | time = 12s | epoch_time = 0.0s | soft_sigma = 2.000 | lr = 7.00e-03\n",
      "Early stopping triggered after 332 epochs (12s)\n",
      "Best score: 20.484663\n",
      "No improvement for 200 epochs\n",
      "\n",
      "Training completed after 331 epochs\n",
      "Total training time: 12s\n",
      "Average time per epoch: 0.0s\n",
      "Best evaluation score: 20.484663\n",
      "Final score: 20.111864\n",
      "\n",
      "Evaluating final policy...\n",
      "Sharp policy price ≈ 19.7930  CI: [19.7661,19.8200] (95% CI)\n",
      "Setting up input normalization...\n",
      "Starting training with early stopping (patience=200, min_epochs=50)\n",
      "Will stop when improvement < 1.00e-02 absolute or < 1.00e-03 relative\n",
      "Epoch   10 | train‑avg =  19.5807 | soft‑eval =  19.7139 | best =  19.9305 | no_improve =  3 | time = 0s | epoch_time = 0.0s | soft_sigma = 2.000 | lr = 7.00e-03\n",
      "Epoch   20 | train‑avg =  19.8386 | soft‑eval =  20.1462 | best =  20.1534 | no_improve =  8 | time = 0s | epoch_time = 0.0s | soft_sigma = 2.000 | lr = 7.00e-03\n",
      "Epoch   30 | train‑avg =  20.0438 | soft‑eval =  19.8692 | best =  20.2058 | no_improve =  0 | time = 1s | epoch_time = 0.0s | soft_sigma = 2.000 | lr = 7.00e-03\n",
      "Epoch   40 | train‑avg =  19.8699 | soft‑eval =  19.6575 | best =  20.2157 | no_improve =  2 | time = 1s | epoch_time = 0.0s | soft_sigma = 2.000 | lr = 7.00e-03\n",
      "Epoch   50 | train‑avg =  19.7772 | soft‑eval =  20.4842 | best =  20.2157 | no_improve = 12 | time = 1s | epoch_time = 0.0s | soft_sigma = 2.000 | lr = 7.00e-03\n",
      "Epoch   60 | train‑avg =  19.2878 | soft‑eval =  19.6523 | best =  20.4842 | no_improve =  9 | time = 2s | epoch_time = 0.0s | soft_sigma = 2.000 | lr = 7.00e-03\n",
      "Epoch   70 | train‑avg =  19.8392 | soft‑eval =  20.1008 | best =  20.5198 | no_improve =  8 | time = 2s | epoch_time = 0.0s | soft_sigma = 2.000 | lr = 7.00e-03\n",
      "Epoch   80 | train‑avg =  20.0328 | soft‑eval =  19.7232 | best =  20.5198 | no_improve = 18 | time = 3s | epoch_time = 0.0s | soft_sigma = 2.000 | lr = 7.00e-03\n",
      "Epoch   90 | train‑avg =  19.4455 | soft‑eval =  19.3498 | best =  20.5198 | no_improve = 28 | time = 3s | epoch_time = 0.0s | soft_sigma = 2.000 | lr = 7.00e-03\n",
      "Epoch  100 | train‑avg =  19.8786 | soft‑eval =  19.9353 | best =  20.5198 | no_improve = 38 | time = 3s | epoch_time = 0.0s | soft_sigma = 2.000 | lr = 7.00e-03\n",
      "Epoch  110 | train‑avg =  19.5741 | soft‑eval =  20.1098 | best =  20.5198 | no_improve = 48 | time = 4s | epoch_time = 0.0s | soft_sigma = 2.000 | lr = 7.00e-03\n",
      "Epoch  120 | train‑avg =  19.6861 | soft‑eval =  19.5672 | best =  20.5198 | no_improve = 58 | time = 4s | epoch_time = 0.0s | soft_sigma = 2.000 | lr = 7.00e-03\n",
      "Epoch  130 | train‑avg =  19.3945 | soft‑eval =  20.0317 | best =  20.5198 | no_improve = 68 | time = 4s | epoch_time = 0.0s | soft_sigma = 2.000 | lr = 7.00e-03\n",
      "Epoch  140 | train‑avg =  20.0733 | soft‑eval =  19.2989 | best =  20.5791 | no_improve =  1 | time = 5s | epoch_time = 0.0s | soft_sigma = 2.000 | lr = 7.00e-03\n",
      "Epoch  150 | train‑avg =  19.7232 | soft‑eval =  19.5209 | best =  20.5791 | no_improve = 11 | time = 5s | epoch_time = 0.0s | soft_sigma = 2.000 | lr = 7.00e-03\n",
      "Epoch  160 | train‑avg =  19.3482 | soft‑eval =  19.7842 | best =  20.5791 | no_improve = 21 | time = 6s | epoch_time = 0.0s | soft_sigma = 2.000 | lr = 7.00e-03\n",
      "Epoch  170 | train‑avg =  19.7873 | soft‑eval =  19.9006 | best =  20.5791 | no_improve = 31 | time = 6s | epoch_time = 0.0s | soft_sigma = 2.000 | lr = 7.00e-03\n",
      "Epoch  180 | train‑avg =  19.3510 | soft‑eval =  19.9957 | best =  20.5791 | no_improve = 41 | time = 6s | epoch_time = 0.0s | soft_sigma = 2.000 | lr = 7.00e-03\n",
      "Epoch  190 | train‑avg =  19.5703 | soft‑eval =  19.4612 | best =  20.7406 | no_improve =  1 | time = 7s | epoch_time = 0.0s | soft_sigma = 2.000 | lr = 7.00e-03\n",
      "Epoch  200 | train‑avg =  19.7415 | soft‑eval =  20.1555 | best =  20.7406 | no_improve = 11 | time = 7s | epoch_time = 0.0s | soft_sigma = 2.000 | lr = 7.00e-03\n",
      "Epoch  210 | train‑avg =  19.4178 | soft‑eval =  20.0433 | best =  20.7406 | no_improve = 21 | time = 7s | epoch_time = 0.0s | soft_sigma = 2.000 | lr = 3.50e-03\n",
      "Epoch  220 | train‑avg =  19.7899 | soft‑eval =  20.0076 | best =  20.7406 | no_improve = 31 | time = 8s | epoch_time = 0.0s | soft_sigma = 2.000 | lr = 3.50e-03\n",
      "Epoch  230 | train‑avg =  19.4619 | soft‑eval =  19.7685 | best =  20.7406 | no_improve = 41 | time = 8s | epoch_time = 0.0s | soft_sigma = 2.000 | lr = 3.50e-03\n",
      "Epoch  240 | train‑avg =  19.3521 | soft‑eval =  20.3048 | best =  20.7406 | no_improve = 51 | time = 9s | epoch_time = 0.0s | soft_sigma = 2.000 | lr = 3.50e-03\n",
      "Epoch  250 | train‑avg =  19.7365 | soft‑eval =  19.5196 | best =  20.7406 | no_improve = 61 | time = 9s | epoch_time = 0.0s | soft_sigma = 2.000 | lr = 3.50e-03\n",
      "Epoch  260 | train‑avg =  19.8072 | soft‑eval =  19.9523 | best =  20.7406 | no_improve = 71 | time = 9s | epoch_time = 0.0s | soft_sigma = 2.000 | lr = 3.50e-03\n",
      "Epoch  270 | train‑avg =  19.5671 | soft‑eval =  19.6390 | best =  20.7406 | no_improve = 81 | time = 10s | epoch_time = 0.0s | soft_sigma = 2.000 | lr = 3.50e-03\n",
      "Epoch  280 | train‑avg =  19.5784 | soft‑eval =  19.7142 | best =  20.7406 | no_improve = 91 | time = 10s | epoch_time = 0.0s | soft_sigma = 2.000 | lr = 3.50e-03\n",
      "Epoch  290 | train‑avg =  19.9402 | soft‑eval =  19.3289 | best =  20.7406 | no_improve = 101 | time = 10s | epoch_time = 0.0s | soft_sigma = 2.000 | lr = 3.50e-03\n",
      "Epoch  300 | train‑avg =  19.7704 | soft‑eval =  19.4365 | best =  20.7406 | no_improve = 111 | time = 11s | epoch_time = 0.0s | soft_sigma = 2.000 | lr = 3.50e-03\n",
      "Epoch  310 | train‑avg =  20.1748 | soft‑eval =  19.3541 | best =  20.7406 | no_improve = 121 | time = 11s | epoch_time = 0.0s | soft_sigma = 2.000 | lr = 3.50e-03\n",
      "Epoch  320 | train‑avg =  19.6666 | soft‑eval =  19.3312 | best =  20.7406 | no_improve = 131 | time = 11s | epoch_time = 0.0s | soft_sigma = 2.000 | lr = 3.50e-03\n",
      "Epoch  330 | train‑avg =  19.6429 | soft‑eval =  19.6997 | best =  20.7406 | no_improve = 141 | time = 12s | epoch_time = 0.0s | soft_sigma = 2.000 | lr = 3.50e-03\n",
      "Epoch  340 | train‑avg =  19.6292 | soft‑eval =  19.6914 | best =  20.7406 | no_improve = 151 | time = 12s | epoch_time = 0.0s | soft_sigma = 2.000 | lr = 3.50e-03\n",
      "Epoch  350 | train‑avg =  20.0718 | soft‑eval =  19.8822 | best =  20.7406 | no_improve = 161 | time = 13s | epoch_time = 0.0s | soft_sigma = 2.000 | lr = 3.50e-03\n",
      "Epoch  360 | train‑avg =  20.2078 | soft‑eval =  19.8953 | best =  20.7406 | no_improve = 171 | time = 13s | epoch_time = 0.0s | soft_sigma = 2.000 | lr = 3.50e-03\n",
      "Epoch  370 | train‑avg =  19.4807 | soft‑eval =  20.0670 | best =  20.7406 | no_improve = 181 | time = 14s | epoch_time = 0.0s | soft_sigma = 2.000 | lr = 1.75e-03\n",
      "Epoch  380 | train‑avg =  19.4835 | soft‑eval =  19.8643 | best =  20.7406 | no_improve = 191 | time = 14s | epoch_time = 0.0s | soft_sigma = 2.000 | lr = 1.75e-03\n",
      "Early stopping triggered after 389 epochs (14s)\n",
      "Best score: 20.740617\n",
      "No improvement for 200 epochs\n",
      "\n",
      "Training completed after 388 epochs\n",
      "Total training time: 14s\n",
      "Average time per epoch: 0.0s\n",
      "Best evaluation score: 20.740617\n",
      "Final score: 19.666021\n",
      "\n",
      "Evaluating final policy...\n",
      "Sharp policy price ≈ 19.7926  CI: [19.7653,19.8199] (95% CI)\n",
      "Setting up input normalization...\n",
      "Starting training with early stopping (patience=200, min_epochs=50)\n",
      "Will stop when improvement < 1.00e-02 absolute or < 1.00e-03 relative\n",
      "Epoch   10 | train‑avg =  19.5142 | soft‑eval =  19.8424 | best =  20.0568 | no_improve =  0 | time = 0s | epoch_time = 0.0s | soft_sigma = 2.000 | lr = 7.00e-03\n",
      "Epoch   20 | train‑avg =  19.2813 | soft‑eval =  19.4122 | best =  20.1792 | no_improve =  7 | time = 0s | epoch_time = 0.0s | soft_sigma = 2.000 | lr = 7.00e-03\n",
      "Epoch   30 | train‑avg =  20.2729 | soft‑eval =  19.8843 | best =  20.1792 | no_improve = 17 | time = 1s | epoch_time = 0.0s | soft_sigma = 2.000 | lr = 7.00e-03\n",
      "Epoch   40 | train‑avg =  19.4572 | soft‑eval =  20.0270 | best =  20.1792 | no_improve = 27 | time = 1s | epoch_time = 0.0s | soft_sigma = 2.000 | lr = 7.00e-03\n",
      "Epoch   50 | train‑avg =  20.2693 | soft‑eval =  19.5512 | best =  20.1795 | no_improve =  6 | time = 2s | epoch_time = 0.0s | soft_sigma = 2.000 | lr = 7.00e-03\n",
      "Epoch   60 | train‑avg =  19.6296 | soft‑eval =  19.7326 | best =  20.1795 | no_improve = 16 | time = 2s | epoch_time = 0.0s | soft_sigma = 2.000 | lr = 7.00e-03\n",
      "Epoch   70 | train‑avg =  19.7418 | soft‑eval =  19.4911 | best =  20.4026 | no_improve =  4 | time = 2s | epoch_time = 0.0s | soft_sigma = 2.000 | lr = 7.00e-03\n",
      "Epoch   80 | train‑avg =  19.6219 | soft‑eval =  19.8406 | best =  20.4026 | no_improve = 14 | time = 3s | epoch_time = 0.0s | soft_sigma = 2.000 | lr = 7.00e-03\n",
      "Epoch   90 | train‑avg =  19.5779 | soft‑eval =  20.0679 | best =  20.4026 | no_improve = 24 | time = 3s | epoch_time = 0.0s | soft_sigma = 2.000 | lr = 7.00e-03\n",
      "Epoch  100 | train‑avg =  19.7179 | soft‑eval =  19.8250 | best =  20.4866 | no_improve =  3 | time = 4s | epoch_time = 0.0s | soft_sigma = 2.000 | lr = 7.00e-03\n",
      "Epoch  110 | train‑avg =  19.4399 | soft‑eval =  19.5885 | best =  20.4866 | no_improve = 13 | time = 4s | epoch_time = 0.0s | soft_sigma = 2.000 | lr = 7.00e-03\n",
      "Epoch  120 | train‑avg =  19.6169 | soft‑eval =  19.3581 | best =  20.4866 | no_improve = 23 | time = 4s | epoch_time = 0.0s | soft_sigma = 2.000 | lr = 7.00e-03\n",
      "Epoch  130 | train‑avg =  19.8542 | soft‑eval =  19.5003 | best =  20.5577 | no_improve =  7 | time = 5s | epoch_time = 0.0s | soft_sigma = 2.000 | lr = 7.00e-03\n",
      "Epoch  140 | train‑avg =  20.0868 | soft‑eval =  19.1362 | best =  20.5577 | no_improve = 17 | time = 5s | epoch_time = 0.0s | soft_sigma = 2.000 | lr = 7.00e-03\n",
      "Epoch  150 | train‑avg =  19.5721 | soft‑eval =  19.5452 | best =  20.5577 | no_improve = 27 | time = 6s | epoch_time = 0.0s | soft_sigma = 2.000 | lr = 7.00e-03\n",
      "Epoch  160 | train‑avg =  20.3829 | soft‑eval =  19.3409 | best =  20.5577 | no_improve = 37 | time = 6s | epoch_time = 0.0s | soft_sigma = 2.000 | lr = 7.00e-03\n",
      "Epoch  170 | train‑avg =  19.1547 | soft‑eval =  19.9345 | best =  20.5577 | no_improve = 47 | time = 6s | epoch_time = 0.0s | soft_sigma = 2.000 | lr = 7.00e-03\n",
      "Epoch  180 | train‑avg =  19.3228 | soft‑eval =  19.8841 | best =  20.5577 | no_improve = 57 | time = 7s | epoch_time = 0.0s | soft_sigma = 2.000 | lr = 7.00e-03\n",
      "Epoch  190 | train‑avg =  19.7125 | soft‑eval =  19.9285 | best =  20.5577 | no_improve = 67 | time = 7s | epoch_time = 0.0s | soft_sigma = 2.000 | lr = 7.00e-03\n",
      "Epoch  200 | train‑avg =  19.4321 | soft‑eval =  19.6748 | best =  20.5577 | no_improve = 77 | time = 8s | epoch_time = 0.0s | soft_sigma = 2.000 | lr = 7.00e-03\n",
      "Epoch  210 | train‑avg =  19.2874 | soft‑eval =  19.6224 | best =  20.5577 | no_improve = 87 | time = 8s | epoch_time = 0.0s | soft_sigma = 2.000 | lr = 7.00e-03\n",
      "Epoch  220 | train‑avg =  19.6567 | soft‑eval =  19.4534 | best =  20.5953 | no_improve =  2 | time = 9s | epoch_time = 0.0s | soft_sigma = 2.000 | lr = 7.00e-03\n",
      "Epoch  230 | train‑avg =  19.2963 | soft‑eval =  19.9734 | best =  20.5953 | no_improve = 12 | time = 9s | epoch_time = 0.0s | soft_sigma = 2.000 | lr = 7.00e-03\n",
      "Epoch  240 | train‑avg =  19.1277 | soft‑eval =  20.2592 | best =  20.5953 | no_improve = 22 | time = 9s | epoch_time = 0.0s | soft_sigma = 2.000 | lr = 7.00e-03\n",
      "Epoch  250 | train‑avg =  20.1700 | soft‑eval =  19.7693 | best =  20.5953 | no_improve = 32 | time = 10s | epoch_time = 0.0s | soft_sigma = 2.000 | lr = 7.00e-03\n",
      "Epoch  260 | train‑avg =  19.4376 | soft‑eval =  19.2936 | best =  20.5953 | no_improve = 42 | time = 10s | epoch_time = 0.0s | soft_sigma = 2.000 | lr = 7.00e-03\n",
      "Epoch  270 | train‑avg =  19.9052 | soft‑eval =  19.9426 | best =  20.5953 | no_improve = 52 | time = 10s | epoch_time = 0.0s | soft_sigma = 2.000 | lr = 7.00e-03\n",
      "Epoch  280 | train‑avg =  19.8214 | soft‑eval =  19.7527 | best =  20.5953 | no_improve = 62 | time = 11s | epoch_time = 0.0s | soft_sigma = 2.000 | lr = 7.00e-03\n",
      "Epoch  290 | train‑avg =  19.0833 | soft‑eval =  19.6961 | best =  20.5953 | no_improve = 72 | time = 11s | epoch_time = 0.0s | soft_sigma = 2.000 | lr = 7.00e-03\n",
      "Epoch  300 | train‑avg =  19.9209 | soft‑eval =  20.0051 | best =  20.5953 | no_improve = 82 | time = 12s | epoch_time = 0.0s | soft_sigma = 2.000 | lr = 7.00e-03\n",
      "Epoch  310 | train‑avg =  19.5736 | soft‑eval =  19.5251 | best =  20.5953 | no_improve = 92 | time = 12s | epoch_time = 0.0s | soft_sigma = 2.000 | lr = 7.00e-03\n",
      "Epoch  320 | train‑avg =  19.2868 | soft‑eval =  19.4611 | best =  20.5953 | no_improve = 102 | time = 12s | epoch_time = 0.0s | soft_sigma = 2.000 | lr = 7.00e-03\n",
      "Epoch  330 | train‑avg =  19.8817 | soft‑eval =  20.0057 | best =  20.5953 | no_improve = 112 | time = 13s | epoch_time = 0.0s | soft_sigma = 2.000 | lr = 7.00e-03\n",
      "Epoch  340 | train‑avg =  19.5109 | soft‑eval =  19.7076 | best =  20.5953 | no_improve = 122 | time = 13s | epoch_time = 0.0s | soft_sigma = 2.000 | lr = 7.00e-03\n",
      "Epoch  350 | train‑avg =  19.1689 | soft‑eval =  19.6228 | best =  20.5953 | no_improve = 132 | time = 14s | epoch_time = 0.0s | soft_sigma = 2.000 | lr = 7.00e-03\n",
      "Epoch  360 | train‑avg =  19.6206 | soft‑eval =  19.4781 | best =  20.5953 | no_improve = 142 | time = 14s | epoch_time = 0.0s | soft_sigma = 2.000 | lr = 7.00e-03\n",
      "Epoch  370 | train‑avg =  19.3366 | soft‑eval =  19.9749 | best =  20.5953 | no_improve = 152 | time = 15s | epoch_time = 0.0s | soft_sigma = 2.000 | lr = 7.00e-03\n",
      "Epoch  380 | train‑avg =  19.9202 | soft‑eval =  19.6120 | best =  20.5953 | no_improve = 162 | time = 15s | epoch_time = 0.0s | soft_sigma = 2.000 | lr = 7.00e-03\n",
      "Epoch  390 | train‑avg =  19.3897 | soft‑eval =  20.0024 | best =  20.5953 | no_improve = 172 | time = 15s | epoch_time = 0.0s | soft_sigma = 2.000 | lr = 7.00e-03\n",
      "Epoch  400 | train‑avg =  19.5830 | soft‑eval =  19.8986 | best =  20.5953 | no_improve = 182 | time = 16s | epoch_time = 0.0s | soft_sigma = 2.000 | lr = 3.50e-03\n",
      "Epoch  410 | train‑avg =  19.6834 | soft‑eval =  20.3949 | best =  20.5953 | no_improve = 192 | time = 16s | epoch_time = 0.0s | soft_sigma = 2.000 | lr = 3.50e-03\n",
      "Early stopping triggered after 418 epochs (17s)\n",
      "Best score: 20.595280\n",
      "No improvement for 200 epochs\n",
      "\n",
      "Training completed after 417 epochs\n",
      "Total training time: 17s\n",
      "Average time per epoch: 0.0s\n",
      "Best evaluation score: 20.595280\n",
      "Final score: 19.936650\n",
      "\n",
      "Evaluating final policy...\n",
      "Sharp policy price ≈ 19.7919  CI: [19.7647,19.8191] (95% CI)\n"
     ]
    }
   ],
   "source": [
    "d = 2\n",
    "seed = 42\n",
    "\n",
    "S0_vec       = np.full(d, 100.0, dtype=np.float32)\n",
    "sigma_vec    = get_vol(d)\n",
    "q_vec        = np.full(d, 0.1, dtype=np.float32)\n",
    "rho          = 0.0\n",
    "r            = 0.05\n",
    "K            = 100.0\n",
    "T            = 3.0\n",
    "num_steps    = 9\n",
    "dt           = T / num_steps\n",
    "\n",
    "\n",
    "prices = []\n",
    "times = []\n",
    "n_trials = 4\n",
    "\n",
    "for trial in range(n_trials):\n",
    "    net, train_hist, eval_hist, training_time = train_net(\n",
    "    soft_sigma=2.0,\n",
    "    N_train=10_000,\n",
    "    batch=500,\n",
    "    lr=0.007,\n",
    "    seed=seed + trial,\n",
    "    eval_every=10,\n",
    "    width=64,\n",
    "    depth=2,\n",
    "    dropout=0.1,\n",
    "    curriculum=False,\n",
    "    patience=200,            \n",
    "    min_delta=1e-2,      \n",
    "    relative_threshold=1e-3,\n",
    "    min_epochs=50,         \n",
    "    max_epochs=2000     \n",
    "    )\n",
    "    times.append(training_time)\n",
    "\n",
    "    print(\"\\nEvaluating final policy...\")\n",
    "    sharp_mean, sharp_se = evaluate_sharp_policy(net, N_eval=5_000_000)\n",
    "    prices.append(sharp_mean)\n",
    "    print(f\"Sharp policy price ≈ {sharp_mean:.4f}  CI: [{sharp_mean - 1.96*sharp_se:.4f},{sharp_mean + 1.96*sharp_se:.4f}] (95% CI)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "a2d06f77-eb26-4e0d-9526-278dac94f3d1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Price = 19.794 (0.003)\n",
      "Max Price = 19.798\n",
      "Times = ['13s', '12s', '14s', '17s']\n"
     ]
    }
   ],
   "source": [
    "print(f\"Price = {np.mean(prices):.3f} ({np.std(prices):.3f})\")\n",
    "print(f\"Max Price = {np.max(prices):.3f}\")\n",
    "print(f\"Times = {times}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "b9e5c914-8403-459b-9e70-c50bfbbf5153",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average training time = 14.0\n"
     ]
    }
   ],
   "source": [
    "Times = ['13s', '12s', '14s', '17s']\n",
    "print(f\"Average training time = {average_time_in_seconds(Times)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "c55b0d08-62ef-4d24-917a-91cfdf629f0a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Setting up input normalization...\n",
      "Starting training with early stopping (patience=200, min_epochs=50)\n",
      "Will stop when improvement < 1.00e-02 absolute or < 1.00e-03 relative\n",
      "Epoch   10 | train‑avg =  14.3164 | soft‑eval =  14.3499 | best =  14.9838 | no_improve =  4 | time = 0s | epoch_time = 0.0s | soft_sigma = 2.000 | lr = 7.00e-03\n",
      "Epoch   20 | train‑avg =  14.2927 | soft‑eval =  14.2625 | best =  14.9838 | no_improve = 14 | time = 0s | epoch_time = 0.0s | soft_sigma = 2.000 | lr = 7.00e-03\n",
      "Epoch   30 | train‑avg =  13.8938 | soft‑eval =  14.2701 | best =  14.9838 | no_improve = 24 | time = 1s | epoch_time = 0.0s | soft_sigma = 2.000 | lr = 7.00e-03\n",
      "Epoch   40 | train‑avg =  13.8956 | soft‑eval =  14.3413 | best =  14.9838 | no_improve = 34 | time = 1s | epoch_time = 0.0s | soft_sigma = 2.000 | lr = 7.00e-03\n",
      "Epoch   50 | train‑avg =  13.9112 | soft‑eval =  14.6117 | best =  14.9838 | no_improve = 44 | time = 1s | epoch_time = 0.0s | soft_sigma = 2.000 | lr = 7.00e-03\n",
      "Epoch   60 | train‑avg =  14.5212 | soft‑eval =  14.4209 | best =  14.9838 | no_improve = 54 | time = 2s | epoch_time = 0.0s | soft_sigma = 2.000 | lr = 7.00e-03\n",
      "Epoch   70 | train‑avg =  13.9593 | soft‑eval =  14.6761 | best =  15.0173 | no_improve =  3 | time = 2s | epoch_time = 0.0s | soft_sigma = 2.000 | lr = 7.00e-03\n",
      "Epoch   80 | train‑avg =  15.0859 | soft‑eval =  14.1219 | best =  15.0173 | no_improve = 13 | time = 3s | epoch_time = 0.0s | soft_sigma = 2.000 | lr = 7.00e-03\n",
      "Epoch   90 | train‑avg =  13.9032 | soft‑eval =  14.5867 | best =  15.0173 | no_improve = 23 | time = 3s | epoch_time = 0.0s | soft_sigma = 2.000 | lr = 7.00e-03\n",
      "Epoch  100 | train‑avg =  14.4907 | soft‑eval =  14.1770 | best =  15.0173 | no_improve = 33 | time = 3s | epoch_time = 0.0s | soft_sigma = 2.000 | lr = 7.00e-03\n",
      "Epoch  110 | train‑avg =  14.1513 | soft‑eval =  14.6866 | best =  15.0173 | no_improve = 43 | time = 4s | epoch_time = 0.0s | soft_sigma = 2.000 | lr = 7.00e-03\n",
      "Epoch  120 | train‑avg =  14.1897 | soft‑eval =  14.3857 | best =  15.0173 | no_improve = 53 | time = 4s | epoch_time = 0.0s | soft_sigma = 2.000 | lr = 7.00e-03\n",
      "Epoch  130 | train‑avg =  14.5835 | soft‑eval =  14.1435 | best =  15.0173 | no_improve = 63 | time = 5s | epoch_time = 0.0s | soft_sigma = 2.000 | lr = 7.00e-03\n",
      "Epoch  140 | train‑avg =  14.8343 | soft‑eval =  14.1929 | best =  15.0173 | no_improve = 73 | time = 5s | epoch_time = 0.0s | soft_sigma = 2.000 | lr = 7.00e-03\n",
      "Epoch  150 | train‑avg =  14.7087 | soft‑eval =  14.1730 | best =  15.0173 | no_improve = 83 | time = 5s | epoch_time = 0.0s | soft_sigma = 2.000 | lr = 7.00e-03\n",
      "Epoch  160 | train‑avg =  14.1552 | soft‑eval =  13.8578 | best =  15.0173 | no_improve = 93 | time = 6s | epoch_time = 0.0s | soft_sigma = 2.000 | lr = 7.00e-03\n",
      "Epoch  170 | train‑avg =  14.3668 | soft‑eval =  14.2795 | best =  15.0173 | no_improve = 103 | time = 6s | epoch_time = 0.0s | soft_sigma = 2.000 | lr = 7.00e-03\n",
      "Epoch  180 | train‑avg =  13.4624 | soft‑eval =  14.4846 | best =  15.0173 | no_improve = 113 | time = 6s | epoch_time = 0.0s | soft_sigma = 2.000 | lr = 7.00e-03\n",
      "Epoch  190 | train‑avg =  14.4434 | soft‑eval =  14.2821 | best =  15.0173 | no_improve = 123 | time = 7s | epoch_time = 0.0s | soft_sigma = 2.000 | lr = 7.00e-03\n",
      "Epoch  200 | train‑avg =  14.4596 | soft‑eval =  14.0818 | best =  15.0173 | no_improve = 133 | time = 7s | epoch_time = 0.0s | soft_sigma = 2.000 | lr = 7.00e-03\n",
      "Epoch  210 | train‑avg =  13.9109 | soft‑eval =  13.8326 | best =  15.0173 | no_improve = 143 | time = 8s | epoch_time = 0.0s | soft_sigma = 2.000 | lr = 7.00e-03\n",
      "Epoch  220 | train‑avg =  14.1166 | soft‑eval =  14.4439 | best =  15.0173 | no_improve = 153 | time = 8s | epoch_time = 0.0s | soft_sigma = 2.000 | lr = 7.00e-03\n",
      "Epoch  230 | train‑avg =  14.6754 | soft‑eval =  14.4279 | best =  15.0173 | no_improve = 163 | time = 8s | epoch_time = 0.0s | soft_sigma = 2.000 | lr = 7.00e-03\n",
      "Epoch  240 | train‑avg =  14.4632 | soft‑eval =  14.3169 | best =  15.0173 | no_improve = 173 | time = 9s | epoch_time = 0.0s | soft_sigma = 2.000 | lr = 7.00e-03\n",
      "Epoch  250 | train‑avg =  14.0101 | soft‑eval =  14.1722 | best =  15.0173 | no_improve = 183 | time = 9s | epoch_time = 0.0s | soft_sigma = 2.000 | lr = 7.00e-03\n",
      "Epoch  260 | train‑avg =  14.3643 | soft‑eval =  13.8387 | best =  15.0173 | no_improve = 193 | time = 10s | epoch_time = 0.0s | soft_sigma = 2.000 | lr = 7.00e-03\n",
      "Early stopping triggered after 267 epochs (10s)\n",
      "Best score: 15.017307\n",
      "No improvement for 200 epochs\n",
      "\n",
      "Training completed after 266 epochs\n",
      "Total training time: 10s\n",
      "Average time per epoch: 0.0s\n",
      "Best evaluation score: 15.017307\n",
      "Final score: 14.231189\n",
      "\n",
      "Evaluating final policy...\n",
      "Sharp policy price ≈ 14.3223  CI: [14.2994,14.3452] (95% CI)\n",
      "Setting up input normalization...\n",
      "Starting training with early stopping (patience=200, min_epochs=50)\n",
      "Will stop when improvement < 1.00e-02 absolute or < 1.00e-03 relative\n",
      "Epoch   10 | train‑avg =  14.3201 | soft‑eval =  14.3962 | best =  14.7400 | no_improve =  3 | time = 0s | epoch_time = 0.0s | soft_sigma = 2.000 | lr = 7.00e-03\n",
      "Epoch   20 | train‑avg =  14.1648 | soft‑eval =  14.5373 | best =  14.7400 | no_improve = 13 | time = 0s | epoch_time = 0.0s | soft_sigma = 2.000 | lr = 7.00e-03\n",
      "Epoch   30 | train‑avg =  13.9925 | soft‑eval =  14.0120 | best =  14.7400 | no_improve = 23 | time = 1s | epoch_time = 0.0s | soft_sigma = 2.000 | lr = 7.00e-03\n",
      "Epoch   40 | train‑avg =  14.5343 | soft‑eval =  14.1713 | best =  14.7400 | no_improve = 33 | time = 1s | epoch_time = 0.0s | soft_sigma = 2.000 | lr = 7.00e-03\n",
      "Epoch   50 | train‑avg =  14.2383 | soft‑eval =  14.8250 | best =  14.7400 | no_improve = 43 | time = 1s | epoch_time = 0.0s | soft_sigma = 2.000 | lr = 7.00e-03\n",
      "Epoch   60 | train‑avg =  13.8284 | soft‑eval =  14.7094 | best =  14.8250 | no_improve =  9 | time = 2s | epoch_time = 0.0s | soft_sigma = 2.000 | lr = 7.00e-03\n",
      "Epoch   70 | train‑avg =  13.9811 | soft‑eval =  14.5764 | best =  14.8250 | no_improve = 19 | time = 2s | epoch_time = 0.0s | soft_sigma = 2.000 | lr = 7.00e-03\n",
      "Epoch   80 | train‑avg =  14.3407 | soft‑eval =  13.8875 | best =  14.8250 | no_improve = 29 | time = 2s | epoch_time = 0.0s | soft_sigma = 2.000 | lr = 7.00e-03\n",
      "Epoch   90 | train‑avg =  14.1591 | soft‑eval =  14.3817 | best =  14.8250 | no_improve = 39 | time = 3s | epoch_time = 0.0s | soft_sigma = 2.000 | lr = 7.00e-03\n",
      "Epoch  100 | train‑avg =  14.2573 | soft‑eval =  14.3178 | best =  14.8250 | no_improve = 49 | time = 3s | epoch_time = 0.0s | soft_sigma = 2.000 | lr = 7.00e-03\n",
      "Epoch  110 | train‑avg =  14.3508 | soft‑eval =  14.3328 | best =  14.9010 | no_improve =  1 | time = 4s | epoch_time = 0.0s | soft_sigma = 2.000 | lr = 7.00e-03\n",
      "Epoch  120 | train‑avg =  14.7623 | soft‑eval =  14.7564 | best =  14.9010 | no_improve = 11 | time = 4s | epoch_time = 0.0s | soft_sigma = 2.000 | lr = 7.00e-03\n",
      "Epoch  130 | train‑avg =  14.2554 | soft‑eval =  14.2432 | best =  14.9010 | no_improve = 21 | time = 4s | epoch_time = 0.0s | soft_sigma = 2.000 | lr = 7.00e-03\n",
      "Epoch  140 | train‑avg =  14.6005 | soft‑eval =  14.9342 | best =  14.9274 | no_improve =  1 | time = 5s | epoch_time = 0.0s | soft_sigma = 2.000 | lr = 7.00e-03\n",
      "Epoch  150 | train‑avg =  14.3185 | soft‑eval =  13.8964 | best =  14.9274 | no_improve = 11 | time = 5s | epoch_time = 0.0s | soft_sigma = 2.000 | lr = 7.00e-03\n",
      "Epoch  160 | train‑avg =  14.2053 | soft‑eval =  14.0242 | best =  14.9274 | no_improve = 21 | time = 6s | epoch_time = 0.0s | soft_sigma = 2.000 | lr = 7.00e-03\n",
      "Epoch  170 | train‑avg =  14.3491 | soft‑eval =  13.9460 | best =  14.9274 | no_improve = 31 | time = 6s | epoch_time = 0.0s | soft_sigma = 2.000 | lr = 7.00e-03\n",
      "Epoch  180 | train‑avg =  14.3560 | soft‑eval =  14.0032 | best =  14.9274 | no_improve = 41 | time = 6s | epoch_time = 0.0s | soft_sigma = 2.000 | lr = 7.00e-03\n",
      "Epoch  190 | train‑avg =  14.2343 | soft‑eval =  14.8231 | best =  14.9274 | no_improve = 51 | time = 7s | epoch_time = 0.0s | soft_sigma = 2.000 | lr = 7.00e-03\n",
      "Epoch  200 | train‑avg =  14.0783 | soft‑eval =  14.6149 | best =  14.9274 | no_improve = 61 | time = 7s | epoch_time = 0.0s | soft_sigma = 2.000 | lr = 7.00e-03\n",
      "Epoch  210 | train‑avg =  14.2476 | soft‑eval =  14.1437 | best =  14.9274 | no_improve = 71 | time = 8s | epoch_time = 0.0s | soft_sigma = 2.000 | lr = 7.00e-03\n",
      "Epoch  220 | train‑avg =  14.4807 | soft‑eval =  14.7005 | best =  14.9274 | no_improve = 81 | time = 8s | epoch_time = 0.0s | soft_sigma = 2.000 | lr = 7.00e-03\n",
      "Epoch  230 | train‑avg =  14.4465 | soft‑eval =  14.1046 | best =  14.9274 | no_improve = 91 | time = 8s | epoch_time = 0.0s | soft_sigma = 2.000 | lr = 7.00e-03\n",
      "Epoch  240 | train‑avg =  14.5349 | soft‑eval =  14.1808 | best =  14.9274 | no_improve = 101 | time = 9s | epoch_time = 0.0s | soft_sigma = 2.000 | lr = 7.00e-03\n",
      "Epoch  250 | train‑avg =  14.1845 | soft‑eval =  14.3315 | best =  14.9274 | no_improve = 111 | time = 9s | epoch_time = 0.0s | soft_sigma = 2.000 | lr = 7.00e-03\n",
      "Epoch  260 | train‑avg =  14.4276 | soft‑eval =  14.4436 | best =  14.9274 | no_improve = 121 | time = 10s | epoch_time = 0.0s | soft_sigma = 2.000 | lr = 7.00e-03\n",
      "Epoch  270 | train‑avg =  14.1720 | soft‑eval =  14.8735 | best =  14.9274 | no_improve = 131 | time = 10s | epoch_time = 0.0s | soft_sigma = 2.000 | lr = 7.00e-03\n",
      "Epoch  280 | train‑avg =  14.2365 | soft‑eval =  14.2943 | best =  14.9274 | no_improve = 141 | time = 10s | epoch_time = 0.0s | soft_sigma = 2.000 | lr = 7.00e-03\n",
      "Epoch  290 | train‑avg =  14.7505 | soft‑eval =  13.7357 | best =  14.9274 | no_improve = 151 | time = 11s | epoch_time = 0.0s | soft_sigma = 2.000 | lr = 7.00e-03\n",
      "Epoch  300 | train‑avg =  14.2819 | soft‑eval =  14.9547 | best =  14.9274 | no_improve = 161 | time = 11s | epoch_time = 0.0s | soft_sigma = 2.000 | lr = 7.00e-03\n",
      "Epoch  310 | train‑avg =  14.3362 | soft‑eval =  14.4355 | best =  14.9547 | no_improve =  9 | time = 12s | epoch_time = 0.0s | soft_sigma = 2.000 | lr = 7.00e-03\n",
      "Epoch  320 | train‑avg =  14.6161 | soft‑eval =  14.0841 | best =  14.9547 | no_improve = 19 | time = 12s | epoch_time = 0.0s | soft_sigma = 2.000 | lr = 7.00e-03\n",
      "Epoch  330 | train‑avg =  14.2140 | soft‑eval =  14.3741 | best =  14.9547 | no_improve = 29 | time = 12s | epoch_time = 0.0s | soft_sigma = 2.000 | lr = 7.00e-03\n",
      "Epoch  340 | train‑avg =  14.0303 | soft‑eval =  14.3173 | best =  14.9547 | no_improve = 39 | time = 13s | epoch_time = 0.0s | soft_sigma = 2.000 | lr = 7.00e-03\n",
      "Epoch  350 | train‑avg =  14.4721 | soft‑eval =  14.3674 | best =  14.9547 | no_improve = 49 | time = 13s | epoch_time = 0.0s | soft_sigma = 2.000 | lr = 7.00e-03\n",
      "Epoch  360 | train‑avg =  14.0992 | soft‑eval =  14.5496 | best =  14.9547 | no_improve = 59 | time = 14s | epoch_time = 0.0s | soft_sigma = 2.000 | lr = 7.00e-03\n",
      "Epoch  370 | train‑avg =  14.2354 | soft‑eval =  14.4105 | best =  14.9547 | no_improve = 69 | time = 14s | epoch_time = 0.0s | soft_sigma = 2.000 | lr = 7.00e-03\n",
      "Epoch  380 | train‑avg =  14.3465 | soft‑eval =  14.5379 | best =  14.9547 | no_improve = 79 | time = 15s | epoch_time = 0.0s | soft_sigma = 2.000 | lr = 7.00e-03\n",
      "Epoch  390 | train‑avg =  14.4498 | soft‑eval =  14.0944 | best =  14.9547 | no_improve = 89 | time = 15s | epoch_time = 0.0s | soft_sigma = 2.000 | lr = 7.00e-03\n",
      "Epoch  400 | train‑avg =  14.2540 | soft‑eval =  14.2868 | best =  14.9547 | no_improve = 99 | time = 15s | epoch_time = 0.0s | soft_sigma = 2.000 | lr = 7.00e-03\n",
      "Epoch  410 | train‑avg =  13.9140 | soft‑eval =  14.3227 | best =  14.9547 | no_improve = 109 | time = 16s | epoch_time = 0.0s | soft_sigma = 2.000 | lr = 7.00e-03\n",
      "Epoch  420 | train‑avg =  14.8072 | soft‑eval =  14.3873 | best =  14.9547 | no_improve = 119 | time = 16s | epoch_time = 0.0s | soft_sigma = 2.000 | lr = 7.00e-03\n",
      "Epoch  430 | train‑avg =  14.6670 | soft‑eval =  14.4867 | best =  14.9547 | no_improve = 129 | time = 17s | epoch_time = 0.0s | soft_sigma = 2.000 | lr = 7.00e-03\n",
      "Epoch  440 | train‑avg =  14.3010 | soft‑eval =  14.4467 | best =  14.9547 | no_improve = 139 | time = 17s | epoch_time = 0.0s | soft_sigma = 2.000 | lr = 7.00e-03\n",
      "Epoch  450 | train‑avg =  14.3886 | soft‑eval =  14.2540 | best =  14.9547 | no_improve = 149 | time = 17s | epoch_time = 0.0s | soft_sigma = 2.000 | lr = 7.00e-03\n",
      "Epoch  460 | train‑avg =  14.5959 | soft‑eval =  14.0201 | best =  14.9547 | no_improve = 159 | time = 18s | epoch_time = 0.0s | soft_sigma = 2.000 | lr = 3.50e-03\n",
      "Epoch  470 | train‑avg =  13.9761 | soft‑eval =  14.4719 | best =  14.9547 | no_improve = 169 | time = 18s | epoch_time = 0.0s | soft_sigma = 2.000 | lr = 3.50e-03\n",
      "Epoch  480 | train‑avg =  14.2081 | soft‑eval =  14.5158 | best =  14.9547 | no_improve = 179 | time = 18s | epoch_time = 0.0s | soft_sigma = 2.000 | lr = 3.50e-03\n",
      "Epoch  490 | train‑avg =  14.5265 | soft‑eval =  14.0434 | best =  14.9547 | no_improve = 189 | time = 19s | epoch_time = 0.0s | soft_sigma = 2.000 | lr = 3.50e-03\n",
      "Epoch  500 | train‑avg =  14.5533 | soft‑eval =  14.4062 | best =  15.0234 | no_improve =  4 | time = 19s | epoch_time = 0.0s | soft_sigma = 2.000 | lr = 3.50e-03\n",
      "Epoch  510 | train‑avg =  14.2144 | soft‑eval =  14.7796 | best =  15.0234 | no_improve = 14 | time = 20s | epoch_time = 0.0s | soft_sigma = 2.000 | lr = 3.50e-03\n",
      "Epoch  520 | train‑avg =  14.4820 | soft‑eval =  14.6807 | best =  15.0234 | no_improve = 24 | time = 20s | epoch_time = 0.0s | soft_sigma = 2.000 | lr = 3.50e-03\n",
      "Epoch  530 | train‑avg =  14.5390 | soft‑eval =  14.3551 | best =  15.0234 | no_improve = 34 | time = 21s | epoch_time = 0.0s | soft_sigma = 2.000 | lr = 3.50e-03\n",
      "Epoch  540 | train‑avg =  14.6831 | soft‑eval =  14.1464 | best =  15.0234 | no_improve = 44 | time = 21s | epoch_time = 0.0s | soft_sigma = 2.000 | lr = 3.50e-03\n",
      "Epoch  550 | train‑avg =  14.1901 | soft‑eval =  14.6394 | best =  15.0234 | no_improve = 54 | time = 21s | epoch_time = 0.0s | soft_sigma = 2.000 | lr = 3.50e-03\n",
      "Epoch  560 | train‑avg =  14.8601 | soft‑eval =  14.3406 | best =  15.0234 | no_improve = 64 | time = 22s | epoch_time = 0.0s | soft_sigma = 2.000 | lr = 3.50e-03\n",
      "Epoch  570 | train‑avg =  14.3117 | soft‑eval =  14.2970 | best =  15.0234 | no_improve = 74 | time = 22s | epoch_time = 0.0s | soft_sigma = 2.000 | lr = 3.50e-03\n",
      "Epoch  580 | train‑avg =  14.4705 | soft‑eval =  14.6460 | best =  15.0234 | no_improve = 84 | time = 23s | epoch_time = 0.0s | soft_sigma = 2.000 | lr = 3.50e-03\n",
      "Epoch  590 | train‑avg =  14.6303 | soft‑eval =  14.0867 | best =  15.0563 | no_improve =  1 | time = 23s | epoch_time = 0.0s | soft_sigma = 2.000 | lr = 3.50e-03\n",
      "Epoch  600 | train‑avg =  14.3841 | soft‑eval =  14.3860 | best =  15.0563 | no_improve = 11 | time = 23s | epoch_time = 0.0s | soft_sigma = 2.000 | lr = 3.50e-03\n",
      "Epoch  610 | train‑avg =  14.8277 | soft‑eval =  14.5081 | best =  15.0563 | no_improve = 21 | time = 24s | epoch_time = 0.0s | soft_sigma = 2.000 | lr = 3.50e-03\n",
      "Epoch  620 | train‑avg =  14.2827 | soft‑eval =  14.0618 | best =  15.0563 | no_improve = 31 | time = 24s | epoch_time = 0.0s | soft_sigma = 2.000 | lr = 1.75e-03\n",
      "Epoch  630 | train‑avg =  14.1458 | soft‑eval =  14.4034 | best =  15.0563 | no_improve = 41 | time = 25s | epoch_time = 0.0s | soft_sigma = 2.000 | lr = 1.75e-03\n",
      "Epoch  640 | train‑avg =  14.4123 | soft‑eval =  13.7812 | best =  15.0563 | no_improve = 51 | time = 25s | epoch_time = 0.0s | soft_sigma = 2.000 | lr = 1.75e-03\n",
      "Epoch  650 | train‑avg =  14.3558 | soft‑eval =  14.5084 | best =  15.0563 | no_improve = 61 | time = 25s | epoch_time = 0.0s | soft_sigma = 2.000 | lr = 1.75e-03\n",
      "Epoch  660 | train‑avg =  14.0031 | soft‑eval =  14.5621 | best =  15.0563 | no_improve = 71 | time = 26s | epoch_time = 0.0s | soft_sigma = 2.000 | lr = 1.75e-03\n",
      "Epoch  670 | train‑avg =  14.0941 | soft‑eval =  14.0239 | best =  15.0563 | no_improve = 81 | time = 26s | epoch_time = 0.0s | soft_sigma = 2.000 | lr = 1.75e-03\n",
      "Epoch  680 | train‑avg =  14.2938 | soft‑eval =  14.4933 | best =  15.0563 | no_improve = 91 | time = 27s | epoch_time = 0.0s | soft_sigma = 2.000 | lr = 1.75e-03\n",
      "Epoch  690 | train‑avg =  14.2951 | soft‑eval =  14.9003 | best =  15.0563 | no_improve = 101 | time = 27s | epoch_time = 0.0s | soft_sigma = 2.000 | lr = 1.75e-03\n",
      "Epoch  700 | train‑avg =  14.1712 | soft‑eval =  14.2808 | best =  15.0563 | no_improve = 111 | time = 27s | epoch_time = 0.0s | soft_sigma = 2.000 | lr = 1.75e-03\n",
      "Epoch  710 | train‑avg =  14.0697 | soft‑eval =  14.4871 | best =  15.0563 | no_improve = 121 | time = 28s | epoch_time = 0.0s | soft_sigma = 2.000 | lr = 1.75e-03\n",
      "Epoch  720 | train‑avg =  14.4684 | soft‑eval =  14.5134 | best =  15.0563 | no_improve = 131 | time = 28s | epoch_time = 0.0s | soft_sigma = 2.000 | lr = 1.75e-03\n",
      "Epoch  730 | train‑avg =  14.1910 | soft‑eval =  14.3199 | best =  15.0563 | no_improve = 141 | time = 29s | epoch_time = 0.0s | soft_sigma = 2.000 | lr = 1.75e-03\n",
      "Epoch  740 | train‑avg =  14.6549 | soft‑eval =  14.6200 | best =  15.0563 | no_improve = 151 | time = 29s | epoch_time = 0.0s | soft_sigma = 2.000 | lr = 1.75e-03\n",
      "Epoch  750 | train‑avg =  14.4092 | soft‑eval =  14.2091 | best =  15.1953 | no_improve =  3 | time = 30s | epoch_time = 0.0s | soft_sigma = 2.000 | lr = 1.75e-03\n",
      "Epoch  760 | train‑avg =  13.6319 | soft‑eval =  14.3970 | best =  15.1953 | no_improve = 13 | time = 30s | epoch_time = 0.0s | soft_sigma = 2.000 | lr = 1.75e-03\n",
      "Epoch  770 | train‑avg =  14.7358 | soft‑eval =  14.5247 | best =  15.1953 | no_improve = 23 | time = 31s | epoch_time = 0.0s | soft_sigma = 2.000 | lr = 1.75e-03\n",
      "Epoch  780 | train‑avg =  14.6071 | soft‑eval =  13.9172 | best =  15.1953 | no_improve = 33 | time = 31s | epoch_time = 0.0s | soft_sigma = 2.000 | lr = 8.75e-04\n",
      "Epoch  790 | train‑avg =  14.4178 | soft‑eval =  14.1879 | best =  15.1953 | no_improve = 43 | time = 31s | epoch_time = 0.0s | soft_sigma = 2.000 | lr = 8.75e-04\n",
      "Epoch  800 | train‑avg =  14.2136 | soft‑eval =  14.3107 | best =  15.1953 | no_improve = 53 | time = 32s | epoch_time = 0.0s | soft_sigma = 2.000 | lr = 8.75e-04\n",
      "Epoch  810 | train‑avg =  14.6184 | soft‑eval =  14.1131 | best =  15.1953 | no_improve = 63 | time = 32s | epoch_time = 0.0s | soft_sigma = 2.000 | lr = 8.75e-04\n",
      "Epoch  820 | train‑avg =  14.1862 | soft‑eval =  13.4621 | best =  15.1953 | no_improve = 73 | time = 33s | epoch_time = 0.0s | soft_sigma = 2.000 | lr = 8.75e-04\n",
      "Epoch  830 | train‑avg =  14.1632 | soft‑eval =  14.2652 | best =  15.1953 | no_improve = 83 | time = 33s | epoch_time = 0.0s | soft_sigma = 2.000 | lr = 8.75e-04\n",
      "Epoch  840 | train‑avg =  14.1155 | soft‑eval =  14.6351 | best =  15.1953 | no_improve = 93 | time = 34s | epoch_time = 0.0s | soft_sigma = 2.000 | lr = 8.75e-04\n",
      "Epoch  850 | train‑avg =  14.1823 | soft‑eval =  14.5055 | best =  15.1953 | no_improve = 103 | time = 34s | epoch_time = 0.0s | soft_sigma = 2.000 | lr = 8.75e-04\n",
      "Epoch  860 | train‑avg =  14.7463 | soft‑eval =  14.5748 | best =  15.1953 | no_improve = 113 | time = 34s | epoch_time = 0.0s | soft_sigma = 2.000 | lr = 8.75e-04\n",
      "Epoch  870 | train‑avg =  14.3505 | soft‑eval =  14.0410 | best =  15.1953 | no_improve = 123 | time = 35s | epoch_time = 0.0s | soft_sigma = 2.000 | lr = 8.75e-04\n",
      "Epoch  880 | train‑avg =  14.1871 | soft‑eval =  14.6672 | best =  15.1953 | no_improve = 133 | time = 35s | epoch_time = 0.0s | soft_sigma = 2.000 | lr = 8.75e-04\n",
      "Epoch  890 | train‑avg =  14.3659 | soft‑eval =  13.9379 | best =  15.1953 | no_improve = 143 | time = 35s | epoch_time = 0.0s | soft_sigma = 2.000 | lr = 8.75e-04\n",
      "Epoch  900 | train‑avg =  14.1916 | soft‑eval =  14.3028 | best =  15.1953 | no_improve = 153 | time = 36s | epoch_time = 0.0s | soft_sigma = 2.000 | lr = 8.75e-04\n",
      "Epoch  910 | train‑avg =  13.5402 | soft‑eval =  14.3138 | best =  15.1953 | no_improve = 163 | time = 36s | epoch_time = 0.0s | soft_sigma = 2.000 | lr = 8.75e-04\n",
      "Epoch  920 | train‑avg =  14.0644 | soft‑eval =  14.6693 | best =  15.1953 | no_improve = 173 | time = 37s | epoch_time = 0.0s | soft_sigma = 2.000 | lr = 8.75e-04\n",
      "Epoch  930 | train‑avg =  14.1264 | soft‑eval =  14.5138 | best =  15.1953 | no_improve = 183 | time = 37s | epoch_time = 0.0s | soft_sigma = 2.000 | lr = 8.75e-04\n",
      "Epoch  940 | train‑avg =  14.6747 | soft‑eval =  14.3307 | best =  15.1953 | no_improve = 193 | time = 38s | epoch_time = 0.0s | soft_sigma = 2.000 | lr = 4.38e-04\n",
      "Early stopping triggered after 947 epochs (38s)\n",
      "Best score: 15.195282\n",
      "No improvement for 200 epochs\n",
      "\n",
      "Training completed after 946 epochs\n",
      "Total training time: 38s\n",
      "Average time per epoch: 0.0s\n",
      "Best evaluation score: 15.195282\n",
      "Final score: 14.025003\n",
      "\n",
      "Evaluating final policy...\n",
      "Sharp policy price ≈ 14.3396  CI: [14.3160,14.3632] (95% CI)\n",
      "Setting up input normalization...\n",
      "Starting training with early stopping (patience=200, min_epochs=50)\n",
      "Will stop when improvement < 1.00e-02 absolute or < 1.00e-03 relative\n",
      "Epoch   10 | train‑avg =  14.0851 | soft‑eval =  14.3701 | best =  14.7382 | no_improve =  3 | time = 0s | epoch_time = 0.0s | soft_sigma = 2.000 | lr = 7.00e-03\n",
      "Epoch   20 | train‑avg =  14.2248 | soft‑eval =  14.9609 | best =  15.0083 | no_improve =  8 | time = 0s | epoch_time = 0.0s | soft_sigma = 2.000 | lr = 7.00e-03\n",
      "Epoch   30 | train‑avg =  14.5258 | soft‑eval =  14.4714 | best =  15.0083 | no_improve = 18 | time = 1s | epoch_time = 0.0s | soft_sigma = 2.000 | lr = 7.00e-03\n",
      "Epoch   40 | train‑avg =  14.4140 | soft‑eval =  13.9413 | best =  15.0083 | no_improve = 28 | time = 1s | epoch_time = 0.0s | soft_sigma = 2.000 | lr = 7.00e-03\n",
      "Epoch   50 | train‑avg =  14.3070 | soft‑eval =  14.8375 | best =  15.0083 | no_improve = 38 | time = 2s | epoch_time = 0.0s | soft_sigma = 2.000 | lr = 7.00e-03\n",
      "Epoch   60 | train‑avg =  14.1563 | soft‑eval =  13.8684 | best =  15.0083 | no_improve = 48 | time = 2s | epoch_time = 0.0s | soft_sigma = 2.000 | lr = 7.00e-03\n",
      "Epoch   70 | train‑avg =  14.3719 | soft‑eval =  14.6520 | best =  15.0836 | no_improve =  8 | time = 2s | epoch_time = 0.0s | soft_sigma = 2.000 | lr = 7.00e-03\n",
      "Epoch   80 | train‑avg =  14.4838 | soft‑eval =  14.1982 | best =  15.0836 | no_improve = 18 | time = 3s | epoch_time = 0.0s | soft_sigma = 2.000 | lr = 7.00e-03\n",
      "Epoch   90 | train‑avg =  14.0133 | soft‑eval =  13.9939 | best =  15.0836 | no_improve = 28 | time = 3s | epoch_time = 0.0s | soft_sigma = 2.000 | lr = 7.00e-03\n",
      "Epoch  100 | train‑avg =  14.5066 | soft‑eval =  14.7557 | best =  15.0836 | no_improve = 38 | time = 4s | epoch_time = 0.0s | soft_sigma = 2.000 | lr = 7.00e-03\n",
      "Epoch  110 | train‑avg =  14.3151 | soft‑eval =  14.6533 | best =  15.0836 | no_improve = 48 | time = 4s | epoch_time = 0.0s | soft_sigma = 2.000 | lr = 7.00e-03\n",
      "Epoch  120 | train‑avg =  14.0681 | soft‑eval =  14.3221 | best =  15.0836 | no_improve = 58 | time = 4s | epoch_time = 0.0s | soft_sigma = 2.000 | lr = 7.00e-03\n",
      "Epoch  130 | train‑avg =  13.9731 | soft‑eval =  14.5147 | best =  15.0836 | no_improve = 68 | time = 5s | epoch_time = 0.0s | soft_sigma = 2.000 | lr = 7.00e-03\n",
      "Epoch  140 | train‑avg =  14.4902 | soft‑eval =  14.2308 | best =  15.0836 | no_improve = 78 | time = 5s | epoch_time = 0.0s | soft_sigma = 2.000 | lr = 7.00e-03\n",
      "Epoch  150 | train‑avg =  14.3270 | soft‑eval =  14.1155 | best =  15.0836 | no_improve = 88 | time = 6s | epoch_time = 0.0s | soft_sigma = 2.000 | lr = 7.00e-03\n",
      "Epoch  160 | train‑avg =  13.8453 | soft‑eval =  14.4459 | best =  15.0836 | no_improve = 98 | time = 6s | epoch_time = 0.0s | soft_sigma = 2.000 | lr = 7.00e-03\n",
      "Epoch  170 | train‑avg =  14.3174 | soft‑eval =  14.4606 | best =  15.0836 | no_improve = 108 | time = 6s | epoch_time = 0.0s | soft_sigma = 2.000 | lr = 7.00e-03\n",
      "Epoch  180 | train‑avg =  13.7989 | soft‑eval =  14.3770 | best =  15.0836 | no_improve = 118 | time = 7s | epoch_time = 0.0s | soft_sigma = 2.000 | lr = 3.50e-03\n",
      "Epoch  190 | train‑avg =  14.3110 | soft‑eval =  13.9521 | best =  15.0836 | no_improve = 128 | time = 7s | epoch_time = 0.0s | soft_sigma = 2.000 | lr = 3.50e-03\n",
      "Epoch  200 | train‑avg =  14.2095 | soft‑eval =  14.4544 | best =  15.0836 | no_improve = 138 | time = 8s | epoch_time = 0.0s | soft_sigma = 2.000 | lr = 3.50e-03\n",
      "Epoch  210 | train‑avg =  14.0763 | soft‑eval =  14.5800 | best =  15.0836 | no_improve = 148 | time = 8s | epoch_time = 0.0s | soft_sigma = 2.000 | lr = 3.50e-03\n",
      "Epoch  220 | train‑avg =  14.2135 | soft‑eval =  14.4968 | best =  15.0836 | no_improve = 158 | time = 8s | epoch_time = 0.0s | soft_sigma = 2.000 | lr = 3.50e-03\n",
      "Epoch  230 | train‑avg =  14.2937 | soft‑eval =  14.3820 | best =  15.0836 | no_improve = 168 | time = 9s | epoch_time = 0.0s | soft_sigma = 2.000 | lr = 3.50e-03\n",
      "Epoch  240 | train‑avg =  13.9530 | soft‑eval =  14.8691 | best =  15.0836 | no_improve = 178 | time = 9s | epoch_time = 0.0s | soft_sigma = 2.000 | lr = 3.50e-03\n",
      "Epoch  250 | train‑avg =  14.4180 | soft‑eval =  14.1000 | best =  15.0836 | no_improve = 188 | time = 10s | epoch_time = 0.0s | soft_sigma = 2.000 | lr = 3.50e-03\n",
      "Epoch  260 | train‑avg =  14.4483 | soft‑eval =  14.3521 | best =  15.0836 | no_improve = 198 | time = 10s | epoch_time = 0.0s | soft_sigma = 2.000 | lr = 3.50e-03\n",
      "Early stopping triggered after 262 epochs (10s)\n",
      "Best score: 15.083622\n",
      "No improvement for 200 epochs\n",
      "\n",
      "Training completed after 261 epochs\n",
      "Total training time: 10s\n",
      "Average time per epoch: 0.0s\n",
      "Best evaluation score: 15.083622\n",
      "Final score: 14.321701\n",
      "\n",
      "Evaluating final policy...\n",
      "Sharp policy price ≈ 14.3346  CI: [14.3109,14.3584] (95% CI)\n",
      "Setting up input normalization...\n",
      "Starting training with early stopping (patience=200, min_epochs=50)\n",
      "Will stop when improvement < 1.00e-02 absolute or < 1.00e-03 relative\n",
      "Epoch   10 | train‑avg =  14.2230 | soft‑eval =  14.5352 | best =  14.6335 | no_improve =  0 | time = 0s | epoch_time = 0.0s | soft_sigma = 2.000 | lr = 7.00e-03\n",
      "Epoch   20 | train‑avg =  14.1191 | soft‑eval =  14.0571 | best =  14.7684 | no_improve =  2 | time = 0s | epoch_time = 0.0s | soft_sigma = 2.000 | lr = 7.00e-03\n",
      "Epoch   30 | train‑avg =  14.7586 | soft‑eval =  14.4147 | best =  14.7684 | no_improve = 12 | time = 1s | epoch_time = 0.0s | soft_sigma = 2.000 | lr = 7.00e-03\n",
      "Epoch   40 | train‑avg =  14.0225 | soft‑eval =  14.5814 | best =  14.8657 | no_improve =  0 | time = 1s | epoch_time = 0.0s | soft_sigma = 2.000 | lr = 7.00e-03\n",
      "Epoch   50 | train‑avg =  14.9486 | soft‑eval =  14.1958 | best =  14.8657 | no_improve = 10 | time = 2s | epoch_time = 0.0s | soft_sigma = 2.000 | lr = 7.00e-03\n",
      "Epoch   60 | train‑avg =  14.1816 | soft‑eval =  14.4663 | best =  14.8657 | no_improve = 20 | time = 2s | epoch_time = 0.0s | soft_sigma = 2.000 | lr = 7.00e-03\n",
      "Epoch   70 | train‑avg =  14.3165 | soft‑eval =  14.0266 | best =  14.8657 | no_improve = 30 | time = 2s | epoch_time = 0.0s | soft_sigma = 2.000 | lr = 7.00e-03\n",
      "Epoch   80 | train‑avg =  14.3523 | soft‑eval =  14.1662 | best =  14.8657 | no_improve = 40 | time = 3s | epoch_time = 0.0s | soft_sigma = 2.000 | lr = 7.00e-03\n",
      "Epoch   90 | train‑avg =  14.1458 | soft‑eval =  14.5724 | best =  14.8657 | no_improve = 50 | time = 3s | epoch_time = 0.0s | soft_sigma = 2.000 | lr = 7.00e-03\n",
      "Epoch  100 | train‑avg =  14.1300 | soft‑eval =  14.4918 | best =  14.8657 | no_improve = 60 | time = 4s | epoch_time = 0.0s | soft_sigma = 2.000 | lr = 7.00e-03\n",
      "Epoch  110 | train‑avg =  14.1617 | soft‑eval =  14.1806 | best =  14.8657 | no_improve = 70 | time = 4s | epoch_time = 0.0s | soft_sigma = 2.000 | lr = 7.00e-03\n",
      "Epoch  120 | train‑avg =  14.2061 | soft‑eval =  13.9611 | best =  14.8657 | no_improve = 80 | time = 4s | epoch_time = 0.0s | soft_sigma = 2.000 | lr = 7.00e-03\n",
      "Epoch  130 | train‑avg =  14.3731 | soft‑eval =  14.0821 | best =  14.9877 | no_improve =  7 | time = 5s | epoch_time = 0.0s | soft_sigma = 2.000 | lr = 7.00e-03\n",
      "Epoch  140 | train‑avg =  14.6286 | soft‑eval =  13.8498 | best =  14.9877 | no_improve = 17 | time = 5s | epoch_time = 0.0s | soft_sigma = 2.000 | lr = 7.00e-03\n",
      "Epoch  150 | train‑avg =  14.2659 | soft‑eval =  14.2674 | best =  14.9877 | no_improve = 27 | time = 6s | epoch_time = 0.0s | soft_sigma = 2.000 | lr = 7.00e-03\n",
      "Epoch  160 | train‑avg =  14.8407 | soft‑eval =  13.8365 | best =  14.9877 | no_improve = 37 | time = 6s | epoch_time = 0.0s | soft_sigma = 2.000 | lr = 7.00e-03\n",
      "Epoch  170 | train‑avg =  13.9185 | soft‑eval =  14.2862 | best =  14.9877 | no_improve = 47 | time = 6s | epoch_time = 0.0s | soft_sigma = 2.000 | lr = 7.00e-03\n",
      "Epoch  180 | train‑avg =  14.0577 | soft‑eval =  14.2348 | best =  14.9877 | no_improve = 57 | time = 7s | epoch_time = 0.0s | soft_sigma = 2.000 | lr = 7.00e-03\n",
      "Epoch  190 | train‑avg =  14.2321 | soft‑eval =  14.4293 | best =  14.9877 | no_improve = 67 | time = 7s | epoch_time = 0.0s | soft_sigma = 2.000 | lr = 7.00e-03\n",
      "Epoch  200 | train‑avg =  13.8983 | soft‑eval =  14.4029 | best =  14.9877 | no_improve = 77 | time = 8s | epoch_time = 0.0s | soft_sigma = 2.000 | lr = 3.50e-03\n",
      "Epoch  210 | train‑avg =  13.9163 | soft‑eval =  14.2135 | best =  14.9877 | no_improve = 87 | time = 8s | epoch_time = 0.0s | soft_sigma = 2.000 | lr = 3.50e-03\n",
      "Epoch  220 | train‑avg =  14.2759 | soft‑eval =  14.1845 | best =  14.9877 | no_improve = 97 | time = 8s | epoch_time = 0.0s | soft_sigma = 2.000 | lr = 3.50e-03\n",
      "Epoch  230 | train‑avg =  13.9086 | soft‑eval =  14.2387 | best =  15.1214 | no_improve =  4 | time = 9s | epoch_time = 0.0s | soft_sigma = 2.000 | lr = 3.50e-03\n",
      "Epoch  240 | train‑avg =  13.7640 | soft‑eval =  14.5902 | best =  15.1214 | no_improve = 14 | time = 9s | epoch_time = 0.0s | soft_sigma = 2.000 | lr = 3.50e-03\n",
      "Epoch  250 | train‑avg =  14.6103 | soft‑eval =  14.4042 | best =  15.1214 | no_improve = 24 | time = 10s | epoch_time = 0.0s | soft_sigma = 2.000 | lr = 3.50e-03\n",
      "Epoch  260 | train‑avg =  14.0804 | soft‑eval =  13.9197 | best =  15.1214 | no_improve = 34 | time = 10s | epoch_time = 0.0s | soft_sigma = 2.000 | lr = 3.50e-03\n",
      "Epoch  270 | train‑avg =  14.4305 | soft‑eval =  14.4437 | best =  15.1214 | no_improve = 44 | time = 10s | epoch_time = 0.0s | soft_sigma = 2.000 | lr = 3.50e-03\n",
      "Epoch  280 | train‑avg =  14.4007 | soft‑eval =  14.2298 | best =  15.1214 | no_improve = 54 | time = 11s | epoch_time = 0.0s | soft_sigma = 2.000 | lr = 3.50e-03\n",
      "Epoch  290 | train‑avg =  13.6392 | soft‑eval =  14.4241 | best =  15.1214 | no_improve = 64 | time = 11s | epoch_time = 0.0s | soft_sigma = 2.000 | lr = 3.50e-03\n",
      "Epoch  300 | train‑avg =  14.6306 | soft‑eval =  14.6175 | best =  15.1214 | no_improve = 74 | time = 12s | epoch_time = 0.0s | soft_sigma = 2.000 | lr = 3.50e-03\n",
      "Epoch  310 | train‑avg =  14.2854 | soft‑eval =  14.1043 | best =  15.1214 | no_improve = 84 | time = 12s | epoch_time = 0.0s | soft_sigma = 2.000 | lr = 3.50e-03\n",
      "Epoch  320 | train‑avg =  13.9206 | soft‑eval =  14.0839 | best =  15.1214 | no_improve = 94 | time = 12s | epoch_time = 0.0s | soft_sigma = 2.000 | lr = 3.50e-03\n",
      "Epoch  330 | train‑avg =  14.3119 | soft‑eval =  14.5470 | best =  15.1214 | no_improve = 104 | time = 13s | epoch_time = 0.0s | soft_sigma = 2.000 | lr = 3.50e-03\n",
      "Epoch  340 | train‑avg =  14.1675 | soft‑eval =  14.1718 | best =  15.1214 | no_improve = 114 | time = 13s | epoch_time = 0.0s | soft_sigma = 2.000 | lr = 3.50e-03\n",
      "Epoch  350 | train‑avg =  13.8253 | soft‑eval =  14.2142 | best =  15.1214 | no_improve = 124 | time = 14s | epoch_time = 0.0s | soft_sigma = 2.000 | lr = 3.50e-03\n",
      "Epoch  360 | train‑avg =  14.1858 | soft‑eval =  14.0863 | best =  15.1214 | no_improve = 134 | time = 14s | epoch_time = 0.0s | soft_sigma = 2.000 | lr = 3.50e-03\n",
      "Epoch  370 | train‑avg =  13.9600 | soft‑eval =  14.4792 | best =  15.1214 | no_improve = 144 | time = 14s | epoch_time = 0.0s | soft_sigma = 2.000 | lr = 3.50e-03\n",
      "Epoch  380 | train‑avg =  14.4373 | soft‑eval =  14.3504 | best =  15.1214 | no_improve = 154 | time = 15s | epoch_time = 0.0s | soft_sigma = 2.000 | lr = 3.50e-03\n",
      "Epoch  390 | train‑avg =  14.3042 | soft‑eval =  14.4936 | best =  15.1214 | no_improve = 164 | time = 15s | epoch_time = 0.0s | soft_sigma = 2.000 | lr = 3.50e-03\n",
      "Epoch  400 | train‑avg =  14.0674 | soft‑eval =  14.6112 | best =  15.1214 | no_improve = 174 | time = 16s | epoch_time = 0.0s | soft_sigma = 2.000 | lr = 3.50e-03\n",
      "Epoch  410 | train‑avg =  14.1637 | soft‑eval =  14.8816 | best =  15.1214 | no_improve = 184 | time = 16s | epoch_time = 0.0s | soft_sigma = 2.000 | lr = 3.50e-03\n",
      "Epoch  420 | train‑avg =  14.5874 | soft‑eval =  14.3652 | best =  15.1214 | no_improve = 194 | time = 16s | epoch_time = 0.0s | soft_sigma = 2.000 | lr = 3.50e-03\n",
      "Early stopping triggered after 426 epochs (17s)\n",
      "Best score: 15.121415\n",
      "No improvement for 200 epochs\n",
      "\n",
      "Training completed after 425 epochs\n",
      "Total training time: 17s\n",
      "Average time per epoch: 0.0s\n",
      "Best evaluation score: 15.121415\n",
      "Final score: 14.313301\n",
      "\n",
      "Evaluating final policy...\n",
      "Sharp policy price ≈ 14.3276  CI: [14.3046,14.3506] (95% CI)\n"
     ]
    }
   ],
   "source": [
    "d = 2\n",
    "seed = 42\n",
    "\n",
    "S0_vec       = np.full(d, 90.0, dtype=np.float32)\n",
    "sigma_vec    = get_vol(d)\n",
    "q_vec        = np.full(d, 0.1, dtype=np.float32)\n",
    "rho          = 0.0\n",
    "r            = 0.05\n",
    "K            = 100.0\n",
    "T            = 3.0\n",
    "num_steps    = 9\n",
    "dt           = T / num_steps\n",
    "\n",
    "\n",
    "prices = []\n",
    "times = []\n",
    "n_trials = 4\n",
    "\n",
    "for trial in range(n_trials):\n",
    "    net, train_hist, eval_hist, training_time = train_net(\n",
    "    soft_sigma=2.0,\n",
    "    N_train=10_000,\n",
    "    batch=500,\n",
    "    lr=0.007,\n",
    "    seed=seed + trial,\n",
    "    eval_every=10,\n",
    "    width=64,\n",
    "    depth=2,\n",
    "    dropout=0.1,\n",
    "    curriculum=False,\n",
    "    patience=200,            \n",
    "    min_delta=1e-2,      \n",
    "    relative_threshold=1e-3,\n",
    "    min_epochs=50,         \n",
    "    max_epochs=2000     \n",
    "    )\n",
    "    times.append(training_time)\n",
    "\n",
    "    print(\"\\nEvaluating final policy...\")\n",
    "    sharp_mean, sharp_se = evaluate_sharp_policy(net, N_eval=5_000_000)\n",
    "    prices.append(sharp_mean)\n",
    "    print(f\"Sharp policy price ≈ {sharp_mean:.4f}  CI: [{sharp_mean - 1.96*sharp_se:.4f},{sharp_mean + 1.96*sharp_se:.4f}] (95% CI)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "a709dd49-dcc0-4499-a77c-8c9ac74e8b7b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Price = 14.331 (0.007)\n",
      "Max Price = 14.340\n",
      "Times = ['10s', '38s', '10s', '17s']\n"
     ]
    }
   ],
   "source": [
    "print(f\"Price = {np.mean(prices):.3f} ({np.std(prices):.3f})\")\n",
    "print(f\"Max Price = {np.max(prices):.3f}\")\n",
    "print(f\"Times = {times}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "9a4190dd-258a-417b-b3b7-815932e7facf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average training time = 18.8\n"
     ]
    }
   ],
   "source": [
    "Times = ['10s', '38s', '10s', '17s']\n",
    "print(f\"Average training time = {average_time_in_seconds(Times)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3f5ddb4-2048-4b65-8cbe-4fab5b50b4f9",
   "metadata": {},
   "source": [
    "# d = 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "f0ea0e9a-2d79-4ef4-a9f2-51e4bb4dee63",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Setting up input normalization...\n",
      "Starting training with early stopping (patience=200, min_epochs=50)\n",
      "Will stop when improvement < 1.00e-02 absolute or < 1.00e-03 relative\n",
      "Early stopping triggered after 611 epochs (27s)\n",
      "Best score: 27.587587\n",
      "No improvement for 200 epochs\n",
      "\n",
      "Training completed after 610 epochs\n",
      "Total training time: 27s\n",
      "Average time per epoch: 0.0s\n",
      "Best evaluation score: 27.587587\n",
      "Final score: 26.376560\n",
      "\n",
      "Evaluating final policy...\n",
      "Sharp policy price ≈ 26.6439  CI: [26.6152,26.6726] (95% CI)\n",
      "Setting up input normalization...\n",
      "Starting training with early stopping (patience=200, min_epochs=50)\n",
      "Will stop when improvement < 1.00e-02 absolute or < 1.00e-03 relative\n",
      "Early stopping triggered after 256 epochs (10s)\n",
      "Best score: 27.442592\n",
      "No improvement for 200 epochs\n",
      "\n",
      "Training completed after 255 epochs\n",
      "Total training time: 10s\n",
      "Average time per epoch: 0.0s\n",
      "Best evaluation score: 27.442592\n",
      "Final score: 27.153861\n",
      "\n",
      "Evaluating final policy...\n",
      "Sharp policy price ≈ 26.6198  CI: [26.5903,26.6494] (95% CI)\n",
      "Setting up input normalization...\n",
      "Starting training with early stopping (patience=200, min_epochs=50)\n",
      "Will stop when improvement < 1.00e-02 absolute or < 1.00e-03 relative\n",
      "Early stopping triggered after 294 epochs (12s)\n",
      "Best score: 27.277321\n",
      "No improvement for 200 epochs\n",
      "\n",
      "Training completed after 293 epochs\n",
      "Total training time: 12s\n",
      "Average time per epoch: 0.0s\n",
      "Best evaluation score: 27.277321\n",
      "Final score: 26.229757\n",
      "\n",
      "Evaluating final policy...\n",
      "Sharp policy price ≈ 26.6498  CI: [26.6209,26.6787] (95% CI)\n",
      "Setting up input normalization...\n",
      "Starting training with early stopping (patience=200, min_epochs=50)\n",
      "Will stop when improvement < 1.00e-02 absolute or < 1.00e-03 relative\n",
      "Early stopping triggered after 282 epochs (11s)\n",
      "Best score: 27.418870\n",
      "No improvement for 200 epochs\n",
      "\n",
      "Training completed after 281 epochs\n",
      "Total training time: 11s\n",
      "Average time per epoch: 0.0s\n",
      "Best evaluation score: 27.418870\n",
      "Final score: 26.865613\n",
      "\n",
      "Evaluating final policy...\n",
      "Sharp policy price ≈ 26.6288  CI: [26.5994,26.6581] (95% CI)\n"
     ]
    }
   ],
   "source": [
    "d = 3\n",
    "seed = 42\n",
    "\n",
    "S0_vec       = np.full(d, 100.0, dtype=np.float32)\n",
    "sigma_vec    = get_vol(d)\n",
    "q_vec        = np.full(d, 0.1, dtype=np.float32)\n",
    "rho          = 0.0\n",
    "r            = 0.05\n",
    "K            = 100.0\n",
    "T            = 3.0\n",
    "num_steps    = 9\n",
    "dt           = T / num_steps\n",
    "\n",
    "prices = []\n",
    "times = []\n",
    "n_trials = 4\n",
    "\n",
    "for trial in range(n_trials):\n",
    "    net, train_hist, eval_hist, training_time = train_net(\n",
    "    soft_sigma=2.0,\n",
    "    N_train=10_000,\n",
    "    batch=500,\n",
    "    lr=0.007,\n",
    "    seed=seed + trial,\n",
    "    eval_every=10,\n",
    "    width=64,\n",
    "    depth=2,\n",
    "    dropout=0.1,\n",
    "    curriculum=False,\n",
    "    patience=200,            \n",
    "    min_delta=1e-2,      \n",
    "    relative_threshold=1e-3,\n",
    "    min_epochs=50,         \n",
    "    max_epochs=2000     \n",
    "    )\n",
    "    times.append(training_time)\n",
    "\n",
    "    print(\"\\nEvaluating final policy...\")\n",
    "    sharp_mean, sharp_se = evaluate_sharp_policy(net, N_eval=5_000_000)\n",
    "    prices.append(sharp_mean)\n",
    "    print(f\"Sharp policy price ≈ {sharp_mean:.4f}  CI: [{sharp_mean - 1.96*sharp_se:.4f},{sharp_mean + 1.96*sharp_se:.4f}] (95% CI)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "884dedc3-ed74-44ed-9a12-29be96d836da",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Price = 26.636 (0.012)\n",
      "Max Price = 26.650\n",
      "Times = ['27s', '10s', '12s', '11s']\n"
     ]
    }
   ],
   "source": [
    "print(f\"Price = {np.mean(prices):.3f} ({np.std(prices):.3f})\")\n",
    "print(f\"Max Price = {np.max(prices):.3f}\")\n",
    "print(f\"Times = {times}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "ccd5b9c1-75ef-4f2f-b9b4-80cfd779c4d5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average training time = 15.0\n"
     ]
    }
   ],
   "source": [
    "Times = ['27s', '10s', '12s', '11s']\n",
    "print(f\"Average training time = {average_time_in_seconds(Times)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "4af7bd2f-b3e5-4832-bb92-ead6d0bc48cb",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Setting up input normalization...\n",
      "Starting training with early stopping (patience=200, min_epochs=50)\n",
      "Will stop when improvement < 1.00e-02 absolute or < 1.00e-03 relative\n",
      "Early stopping triggered after 298 epochs (13s)\n",
      "Best score: 19.732530\n",
      "No improvement for 200 epochs\n",
      "\n",
      "Training completed after 297 epochs\n",
      "Total training time: 13s\n",
      "Average time per epoch: 0.0s\n",
      "Best evaluation score: 19.732530\n",
      "Final score: 19.136751\n",
      "\n",
      "Evaluating final policy...\n",
      "Sharp policy price ≈ 19.0478  CI: [19.0233,19.0724] (95% CI)\n",
      "Setting up input normalization...\n",
      "Starting training with early stopping (patience=200, min_epochs=50)\n",
      "Will stop when improvement < 1.00e-02 absolute or < 1.00e-03 relative\n",
      "Early stopping triggered after 506 epochs (22s)\n",
      "Best score: 19.920550\n",
      "No improvement for 200 epochs\n",
      "\n",
      "Training completed after 505 epochs\n",
      "Total training time: 22s\n",
      "Average time per epoch: 0.0s\n",
      "Best evaluation score: 19.920550\n",
      "Final score: 18.583071\n",
      "\n",
      "Evaluating final policy...\n",
      "Sharp policy price ≈ 19.0422  CI: [19.0180,19.0663] (95% CI)\n",
      "Setting up input normalization...\n",
      "Starting training with early stopping (patience=200, min_epochs=50)\n",
      "Will stop when improvement < 1.00e-02 absolute or < 1.00e-03 relative\n",
      "Early stopping triggered after 294 epochs (12s)\n",
      "Best score: 19.732997\n",
      "No improvement for 200 epochs\n",
      "\n",
      "Training completed after 293 epochs\n",
      "Total training time: 12s\n",
      "Average time per epoch: 0.0s\n",
      "Best evaluation score: 19.732997\n",
      "Final score: 18.618242\n",
      "\n",
      "Evaluating final policy...\n",
      "Sharp policy price ≈ 19.0361  CI: [19.0101,19.0621] (95% CI)\n",
      "Setting up input normalization...\n",
      "Starting training with early stopping (patience=200, min_epochs=50)\n",
      "Will stop when improvement < 1.00e-02 absolute or < 1.00e-03 relative\n",
      "Early stopping triggered after 282 epochs (12s)\n",
      "Best score: 19.758282\n",
      "No improvement for 200 epochs\n",
      "\n",
      "Training completed after 281 epochs\n",
      "Total training time: 12s\n",
      "Average time per epoch: 0.0s\n",
      "Best evaluation score: 19.758282\n",
      "Final score: 19.179940\n",
      "\n",
      "Evaluating final policy...\n",
      "Sharp policy price ≈ 18.9742  CI: [18.9472,19.0013] (95% CI)\n"
     ]
    }
   ],
   "source": [
    "d = 3\n",
    "seed = 42\n",
    "\n",
    "S0_vec       = np.full(d, 90.0, dtype=np.float32)\n",
    "sigma_vec    = get_vol(d)\n",
    "q_vec        = np.full(d, 0.1, dtype=np.float32)\n",
    "rho          = 0.0\n",
    "r            = 0.05\n",
    "K            = 100.0\n",
    "T            = 3.0\n",
    "num_steps    = 9\n",
    "dt           = T / num_steps\n",
    "\n",
    "\n",
    "prices = []\n",
    "times = []\n",
    "n_trials = 4\n",
    "\n",
    "for trial in range(n_trials):\n",
    "    net, train_hist, eval_hist, training_time = train_net(\n",
    "    soft_sigma=2.0,\n",
    "    N_train=10_000,\n",
    "    batch=500,\n",
    "    lr=0.007,\n",
    "    seed=seed + trial,\n",
    "    eval_every=10,\n",
    "    width=64,\n",
    "    depth=2,\n",
    "    dropout=0.1,\n",
    "    curriculum=False,\n",
    "    patience=200,            \n",
    "    min_delta=1e-2,      \n",
    "    relative_threshold=1e-3,\n",
    "    min_epochs=50,         \n",
    "    max_epochs=2000     \n",
    "    )\n",
    "    times.append(training_time)\n",
    "\n",
    "    print(\"\\nEvaluating final policy...\")\n",
    "    sharp_mean, sharp_se = evaluate_sharp_policy(net, N_eval=5_000_000)\n",
    "    prices.append(sharp_mean)\n",
    "    print(f\"Sharp policy price ≈ {sharp_mean:.4f}  CI: [{sharp_mean - 1.96*sharp_se:.4f},{sharp_mean + 1.96*sharp_se:.4f}] (95% CI)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "c5692252-dad5-4e22-a789-d11f35e4df0c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Price = 19.025 (0.030)\n",
      "Max Price = 19.048\n",
      "Times = ['13s', '22s', '12s', '12s']\n"
     ]
    }
   ],
   "source": [
    "print(f\"Price = {np.mean(prices):.3f} ({np.std(prices):.3f})\")\n",
    "print(f\"Max Price = {np.max(prices):.3f}\")\n",
    "print(f\"Times = {times}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "3962ac6b-3946-4e92-a5fb-a520a1ce7db6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average training time = 14.8\n"
     ]
    }
   ],
   "source": [
    "Times = ['13s', '22s', '12s', '12s']\n",
    "\n",
    "print(f\"Average training time = {average_time_in_seconds(Times)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ae6d9a2-c7ba-41f7-bebd-a6239e744093",
   "metadata": {},
   "source": [
    "# d = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "7c2f3460-242b-4ced-9a36-73c585fa7f25",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Setting up input normalization...\n",
      "Starting training with early stopping (patience=200, min_epochs=50)\n",
      "Will stop when improvement < 1.00e-02 absolute or < 1.00e-03 relative\n",
      "Early stopping triggered after 449 epochs (21s)\n",
      "Best score: 38.855115\n",
      "No improvement for 200 epochs\n",
      "\n",
      "Training completed after 448 epochs\n",
      "Total training time: 21s\n",
      "Average time per epoch: 0.0s\n",
      "Best evaluation score: 38.855115\n",
      "Final score: 38.231800\n",
      "\n",
      "Evaluating final policy...\n",
      "Sharp policy price ≈ 37.9120  CI: [37.8792,37.9448] (95% CI)\n",
      "Setting up input normalization...\n",
      "Starting training with early stopping (patience=200, min_epochs=50)\n",
      "Will stop when improvement < 1.00e-02 absolute or < 1.00e-03 relative\n",
      "Early stopping triggered after 602 epochs (28s)\n",
      "Best score: 38.871948\n",
      "No improvement for 200 epochs\n",
      "\n",
      "Training completed after 601 epochs\n",
      "Total training time: 28s\n",
      "Average time per epoch: 0.0s\n",
      "Best evaluation score: 38.871948\n",
      "Final score: 37.953054\n",
      "\n",
      "Evaluating final policy...\n",
      "Sharp policy price ≈ 37.9105  CI: [37.8785,37.9425] (95% CI)\n",
      "Setting up input normalization...\n",
      "Starting training with early stopping (patience=200, min_epochs=50)\n",
      "Will stop when improvement < 1.00e-02 absolute or < 1.00e-03 relative\n",
      "Early stopping triggered after 364 epochs (18s)\n",
      "Best score: 39.111031\n",
      "No improvement for 200 epochs\n",
      "\n",
      "Training completed after 363 epochs\n",
      "Total training time: 18s\n",
      "Average time per epoch: 0.1s\n",
      "Best evaluation score: 39.111031\n",
      "Final score: 38.240745\n",
      "\n",
      "Evaluating final policy...\n",
      "Sharp policy price ≈ 37.8649  CI: [37.8313,37.8984] (95% CI)\n",
      "Setting up input normalization...\n",
      "Starting training with early stopping (patience=200, min_epochs=50)\n",
      "Will stop when improvement < 1.00e-02 absolute or < 1.00e-03 relative\n",
      "Early stopping triggered after 363 epochs (18s)\n",
      "Best score: 38.774063\n",
      "No improvement for 200 epochs\n",
      "\n",
      "Training completed after 362 epochs\n",
      "Total training time: 18s\n",
      "Average time per epoch: 0.1s\n",
      "Best evaluation score: 38.774063\n",
      "Final score: 37.611331\n",
      "\n",
      "Evaluating final policy...\n",
      "Sharp policy price ≈ 37.9075  CI: [37.8755,37.9395] (95% CI)\n"
     ]
    }
   ],
   "source": [
    "d = 5\n",
    "seed = 42\n",
    "\n",
    "S0_vec       = np.full(d, 100.0, dtype=np.float32)\n",
    "sigma_vec    = get_vol(d)\n",
    "q_vec        = np.full(d, 0.1, dtype=np.float32)\n",
    "rho          = 0.0\n",
    "r            = 0.05\n",
    "K            = 100.0\n",
    "T            = 3.0\n",
    "num_steps    = 9\n",
    "dt           = T / num_steps\n",
    "\n",
    "\n",
    "prices = []\n",
    "times = []\n",
    "n_trials = 4\n",
    "\n",
    "for trial in range(n_trials):\n",
    "    net, train_hist, eval_hist, training_time = train_net(\n",
    "    soft_sigma=2.0,\n",
    "    N_train=10_000,\n",
    "    batch=500,\n",
    "    lr=0.007,\n",
    "    seed=seed + trial,\n",
    "    eval_every=10,\n",
    "    width=64,\n",
    "    depth=2,\n",
    "    dropout=0.1,\n",
    "    curriculum=False,\n",
    "    patience=200,            \n",
    "    min_delta=1e-2,      \n",
    "    relative_threshold=1e-3,\n",
    "    min_epochs=50,         \n",
    "    max_epochs=2000     \n",
    "    )\n",
    "    times.append(training_time)\n",
    "\n",
    "    print(\"\\nEvaluating final policy...\")\n",
    "    sharp_mean, sharp_se = evaluate_sharp_policy(net, N_eval=5_000_000)\n",
    "    prices.append(sharp_mean)\n",
    "    print(f\"Sharp policy price ≈ {sharp_mean:.4f}  CI: [{sharp_mean - 1.96*sharp_se:.4f},{sharp_mean + 1.96*sharp_se:.4f}] (95% CI)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "0c5f6973-3fa0-4eeb-b6f0-17562515e2e6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Price = 37.899 (0.020)\n",
      "Max Price = 37.912\n",
      "Times = ['21s', '28s', '18s', '18s']\n"
     ]
    }
   ],
   "source": [
    "print(f\"Price = {np.mean(prices):.3f} ({np.std(prices):.3f})\")\n",
    "print(f\"Max Price = {np.max(prices):.3f}\")\n",
    "print(f\"Times = {times}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "e90f224d-d03a-4d32-9fb0-91aff1c98f9f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average training time = 21.2\n"
     ]
    }
   ],
   "source": [
    "Times = ['21s', '28s', '18s', '18s']\n",
    "\n",
    "print(f\"Average training time = {average_time_in_seconds(Times)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "583209b3-d512-45e7-b3a1-0623ebcdd1e1",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Setting up input normalization...\n",
      "Starting training with early stopping (patience=200, min_epochs=50)\n",
      "Will stop when improvement < 1.00e-02 absolute or < 1.00e-03 relative\n",
      "Early stopping triggered after 537 epochs (28s)\n",
      "Best score: 28.543253\n",
      "No improvement for 200 epochs\n",
      "\n",
      "Training completed after 536 epochs\n",
      "Total training time: 28s\n",
      "Average time per epoch: 0.1s\n",
      "Best evaluation score: 28.543253\n",
      "Final score: 26.980859\n",
      "\n",
      "Evaluating final policy...\n",
      "Sharp policy price ≈ 27.6002  CI: [27.5713,27.6291] (95% CI)\n",
      "Setting up input normalization...\n",
      "Starting training with early stopping (patience=200, min_epochs=50)\n",
      "Will stop when improvement < 1.00e-02 absolute or < 1.00e-03 relative\n",
      "Early stopping triggered after 385 epochs (19s)\n",
      "Best score: 28.388719\n",
      "No improvement for 200 epochs\n",
      "\n",
      "Training completed after 384 epochs\n",
      "Total training time: 19s\n",
      "Average time per epoch: 0.1s\n",
      "Best evaluation score: 28.388719\n",
      "Final score: 27.750961\n",
      "\n",
      "Evaluating final policy...\n",
      "Sharp policy price ≈ 27.5823  CI: [27.5533,27.6114] (95% CI)\n",
      "Setting up input normalization...\n",
      "Starting training with early stopping (patience=200, min_epochs=50)\n",
      "Will stop when improvement < 1.00e-02 absolute or < 1.00e-03 relative\n",
      "Early stopping triggered after 364 epochs (17s)\n",
      "Best score: 28.828309\n",
      "No improvement for 200 epochs\n",
      "\n",
      "Training completed after 363 epochs\n",
      "Total training time: 17s\n",
      "Average time per epoch: 0.0s\n",
      "Best evaluation score: 28.828309\n",
      "Final score: 27.800841\n",
      "\n",
      "Evaluating final policy...\n",
      "Sharp policy price ≈ 27.5432  CI: [27.5138,27.5726] (95% CI)\n",
      "Setting up input normalization...\n",
      "Starting training with early stopping (patience=200, min_epochs=50)\n",
      "Will stop when improvement < 1.00e-02 absolute or < 1.00e-03 relative\n",
      "Early stopping triggered after 494 epochs (24s)\n",
      "Best score: 28.398175\n",
      "No improvement for 200 epochs\n",
      "\n",
      "Training completed after 493 epochs\n",
      "Total training time: 24s\n",
      "Average time per epoch: 0.0s\n",
      "Best evaluation score: 28.398175\n",
      "Final score: 27.703405\n",
      "\n",
      "Evaluating final policy...\n",
      "Sharp policy price ≈ 27.5941  CI: [27.5652,27.6230] (95% CI)\n"
     ]
    }
   ],
   "source": [
    "d = 5\n",
    "seed = 42\n",
    "\n",
    "S0_vec       = np.full(d, 90.0, dtype=np.float32)\n",
    "sigma_vec    = get_vol(d)\n",
    "q_vec        = np.full(d, 0.1, dtype=np.float32)\n",
    "rho          = 0.0\n",
    "r            = 0.05\n",
    "K            = 100.0\n",
    "T            = 3.0\n",
    "num_steps    = 9\n",
    "dt           = T / num_steps\n",
    "\n",
    "\n",
    "prices = []\n",
    "times = []\n",
    "n_trials = 4\n",
    "\n",
    "for trial in range(n_trials):\n",
    "    net, train_hist, eval_hist, training_time = train_net(\n",
    "    soft_sigma=2.0,\n",
    "    N_train=10_000,\n",
    "    batch=500,\n",
    "    lr=0.007,\n",
    "    seed=seed + trial,\n",
    "    eval_every=10,\n",
    "    width=64,\n",
    "    depth=2,\n",
    "    dropout=0.1,\n",
    "    curriculum=False,\n",
    "    patience=200,            \n",
    "    min_delta=1e-2,      \n",
    "    relative_threshold=1e-3,\n",
    "    min_epochs=50,         \n",
    "    max_epochs=2000     \n",
    "    )\n",
    "    times.append(training_time)\n",
    "\n",
    "    print(\"\\nEvaluating final policy...\")\n",
    "    sharp_mean, sharp_se = evaluate_sharp_policy(net, N_eval=5_000_000)\n",
    "    prices.append(sharp_mean)\n",
    "    print(f\"Sharp policy price ≈ {sharp_mean:.4f}  CI: [{sharp_mean - 1.96*sharp_se:.4f},{sharp_mean + 1.96*sharp_se:.4f}] (95% CI)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "7643ec7a-3322-4102-8694-c7afa2db8ca9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Price = 27.580 (0.022)\n",
      "Max Price = 27.600\n",
      "Times = ['28s', '19s', '17s', '24s']\n"
     ]
    }
   ],
   "source": [
    "print(f\"Price = {np.mean(prices):.3f} ({np.std(prices):.3f})\")\n",
    "print(f\"Max Price = {np.max(prices):.3f}\")\n",
    "print(f\"Times = {times}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "37ce3755-f602-451b-ab1c-feddd2ba2e9d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average training time = 22.0\n"
     ]
    }
   ],
   "source": [
    "Times = ['28s', '19s', '17s', '24s']\n",
    "\n",
    "print(f\"Average training time = {average_time_in_seconds(Times)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73ff8bec-c69f-4b00-9adc-27baa5bf9670",
   "metadata": {},
   "source": [
    "# d = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "8cfc56a4-a961-4946-9d55-9402ac6b452e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Setting up input normalization...\n",
      "Starting training with early stopping (patience=200, min_epochs=50)\n",
      "Will stop when improvement < 1.00e-02 absolute or < 1.00e-03 relative\n",
      "Early stopping triggered after 472 epochs (40s)\n",
      "Best score: 106.733238\n",
      "No improvement for 200 epochs\n",
      "\n",
      "Training completed after 471 epochs\n",
      "Total training time: 40s\n",
      "Average time per epoch: 0.1s\n",
      "Best evaluation score: 106.733238\n",
      "Final score: 103.757770\n",
      "\n",
      "Evaluating final policy...\n",
      "Sharp policy price ≈ 104.2286  CI: [104.1482,104.3089] (95% CI)\n",
      "Setting up input normalization...\n",
      "Starting training with early stopping (patience=200, min_epochs=50)\n",
      "Will stop when improvement < 1.00e-02 absolute or < 1.00e-03 relative\n",
      "Early stopping triggered after 524 epochs (44s)\n",
      "Best score: 107.213708\n",
      "No improvement for 200 epochs\n",
      "\n",
      "Training completed after 523 epochs\n",
      "Total training time: 44s\n",
      "Average time per epoch: 0.1s\n",
      "Best evaluation score: 107.213708\n",
      "Final score: 103.712999\n",
      "\n",
      "Evaluating final policy...\n",
      "Sharp policy price ≈ 104.2416  CI: [104.1616,104.3216] (95% CI)\n",
      "Setting up input normalization...\n",
      "Starting training with early stopping (patience=200, min_epochs=50)\n",
      "Will stop when improvement < 1.00e-02 absolute or < 1.00e-03 relative\n",
      "Early stopping triggered after 435 epochs (37s)\n",
      "Best score: 106.928717\n",
      "No improvement for 200 epochs\n",
      "\n",
      "Training completed after 434 epochs\n",
      "Total training time: 37s\n",
      "Average time per epoch: 0.1s\n",
      "Best evaluation score: 106.928717\n",
      "Final score: 105.059409\n",
      "\n",
      "Evaluating final policy...\n",
      "Sharp policy price ≈ 104.1400  CI: [104.0590,104.2210] (95% CI)\n",
      "Setting up input normalization...\n",
      "Starting training with early stopping (patience=200, min_epochs=50)\n",
      "Will stop when improvement < 1.00e-02 absolute or < 1.00e-03 relative\n",
      "Early stopping triggered after 452 epochs (39s)\n",
      "Best score: 106.868283\n",
      "No improvement for 200 epochs\n",
      "\n",
      "Training completed after 451 epochs\n",
      "Total training time: 39s\n",
      "Average time per epoch: 0.1s\n",
      "Best evaluation score: 106.868283\n",
      "Final score: 103.680810\n",
      "\n",
      "Evaluating final policy...\n",
      "Sharp policy price ≈ 104.1334  CI: [104.0518,104.2150] (95% CI)\n"
     ]
    }
   ],
   "source": [
    "d = 10\n",
    "seed = 42\n",
    "\n",
    "S0_vec       = np.full(d, 100.0, dtype=np.float32)\n",
    "sigma_vec    = get_vol(d)\n",
    "q_vec        = np.full(d, 0.1, dtype=np.float32)\n",
    "rho          = 0.0\n",
    "r            = 0.05\n",
    "K            = 100.0\n",
    "T            = 3.0\n",
    "num_steps    = 9\n",
    "dt           = T / num_steps\n",
    "\n",
    "\n",
    "prices = []\n",
    "times = []\n",
    "n_trials = 4\n",
    "\n",
    "for trial in range(n_trials):\n",
    "    net, train_hist, eval_hist, training_time = train_net(\n",
    "    soft_sigma=2.0,\n",
    "    N_train=10_000,\n",
    "    batch=500,\n",
    "    lr=0.007,\n",
    "    seed=seed + trial,\n",
    "    eval_every=10,\n",
    "    width=64,\n",
    "    depth=2,\n",
    "    dropout=0.1,\n",
    "    curriculum=False,\n",
    "    patience=200,            \n",
    "    min_delta=1e-2,      \n",
    "    relative_threshold=1e-3,\n",
    "    min_epochs=50,         \n",
    "    max_epochs=2000     \n",
    "    )\n",
    "    times.append(training_time)\n",
    "\n",
    "    print(\"\\nEvaluating final policy...\")\n",
    "    sharp_mean, sharp_se = evaluate_sharp_policy(net, N_eval=5_000_000)\n",
    "    prices.append(sharp_mean)\n",
    "    print(f\"Sharp policy price ≈ {sharp_mean:.4f}  CI: [{sharp_mean - 1.96*sharp_se:.4f},{sharp_mean + 1.96*sharp_se:.4f}] (95% CI)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "cde63a72-aecb-49d7-b9f2-f61273939ae4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Price = 104.186 (0.049)\n",
      "Max Price = 104.242\n",
      "Times = ['40s', '44s', '37s', '39s']\n"
     ]
    }
   ],
   "source": [
    "print(f\"Price = {np.mean(prices):.3f} ({np.std(prices):.3f})\")\n",
    "print(f\"Max Price = {np.max(prices):.3f}\")\n",
    "print(f\"Times = {times}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "1560e77b-a0ea-475d-913c-ed6de4d09ed3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average training time = 40.0\n"
     ]
    }
   ],
   "source": [
    "Times = ['40s', '44s', '37s', '39s']\n",
    "\n",
    "print(f\"Average training time = {average_time_in_seconds(Times)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "719e02f2-0feb-4519-8f43-956dbff4bc7e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Setting up input normalization...\n",
      "Starting training with early stopping (patience=200, min_epochs=50)\n",
      "Will stop when improvement < 1.00e-02 absolute or < 1.00e-03 relative\n",
      "Early stopping triggered after 472 epochs (42s)\n",
      "Best score: 87.885173\n",
      "No improvement for 200 epochs\n",
      "\n",
      "Training completed after 471 epochs\n",
      "Total training time: 42s\n",
      "Average time per epoch: 0.1s\n",
      "Best evaluation score: 87.885173\n",
      "Final score: 85.078569\n",
      "\n",
      "Evaluating final policy...\n",
      "Sharp policy price ≈ 85.6030  CI: [85.5314,85.6746] (95% CI)\n",
      "Setting up input normalization...\n",
      "Starting training with early stopping (patience=200, min_epochs=50)\n",
      "Will stop when improvement < 1.00e-02 absolute or < 1.00e-03 relative\n",
      "Early stopping triggered after 524 epochs (46s)\n",
      "Best score: 88.401685\n",
      "No improvement for 200 epochs\n",
      "\n",
      "Training completed after 523 epochs\n",
      "Total training time: 46s\n",
      "Average time per epoch: 0.1s\n",
      "Best evaluation score: 88.401685\n",
      "Final score: 85.323239\n",
      "\n",
      "Evaluating final policy...\n",
      "Sharp policy price ≈ 85.5438  CI: [85.4708,85.6168] (95% CI)\n",
      "Setting up input normalization...\n",
      "Starting training with early stopping (patience=200, min_epochs=50)\n",
      "Will stop when improvement < 1.00e-02 absolute or < 1.00e-03 relative\n",
      "Early stopping triggered after 435 epochs (40s)\n",
      "Best score: 88.324789\n",
      "No improvement for 200 epochs\n",
      "\n",
      "Training completed after 434 epochs\n",
      "Total training time: 40s\n",
      "Average time per epoch: 0.1s\n",
      "Best evaluation score: 88.324789\n",
      "Final score: 86.663007\n",
      "\n",
      "Evaluating final policy...\n",
      "Sharp policy price ≈ 85.4680  CI: [85.3942,85.5419] (95% CI)\n",
      "Setting up input normalization...\n",
      "Starting training with early stopping (patience=200, min_epochs=50)\n",
      "Will stop when improvement < 1.00e-02 absolute or < 1.00e-03 relative\n",
      "Early stopping triggered after 452 epochs (40s)\n",
      "Best score: 87.711918\n",
      "No improvement for 200 epochs\n",
      "\n",
      "Training completed after 451 epochs\n",
      "Total training time: 40s\n",
      "Average time per epoch: 0.1s\n",
      "Best evaluation score: 87.711918\n",
      "Final score: 84.953949\n",
      "\n",
      "Evaluating final policy...\n",
      "Sharp policy price ≈ 85.5433  CI: [85.4714,85.6152] (95% CI)\n"
     ]
    }
   ],
   "source": [
    "d = 10\n",
    "seed = 42\n",
    "\n",
    "S0_vec       = np.full(d, 90.0, dtype=np.float32)\n",
    "sigma_vec    = get_vol(d)\n",
    "q_vec        = np.full(d, 0.1, dtype=np.float32)\n",
    "rho          = 0.0\n",
    "r            = 0.05\n",
    "K            = 100.0\n",
    "T            = 3.0\n",
    "num_steps    = 9\n",
    "dt           = T / num_steps\n",
    "\n",
    "\n",
    "prices = []\n",
    "times = []\n",
    "n_trials = 4\n",
    "\n",
    "for trial in range(n_trials):\n",
    "    net, train_hist, eval_hist, training_time = train_net(\n",
    "    soft_sigma=2.0,\n",
    "    N_train=10_000,\n",
    "    batch=500,\n",
    "    lr=0.007,\n",
    "    seed=seed + trial,\n",
    "    eval_every=10,\n",
    "    width=64,\n",
    "    depth=2,\n",
    "    dropout=0.1,\n",
    "    curriculum=False,\n",
    "    patience=200,            \n",
    "    min_delta=1e-2,      \n",
    "    relative_threshold=1e-3,\n",
    "    min_epochs=50,         \n",
    "    max_epochs=2000     \n",
    "    )\n",
    "    times.append(training_time)\n",
    "\n",
    "    print(\"\\nEvaluating final policy...\")\n",
    "    sharp_mean, sharp_se = evaluate_sharp_policy(net, N_eval=5_000_000)\n",
    "    prices.append(sharp_mean)\n",
    "    print(f\"Sharp policy price ≈ {sharp_mean:.4f}  CI: [{sharp_mean - 1.96*sharp_se:.4f},{sharp_mean + 1.96*sharp_se:.4f}] (95% CI)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "a5f28d34-58e2-4c7b-b4da-404a4c92e418",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Price = 85.540 (0.048)\n",
      "Max Price = 85.603\n",
      "Times = ['42s', '46s', '40s', '40s']\n"
     ]
    }
   ],
   "source": [
    "print(f\"Price = {np.mean(prices):.3f} ({np.std(prices):.3f})\")\n",
    "print(f\"Max Price = {np.max(prices):.3f}\")\n",
    "print(f\"Times = {times}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "1da95bf1-31b8-4cf3-9ef4-be5dc563552c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average training time = 42.0\n"
     ]
    }
   ],
   "source": [
    "Times = ['42s', '46s', '40s', '40s']\n",
    "\n",
    "print(f\"Average training time = {average_time_in_seconds(Times)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "533c1d32-c986-474e-9767-45aa8468378d",
   "metadata": {},
   "source": [
    "# d = 20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "25fcfc01-9378-43de-b2d1-ee5756a33f9b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Setting up input normalization...\n",
      "Starting training with early stopping (patience=200, min_epochs=50)\n",
      "Will stop when improvement < 1.00e-02 absolute or < 1.00e-03 relative\n",
      "Epoch   10 | train‑avg = 132.6036 | soft‑eval = 132.2347 | best = 129.2994 | no_improve =  0 | time = 1s | epoch_time = 0.1s | soft_sigma = 2.000 | lr = 7.00e-03\n",
      "Epoch   20 | train‑avg = 142.3294 | soft‑eval = 142.9957 | best = 141.0061 | no_improve =  0 | time = 2s | epoch_time = 0.1s | soft_sigma = 2.000 | lr = 7.00e-03\n",
      "Epoch   30 | train‑avg = 142.8824 | soft‑eval = 145.4027 | best = 143.9171 | no_improve =  5 | time = 3s | epoch_time = 0.1s | soft_sigma = 2.000 | lr = 7.00e-03\n",
      "Epoch   40 | train‑avg = 143.4219 | soft‑eval = 144.6482 | best = 147.0524 | no_improve =  3 | time = 4s | epoch_time = 0.1s | soft_sigma = 2.000 | lr = 7.00e-03\n",
      "Epoch   50 | train‑avg = 145.7536 | soft‑eval = 144.5944 | best = 147.0524 | no_improve = 13 | time = 5s | epoch_time = 0.1s | soft_sigma = 2.000 | lr = 7.00e-03\n",
      "Epoch   60 | train‑avg = 144.9076 | soft‑eval = 146.0174 | best = 147.6844 | no_improve =  4 | time = 6s | epoch_time = 0.1s | soft_sigma = 2.000 | lr = 7.00e-03\n",
      "Epoch   70 | train‑avg = 144.9588 | soft‑eval = 147.0687 | best = 149.0310 | no_improve =  0 | time = 7s | epoch_time = 0.1s | soft_sigma = 2.000 | lr = 7.00e-03\n",
      "Epoch   80 | train‑avg = 146.3009 | soft‑eval = 144.7231 | best = 149.0310 | no_improve = 10 | time = 8s | epoch_time = 0.1s | soft_sigma = 2.000 | lr = 7.00e-03\n",
      "Epoch   90 | train‑avg = 146.6560 | soft‑eval = 146.5828 | best = 149.0310 | no_improve = 20 | time = 9s | epoch_time = 0.1s | soft_sigma = 2.000 | lr = 7.00e-03\n",
      "Epoch  100 | train‑avg = 144.8384 | soft‑eval = 144.4614 | best = 149.0310 | no_improve = 30 | time = 10s | epoch_time = 0.1s | soft_sigma = 2.000 | lr = 7.00e-03\n",
      "Epoch  110 | train‑avg = 149.2671 | soft‑eval = 145.7939 | best = 149.0310 | no_improve = 40 | time = 11s | epoch_time = 0.1s | soft_sigma = 2.000 | lr = 7.00e-03\n",
      "Epoch  120 | train‑avg = 148.2126 | soft‑eval = 146.6995 | best = 149.0310 | no_improve = 50 | time = 12s | epoch_time = 0.1s | soft_sigma = 2.000 | lr = 7.00e-03\n",
      "Epoch  130 | train‑avg = 147.4958 | soft‑eval = 149.8297 | best = 149.0310 | no_improve = 60 | time = 13s | epoch_time = 0.1s | soft_sigma = 2.000 | lr = 7.00e-03\n",
      "Epoch  140 | train‑avg = 147.5244 | soft‑eval = 146.6572 | best = 149.8297 | no_improve =  9 | time = 14s | epoch_time = 0.1s | soft_sigma = 2.000 | lr = 7.00e-03\n",
      "Epoch  150 | train‑avg = 146.6587 | soft‑eval = 147.1177 | best = 149.8297 | no_improve = 19 | time = 15s | epoch_time = 0.1s | soft_sigma = 2.000 | lr = 7.00e-03\n",
      "Epoch  160 | train‑avg = 148.4707 | soft‑eval = 147.9576 | best = 149.8297 | no_improve = 29 | time = 16s | epoch_time = 0.1s | soft_sigma = 2.000 | lr = 7.00e-03\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[39]\u001b[39m\u001b[32m, line 20\u001b[39m\n\u001b[32m     17\u001b[39m n_trials = \u001b[32m1\u001b[39m\n\u001b[32m     19\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m trial \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(n_trials):\n\u001b[32m---> \u001b[39m\u001b[32m20\u001b[39m     net, train_hist, eval_hist, training_time = \u001b[43mtrain_net\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m     21\u001b[39m \u001b[43m    \u001b[49m\u001b[43msoft_sigma\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m2.0\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m     22\u001b[39m \u001b[43m    \u001b[49m\u001b[43mN_train\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m10_000\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m     23\u001b[39m \u001b[43m    \u001b[49m\u001b[43mbatch\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m500\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m     24\u001b[39m \u001b[43m    \u001b[49m\u001b[43mlr\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m0.007\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m     25\u001b[39m \u001b[43m    \u001b[49m\u001b[43mseed\u001b[49m\u001b[43m=\u001b[49m\u001b[43mseed\u001b[49m\u001b[43m \u001b[49m\u001b[43m+\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrial\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     26\u001b[39m \u001b[43m    \u001b[49m\u001b[43meval_every\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m10\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m     27\u001b[39m \u001b[43m    \u001b[49m\u001b[43mwidth\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m64\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m     28\u001b[39m \u001b[43m    \u001b[49m\u001b[43mdepth\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m2\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m     29\u001b[39m \u001b[43m    \u001b[49m\u001b[43mdropout\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m0.1\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m     30\u001b[39m \u001b[43m    \u001b[49m\u001b[43mcurriculum\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m     31\u001b[39m \u001b[43m    \u001b[49m\u001b[43mpatience\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m200\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m            \u001b[49m\n\u001b[32m     32\u001b[39m \u001b[43m    \u001b[49m\u001b[43mmin_delta\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m1e-2\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m      \u001b[49m\n\u001b[32m     33\u001b[39m \u001b[43m    \u001b[49m\u001b[43mrelative_threshold\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m1e-3\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m     34\u001b[39m \u001b[43m    \u001b[49m\u001b[43mmin_epochs\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m50\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m         \u001b[49m\n\u001b[32m     35\u001b[39m \u001b[43m    \u001b[49m\u001b[43mmax_epochs\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m2000\u001b[39;49m\u001b[43m     \u001b[49m\n\u001b[32m     36\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     37\u001b[39m     times.append(training_time)\n\u001b[32m     39\u001b[39m     \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33mEvaluating final policy...\u001b[39m\u001b[33m\"\u001b[39m)\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[6]\u001b[39m\u001b[32m, line 337\u001b[39m, in \u001b[36mtrain_net\u001b[39m\u001b[34m(soft_sigma, N_train, batch, lr, seed, eval_every, width, depth, dropout, curriculum, patience, min_delta, relative_threshold, min_epochs, max_epochs)\u001b[39m\n\u001b[32m    335\u001b[39m optimiser.zero_grad()\n\u001b[32m    336\u001b[39m loss = -total_payoffs.mean()\n\u001b[32m--> \u001b[39m\u001b[32m337\u001b[39m \u001b[43mloss\u001b[49m\u001b[43m.\u001b[49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    339\u001b[39m torch.nn.utils.clip_grad_norm_(net.parameters(), max_norm=\u001b[32m1.0\u001b[39m)\n\u001b[32m    340\u001b[39m optimiser.step()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/torch/_tensor.py:525\u001b[39m, in \u001b[36mTensor.backward\u001b[39m\u001b[34m(self, gradient, retain_graph, create_graph, inputs)\u001b[39m\n\u001b[32m    515\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m has_torch_function_unary(\u001b[38;5;28mself\u001b[39m):\n\u001b[32m    516\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m handle_torch_function(\n\u001b[32m    517\u001b[39m         Tensor.backward,\n\u001b[32m    518\u001b[39m         (\u001b[38;5;28mself\u001b[39m,),\n\u001b[32m   (...)\u001b[39m\u001b[32m    523\u001b[39m         inputs=inputs,\n\u001b[32m    524\u001b[39m     )\n\u001b[32m--> \u001b[39m\u001b[32m525\u001b[39m \u001b[43mtorch\u001b[49m\u001b[43m.\u001b[49m\u001b[43mautograd\u001b[49m\u001b[43m.\u001b[49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    526\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgradient\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m=\u001b[49m\u001b[43minputs\u001b[49m\n\u001b[32m    527\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/torch/autograd/__init__.py:267\u001b[39m, in \u001b[36mbackward\u001b[39m\u001b[34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[39m\n\u001b[32m    262\u001b[39m     retain_graph = create_graph\n\u001b[32m    264\u001b[39m \u001b[38;5;66;03m# The reason we repeat the same comment below is that\u001b[39;00m\n\u001b[32m    265\u001b[39m \u001b[38;5;66;03m# some Python versions print out the first line of a multi-line function\u001b[39;00m\n\u001b[32m    266\u001b[39m \u001b[38;5;66;03m# calls in the traceback and some print out the last line\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m267\u001b[39m \u001b[43m_engine_run_backward\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    268\u001b[39m \u001b[43m    \u001b[49m\u001b[43mtensors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    269\u001b[39m \u001b[43m    \u001b[49m\u001b[43mgrad_tensors_\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    270\u001b[39m \u001b[43m    \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    271\u001b[39m \u001b[43m    \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    272\u001b[39m \u001b[43m    \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    273\u001b[39m \u001b[43m    \u001b[49m\u001b[43mallow_unreachable\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m    274\u001b[39m \u001b[43m    \u001b[49m\u001b[43maccumulate_grad\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m    275\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/torch/autograd/graph.py:744\u001b[39m, in \u001b[36m_engine_run_backward\u001b[39m\u001b[34m(t_outputs, *args, **kwargs)\u001b[39m\n\u001b[32m    742\u001b[39m     unregister_hooks = _register_logging_hooks_on_whole_graph(t_outputs)\n\u001b[32m    743\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m744\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mVariable\u001b[49m\u001b[43m.\u001b[49m\u001b[43m_execution_engine\u001b[49m\u001b[43m.\u001b[49m\u001b[43mrun_backward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# Calls into the C++ engine to run the backward pass\u001b[39;49;00m\n\u001b[32m    745\u001b[39m \u001b[43m        \u001b[49m\u001b[43mt_outputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\n\u001b[32m    746\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# Calls into the C++ engine to run the backward pass\u001b[39;00m\n\u001b[32m    747\u001b[39m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[32m    748\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m attach_logging_hooks:\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m: "
     ]
    }
   ],
   "source": [
    "d = 20\n",
    "seed = 42\n",
    "\n",
    "S0_vec       = np.full(d, 100.0, dtype=np.float32)\n",
    "sigma_vec    = get_vol(d)\n",
    "q_vec        = np.full(d, 0.1, dtype=np.float32)\n",
    "rho          = 0.0\n",
    "r            = 0.05\n",
    "K            = 100.0\n",
    "T            = 3.0\n",
    "num_steps    = 9\n",
    "dt           = T / num_steps\n",
    "\n",
    "\n",
    "prices = []\n",
    "times = []\n",
    "n_trials = 1\n",
    "\n",
    "for trial in range(n_trials):\n",
    "    net, train_hist, eval_hist, training_time = train_net(\n",
    "    soft_sigma=2.0,\n",
    "    N_train=10_000,\n",
    "    batch=500,\n",
    "    lr=0.007,\n",
    "    seed=seed + trial,\n",
    "    eval_every=10,\n",
    "    width=64,\n",
    "    depth=2,\n",
    "    dropout=0.1,\n",
    "    curriculum=False,\n",
    "    patience=200,            \n",
    "    min_delta=1e-2,      \n",
    "    relative_threshold=1e-3,\n",
    "    min_epochs=50,         \n",
    "    max_epochs=2000     \n",
    "    )\n",
    "    times.append(training_time)\n",
    "\n",
    "    print(\"\\nEvaluating final policy...\")\n",
    "    sharp_mean, sharp_se = evaluate_sharp_policy(net, N_eval=5_000_000)\n",
    "    prices.append(sharp_mean)\n",
    "    print(f\"Sharp policy price ≈ {sharp_mean:.4f}  CI: [{sharp_mean - 1.96*sharp_se:.4f},{sharp_mean + 1.96*sharp_se:.4f}] (95% CI)\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
